---
name: prism-review
description: |
  Code and module review skill adapted from obra/superpowers for PRISM quality control.
  Use when: reviewing extracted modules, checking material databases, validating
  architecture decisions, or doing pre-merge checks. Provides structured review
  process for consistent quality. Triggers: module extraction complete, database
  ready for use, architecture review, pre-merge check, quality audit.
---

# PRISM REVIEW SKILL v1.0
## Structured Review for Manufacturing Intelligence
### Adapted from obra/superpowers for PRISM quality control

---

## CORE PRINCIPLE

**REVIEW CATCHES WHAT VERIFICATION MISSES.**

Verification checks for correctness. Review checks for quality:
- Is this the RIGHT solution?
- Is this MAINTAINABLE?
- Does this follow PRISM principles?
- Will this scale?
- Are there better alternatives?

---

## üìã REVIEW PROTOCOL

### Review Types

| Type | Scope | When | Time |
|------|-------|------|------|
| Quick | Single item | After creation | 2-5 min |
| Standard | Module/file | After extraction | 10-20 min |
| Deep | Architecture | Major decisions | 30-60 min |
| Audit | Full system | Periodically | 1-2 hours |

---

## QUICK REVIEW CHECKLIST

For individual items (materials, functions, entries):

```markdown
## QUICK REVIEW: [ITEM]

‚òê Correct? Does it work as intended?
‚òê Complete? All required parts present?
‚òê Consistent? Follows existing patterns?
‚òê Clear? Understandable without explanation?
‚òê Clean? No obvious improvements needed?

Result: APPROVE / REQUEST CHANGES
```

---

## STANDARD REVIEW CHECKLIST

For modules and files:

```markdown
## STANDARD REVIEW: [MODULE/FILE]

### Correctness
‚òê Functions work as documented
‚òê Data is accurate
‚òê Edge cases handled
‚òê Error handling present

### Completeness
‚òê All functions extracted/implemented
‚òê All data present
‚òê Dependencies documented
‚òê Consumers identified (min 6)

### Consistency
‚òê Naming follows conventions
‚òê Structure matches similar modules
‚òê API consistent with peers

### Clarity
‚òê Code is readable
‚òê Comments explain "why"
‚òê Complex logic documented

### 10 Commandments Alignment
‚òê 1. Used everywhere? (consumers wired)
‚òê 2. Fuses concepts? (cross-domain integration)
‚òê 3. Verified? (validation present)
‚òê 4. Learns? (feeds ML pipeline)
‚òê 5. Uncertainty? (confidence intervals)
‚òê 6. Explainable? (XAI ready)
‚òê 7. Fails gracefully? (fallbacks present)
‚òê 8. Protected? (validation, sanitization)
‚òê 9. Performs? (<500ms calculations)
‚òê 10. User-focused? (good defaults)

### Issues Found
| # | Severity | Description | Recommendation |
|---|----------|-------------|----------------|
|   |          |             |                |

Result: APPROVE / REQUEST CHANGES / MAJOR REWORK
```

---

## DEEP REVIEW CHECKLIST

For architectural decisions:

```markdown
## DEEP REVIEW: [DECISION/COMPONENT]

### Problem Understanding
‚òê Problem clearly defined
‚òê Requirements documented
‚òê Constraints identified
‚òê Success criteria measurable

### Solution Evaluation
‚òê Multiple options considered
‚òê Tradeoffs documented
‚òê Best option selected with rationale
‚òê Risks identified and mitigated

### Technical Quality
‚òê Design is sound
‚òê Implementation is feasible
‚òê Scalability considered
‚òê Maintainability considered
‚òê Performance requirements met

### Integration
‚òê Fits with existing architecture
‚òê No breaking changes
‚òê Migration path clear (if needed)
‚òê Documentation complete

### Future Considerations
‚òê Extensible for future needs
‚òê Technical debt acceptable
‚òê Learning curve reasonable
‚òê Team can maintain

### 10 Commandments Deep Check
‚òê Every component used to maximum?
‚òê Cross-domain concepts fused?
‚òê Validation at every level?
‚òê Learning feedback loops?
‚òê Uncertainty quantified?
‚òê Decisions explainable?
‚òê Graceful degradation?
‚òê Security hardened?
‚òê Performance optimized?
‚òê User experience prioritized?

Result: APPROVE / CONDITIONAL / REJECT
```

---

## PRISM-SPECIFIC REVIEW CRITERIA

### Material Database Review

```markdown
## MATERIAL DATABASE REVIEW

### Data Quality
‚òê Sources cited (ASM, Machining Handbook)
‚òê Values in realistic ranges
‚òê No copy-paste errors
‚òê Consistent units

### Parameter Coverage
‚òê All 127 parameters defined
‚òê Cutting parameters complete
‚òê Thermal properties complete
‚òê Statistical metadata present

### Usability
‚òê Clear material categorization
‚òê Searchable by multiple criteria
‚òê Compatible with all consumers

### Extensibility
‚òê Easy to add new materials
‚òê Easy to update parameters
‚òê Hierarchy layers supported
```

### Module Extraction Review

```markdown
## MODULE EXTRACTION REVIEW

### Extraction Quality
‚òê All code captured
‚òê No dependencies left behind
‚òê Clean boundaries

### Functionality
‚òê All functions work
‚òê All data accessible
‚òê API documented

### Integration
‚òê Consumer list complete (min 6)
‚òê Gateway routes defined
‚òê Event bus integrated

### Migration Ready
‚òê Can be imported to new architecture
‚òê No circular dependencies
‚òê Version documented
```

### Consumer Wiring Review

```markdown
## CONSUMER WIRING REVIEW

### Coverage
‚òê Minimum 6 consumers per database
‚òê All data fields used somewhere
‚òê No orphan data

### Implementation
‚òê Routes correctly defined
‚òê Data transforms correct
‚òê Error handling present

### Performance
‚òê No N+1 query issues
‚òê Caching appropriate
‚òê Async where needed
```

---

## REVIEW COMMENTS BEST PRACTICES

### Good Comments

```
‚úì "This kc1_1 value (2847) seems high for this material family. 
   Similar steels typically range 1800-2200. Source?"

‚úì "Consider extracting this repeated pattern into a helper function."

‚úì "The fallback here returns undefined. Should return a default value 
   per Commandment 7."
```

### Bad Comments

```
‚úó "This is wrong." (No explanation)
‚úó "Fix this." (No guidance)
‚úó "I would do it differently." (Subjective, no criteria)
```

---

## REVIEW WORKFLOW

### Before Review

```
1. Understand what you're reviewing
2. Know the acceptance criteria
3. Have reference materials ready
4. Set aside adequate time
```

### During Review

```
1. First pass: Overall impression
2. Second pass: Detailed check against criteria
3. Third pass: Integration and implications
4. Document all findings
```

### After Review

```
1. Summarize findings
2. Categorize by severity
3. Provide recommendations
4. Follow up on addressed items
```

---

## REVIEW SEVERITY LEVELS

| Level | Description | Action |
|-------|-------------|--------|
| üî¥ Critical | Blocks release, causes failure | Must fix |
| üü† Major | Significant issue | Should fix |
| üü° Minor | Improvement opportunity | Nice to fix |
| üü¢ Note | Observation, future consideration | Optional |

---

## REVIEW REPORT TEMPLATE

```markdown
# REVIEW REPORT
## Subject: [What was reviewed]
## Reviewer: Claude
## Date: [DATE]
## Type: Quick / Standard / Deep

### Summary
[Overall assessment in 2-3 sentences]

### Result
‚òê APPROVED - Ready for use
‚òê CONDITIONAL - Approve with minor fixes
‚òê REQUEST CHANGES - Major issues found
‚òê REJECT - Fundamental problems

### Findings

#### Critical (Must Fix)
[List critical issues]

#### Major (Should Fix)
[List major issues]

#### Minor (Nice to Fix)
[List minor issues]

#### Notes
[List observations]

### Recommendations
[Specific actions to take]

### Follow-up
‚òê Re-review needed after changes
‚òê No re-review needed
```

---

## ANTI-PATTERNS (DON'T DO THIS)

‚ùå Rubber-stamp approvals without checking
‚ùå Review without criteria
‚ùå Personal preferences as requirements
‚ùå Blocking for trivial issues
‚ùå Not documenting review findings
‚ùå Reviewing your own work (except quick checks)
‚ùå Skipping review "to save time"

---

## INTEGRATION WITH PRISM SKILLS

- **prism-planning**: Review is planned activity
- **prism-tdd**: Tests inform review criteria
- **prism-verification**: Verification before review
- **prism-debugging**: Debug issues found in review
- **prism-auditor**: Audit is comprehensive review

---

**END OF PRISM REVIEW SKILL**

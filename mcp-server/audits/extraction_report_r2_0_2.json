{
  "session": "R2.0.2",
  "ralphIteration": 1,
  "timestamp": "2026-01-31T19:50:00Z",
  "summary": {
    "attempted": 25,
    "successful": 18,
    "failed": 7,
    "total_lines": 14110
  },
  "results": [
    {
      "name": "PRISM_CUTTING_THERMAL_ENGINE",
      "category": "engines",
      "refs": 305,
      "status": "FOUND",
      "code": "const PRISM_CUTTING_THERMAL_ENGINE = {\n    name: 'PRISM_CUTTING_THERMAL_ENGINE',\n    version: '1.0.0',\n    source: 'MIT 16.050, Trigger-Chao, Loewen-Shaw',\n    \n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // SHEAR PLANE TEMPERATURE\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    \n    /**\n     * Shear plane temperature rise (Trigger-Chao model)\n     * @param {Object} params - Cutting parameters\n     * @returns {Object} Temperature analysis\n     */\n    shearPlaneTemperature: function(params) {\n        const {\n            cuttingSpeed: V,      // m/min\n            feed: f,              // mm/rev\n            shearStrength: tau_s, // MPa\n            shearAngle: phi,      // radians\n            rakeAngle: alpha = 0.1, // radians\n            material              // Material properties object\n        } = params;\n        \n        const {\n            density: rho = 7850,           // kg/m\u00b3\n            specificHeat: c = 500,         // J/(kg\u00b7K)\n            thermalConductivity: k = 50,   // W/(m\u00b7K)\n            ambientTemp: T_0 = 25          // \u00b0C\n        } = material || {};\n        \n        // Thermal diffusivity\n        const alpha_th = k / (rho * c); // m\u00b2/s\n        \n        // Cutting velocity in m/s\n        const V_ms = V / 60;\n        \n        // Shear velocity\n        const V_s = V_ms * Math.cos(alpha) / Math.cos(phi - alpha);\n        \n        // Heat generated per unit volume in shear zone\n        const q_shear = tau_s * 1e6 * V_s; // W/m\u00b3\n        \n        // Chip thickness\n        const t_1 = f / 1000; // m\n        \n        // Shear zone thickness (approximate)\n        const delta_s = t_1 * 0.1;\n        \n        // Temperature rise in shear zone (simplified Trigger model)\n        const L = t_1 / Math.sin(phi); // Shear plane length\n        const R_t = V_s * L / alpha_th; // Thermal number\n        \n        let theta_s;\n        if (R_t > 10) {\n            // High speed: most heat goes to chip\n            theta_s = 0.4 * tau_s * 1e6 / (rho * c);\n        } else {\n            // Low speed: heat shared\n            theta_s = (tau_s * 1e6 / (rho * c)) * (1 / (1 + Math.sqrt(1 / R_t)));\n        }\n        \n        return {\n            temperatureRise_C: theta_s,\n            shearZoneTemp_C: T_0 + theta_s,\n            thermalNumber: R_t,\n            shearVelocity_mps: V_s,\n            heatRegime: R_t > 10 ? 'high_speed' : 'low_speed'\n        };\n    },\n    \n    /**\n     * Tool-chip interface temperature (more accurate model)\n     * @param {Object} params - Process and material parameters\n     * @returns {Object} Interface temperature analysis\n     */\n    toolChipInterfaceTemp: function(params) {\n        const {\n            cuttingSpeed: V,      // m/min\n            feed: f,              // mm/rev\n            depthOfCut: d,        // mm\n            specificCuttingEnergy: u_c, // J/mm\u00b3\n            material,             // Workpiece material\n            tool                  // Tool material\n        } = params;\n        \n        // Material properties\n        const rho_w = material?.density || 7850;\n        const c_w = material?.specificHeat || 500;\n        const k_w = material?.thermalConductivity || 50;\n        const T_0 = material?.ambientTemp || 25;\n        \n        // Tool properties\n        const k_t = tool?.thermalConductivity || 80; // Carbide\n        \n        // Thermal diffusivity of workpiece\n        const alpha_w = k_w / (rho_w * c_w);\n        \n        // Cutting velocity in m/s\n        const V_ms = V / 60;\n        \n        // Contact length (approximate)\n        const L_c = f * 2; // mm (Zorev approximation)\n        \n        // Heat flux\n        const MRR = V * f * d / 60000; // m\u00b3/s\n        const P_cut = u_c * 1e9 * MRR; // W\n        const A_contact = L_c * d / 1e6; // m\u00b2\n        const q_flux = P_cut / A_contact; // W/m\u00b2\n        \n        // Jaeger moving heat source solution (simplified)\n        const L = L_c / 1000; // m\n        const Pe = V_ms * L / (2 * alpha_w); // Peclet number\n        \n        let T_interface;\n        if (Pe > 5) {\n            // High Peclet (high speed): chip carries most heat\n            T_interface = T_0 + 0.754 * q_flux * Math.sqrt(L / (k_w * rho_w * c_w * V_ms));\n        } else {\n            // Low Peclet: more to tool\n            T_interface = T_0 + q_flux * L / k_w * 0.5;\n        }\n        \n        // Heat partition (Shaw's approximation)\n        const beta = Math.sqrt(k_w * rho_w * c_w);\n        const beta_t = Math.sqrt(k_t * (tool?.density || 14000) * (tool?.specificHeat || 300));\n        const R_tool = beta / (beta + beta_t);\n        \n        // Tool bulk temperature\n        const T_tool_avg = T_0 + (q_flux * R_tool) * Math.sqrt(L / (k_t * (tool?.density || 14000) * (tool?.specificHeat || 300) * V_ms));\n        \n        return {\n            interfaceTemperature_C: T_interface,\n            toolAverageTemp_C: T_tool_avg,\n            heatPartitionToTool: R_tool,\n            heatPartitionToChip: 1 - R_tool,\n            pecletNumber: Pe,\n            contactLength_mm: L_c,\n            heatFlux_W_m2: q_flux,\n            cuttingPower_W: P_cut\n        };\n    },\n    \n    /**\n     * Heat partition model (simplified)\n     */\n    heatPartition: function(params) {\n        const {\n            cuttingSpeed: V,\n            workMaterial,\n            toolMaterial\n        } = params;\n        \n        // Material thermal properties\n        const materials = {\n            'steel': { k: 50, rho: 7850, c: 500 },\n            'aluminum': { k: 205, rho: 2700, c: 900 },\n            'titanium': { k: 7.2, rho: 4500, c: 520 },\n            'carbide': { k: 80, rho: 14000, c: 300 },\n            'ceramic': { k: 30, rho: 3900, c: 800 },\n            'hss': { k: 27, rho: 8100, c: 460 }\n        };\n        \n        const work = materials[workMaterial?.toLowerCase()] || materials.steel;\n        const tool = materials[toolMaterial?.toLowerCase()] || materials.carbide;\n        \n        // Effusivity ratio (Shaw)\n        const e_work = Math.sqrt(work.k * work.rho * work.c);\n        const e_tool = Math.sqrt(tool.k * tool.rho * tool.c);\n        \n        // Speed factor (more heat to chip at high speed)\n        const V_ref = 100; // m/min reference\n        const speed_factor = 1 - 0.3 * Math.log10(V / V_ref);\n        \n        // Partition ratios\n        const R_chip = 0.6 + 0.2 * speed_factor;\n        const R_tool = (1 - R_chip) * e_work / (e_work + e_tool);\n        const R_work = 1 - R_chip - R_tool;\n        \n        return {\n            toChip_percent: R_chip * 100,\n            toTool_percent: R_tool * 100,\n            toWorkpiece_percent: R_work * 100,\n            effusivityWork: e_work,\n            effusivityTool: e_tool,\n            speedFactor: speed_factor\n        };\n    },\n    \n    // Gateway registration\n    register: function() {\n        if (typeof PRISM_GATEWAY !== 'undefined') {\n            PRISM_GATEWAY.register('thermal.shearPlane', 'PRISM_CUTTING_THERMAL_ENGINE.shearPlaneTemperature');\n            PRISM_GATEWAY.register('thermal.interface', 'PRISM_CUTTING_THERMAL_ENGINE.toolChipInterfaceTemp');\n            PRISM_GATEWAY.register('thermal.partition', 'PRISM_CUTTING_THERMAL_ENGINE.heatPartition');\n            console.log('[PRISM] PRISM_CUTTING_THERMAL_ENGINE registered: 3 routes');\n        }\n    }\n};\n\n\n/**\n * PRISM_HEAT_TRANSFER_ENGINE\n * Conduction, convection, and coolant modeling\n * Source: MIT 2.51 (Heat Transfer), MIT 16.050\n */\nconst PRISM_HEAT_TRANSFER_ENGINE = {\n    name: 'PRISM_HEAT_TRANSFER_ENGINE',\n    version: '1.0.0',\n    source: 'MIT 2.51, MIT 16.050',\n    \n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // CONDUCTION\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    \n    /**\n     * 1D steady-state conduction (Fourier's law)\n     * q = -k \u00d7 dT/dx\n     */\n    steadyStateConduction1D: function(params) {\n        const {\n            thermalConductivity: k, // W/(m\u00b7K)\n            length: L,              // m\n            crossSectionArea: A,    // m\u00b2\n            T_hot,                  // \u00b0C\n            T_cold                  // \u00b0C\n        } = params;\n        \n        const dT = T_hot - T_cold;\n        const q = k * A * dT / L; // W\n        const R_thermal = L / (k * A); // K/W\n        \n        return {\n            heatFlux_W: q,\n            heatFlux_W_m2: k * dT / L,\n            thermalResistance_K_W: R_thermal,\n            temperatureGradient_K_m: -dT / L,\n            temperatureProfile: (x) => T_hot - (dT / L) * x\n        };\n    },\n    \n    /**\n     * 1D transient conduction (lumped capacitance)\n     * Valid when Bi < 0.1\n     */\n    transientLumpedCapacitance: function(params) {\n        const {\n            mass: m,                    // kg\n            specificHeat: c,            // J/(kg\u00b7K)\n            surfaceArea: A_s,           // m\u00b2\n            heatTransferCoeff: h,       // W/(m\u00b2\u00b7K)\n            T_initial,                  // \u00b0C\n            T_ambient,                  // \u00b0C\n            time: t                     // s\n        } = params;\n        \n        // Time constant\n        const tau = m * c / (h * A_s);\n        \n        // Temperature at time t\n        const T = T_ambient + (T_initial - T_ambient) * Math.exp(-t / tau);\n        \n        // Cooling/heating rate\n        const dT_dt = -(T_initial - T_ambient) / tau * Math.exp(-t / tau);\n        \n        // Time to reach target temperature\n        const timeToTemp = (T_target) => {\n            const ratio = (T_target - T_ambient) / (T_initial - T_ambient);\n            return ratio > 0 ? -tau * Math.log(ratio) : Infinity;\n        };\n        \n        return {\n            temperature_C: T,\n            timeConstant_s: tau,\n            coolingRate_C_s: Math.abs(dT_dt),\n            percentComplete: (1 - Math.exp(-t / tau)) * 100,\n            time95percent_s: 3 * tau,\n            temperatureFunction: (time) => T_ambient + (T_initial - T_ambient) * Math.exp(-time / tau),\n            timeToTarget: timeToTemp\n        };\n    },\n    \n    /**\n     * 1D transient conduction with FDM (finite difference)\n     * @param {Object} params - Material, geometry, boundary conditions\n     * @param {Object} config - Numerical parameters\n     * @returns {Object} Temperature field evolution\n     */\n    transientConduction1D_FDM: function(params, config) {\n        const {\n            thermalConductivity: k,\n            density: rho,\n            specificHeat: c,\n            length: L,\n            T_initial,\n            T_left,          // Left boundary (Dirichlet)\n            T_right,         // Right boundary (Dirichlet)\n            q_left,          // Left heat flux (Neumann) - alternative\n            h_right,         // Convection at right (Robin) - alternative\n            T_inf            // Ambient for convection\n        } = params;\n        \n        const {\n            nx = 50,         // Spatial nodes\n            dt = 0.1,        // Time step (s)\n            duration = 100   // Total simulation time (s)\n        } = config;\n        \n        const alpha = k / (rho * c); // Thermal diffusivity\n        const dx = L / (nx - 1);\n        \n        // Stability check (Fo \u2264 0.5 for explicit)\n        const Fo = alpha * dt / (dx * dx);\n        if (Fo > 0.5) {\n            console.warn(`Fourier number ${Fo.toFixed(3)} > 0.5. Reduce dt for stability.`);\n        }\n        \n        // Initialize temperature array\n        let T = Array(nx).fill(T_initial);\n        const history = [{ time: 0, T: [...T] }];\n        \n        const numSteps = Math.floor(duration / dt);\n        \n        for (let step = 0; step < numSteps; step++) {\n            const T_new = [...T];\n            \n            // Interior points (explicit FTCS)\n            for (let i = 1; i < nx - 1; i++) {\n                T_new[i] = T[i] + Fo * (T[i+1] - 2*T[i] + T[i-1]);\n            }\n            \n            // Boundary conditions\n            if (T_left !== undefined) {\n                T_new[0] = T_left;\n            } else if (q_left !== undefined) {\n                // Neumann: q = -k dT/dx\n                T_new[0] = T_new[1] + q_left * dx / k;\n            }\n            \n            if (T_right !== undefined) {\n                T_new[nx-1] = T_right;\n            } else if (h_right !== undefined && T_inf !== undefined) {\n                // Robin: q = h(T - T_inf)\n                const Bi = h_right * dx / k;\n                T_new[nx-1] = (T_new[nx-2] + Bi * T_inf) / (1 + Bi);\n            }\n            \n            T = T_new;\n            \n            // Store at intervals\n            if (step % Math.max(1, Math.floor(numSteps / 100)) === 0) {\n                history.push({ time: (step + 1) * dt, T: [...T] });\n            }\n        }\n        \n        return {\n            finalTemperature: T,\n            history,\n            fourierNumber: Fo,\n            dx,\n            dt,\n            maxTemp: Math.max(...T),\n            minTemp: Math.min(...T),\n            positions: Array(nx).fill(0).map((_, i) => i * dx)\n        };\n    },\n    \n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // CONVECTION\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    \n    /**\n     * Forced convection heat transfer coefficient\n     * @param {Object} params - Flow and geometry parameters\n     * @returns {Object} Heat transfer coefficient and related values\n     */\n    forcedConvectionCoefficient: function(params) {\n        const {\n            velocity: U,            // m/s\n            characteristicLength: L, // m\n            fluidType = 'air'       // or 'water', 'oil', 'coolant'\n        } = params;\n        \n        // Fluid properties at ~20-25\u00b0C\n        const fluids = {\n            'air': { rho: 1.2, mu: 1.8e-5, k: 0.026, cp: 1006, Pr: 0.71 },\n            'water': { rho: 1000, mu: 1e-3, k: 0.6, cp: 4186, Pr: 7 },\n            'oil': { rho: 870, mu: 0.03, k: 0.14, cp: 1880, Pr: 400 },\n            'coolant': { rho: 1050, mu: 2e-3, k: 0.5, cp: 3500, Pr: 14 }\n        };\n        \n        const fluid = fluids[fluidType] || fluids.water;\n        \n        // Reynolds number\n        const Re = fluid.rho * U * L / fluid.mu;\n        \n        // Flow regime\n        const flowRegime = Re < 2300 ? 'laminar' : Re < 4000 ? 'transition' : 'turbulent';\n        \n        // Nusselt number correlations\n        let Nu;\n        if (Re < 2300) {\n            // Laminar flow over flat plate\n            Nu = 0.664 * Math.pow(Re, 0.5) * Math.pow(fluid.Pr, 1/3);\n        } else if (Re < 5e5) {\n            // Turbulent flat plate (Colburn)\n            Nu = 0.0296 * Math.pow(Re, 0.8) * Math.pow(fluid.Pr, 1/3);\n        } else {\n            // Fully turbulent (Dittus-Boelter)\n            Nu = 0.023 * Math.pow(Re, 0.8) * Math.pow(fluid.Pr, 0.4);\n        }\n        \n        // Heat transfer coefficient\n        const h = Nu * fluid.k / L;\n        \n        return {\n            heatTransferCoeff_W_m2K: h,\n            reynoldsNumber: Re,\n            nusseltNumber: Nu,\n            prandtlNumber: fluid.Pr,\n            flowRegime,\n            fluid: fluidType,\n            thermalBoundaryLayer_mm: L * 1000 / Math.pow(Re, 0.5) * Math.pow(fluid.Pr, 1/3)\n        };\n    },\n    \n    /**\n     * Coolant effectiveness in machining\n     */\n    coolantEffectiveness: function(params) {\n        const {\n            cuttingSpeed: V,         // m/min\n            flowRate: Q,             // L/min\n            coolantType = 'water_based',\n            nozzleDiameter: d_n = 3, // mm\n            nozzleDistance: L_n = 50 // mm from cutting zone\n        } = params;\n        \n        // Coolant properties\n        const coolants = {\n            'water_based': { h_eff: 10000, coolingCapacity: 1.0, friction_reduction: 0.15 },\n            'straight_oil': { h_eff: 3000, coolingCapacity: 0.4, friction_reduction: 0.25 },\n            'synthetic': { h_eff: 8000, coolingCapacity: 0.8, friction_reduction: 0.20 },\n            'semi_synthetic': { h_eff: 7000, coolingCapacity: 0.7, friction_reduction: 0.22 },\n            'mql': { h_eff: 2000, coolingCapacity: 0.15, friction_reduction: 0.30 }\n        };\n        \n        const coolant = coolants[coolantType] || coolants.water_based;\n        \n        // Jet velocity\n        const A_nozzle = Math.PI * (d_n/2/1000) ** 2; // m\u00b2\n        const V_jet = (Q / 60000) / A_nozzle; // m/s\n        \n        // Momentum ratio (jet penetration)\n        const V_chip = V / 60; // m/s\n        const momentumRatio = V_jet / V_chip;\n        \n        // Effective heat transfer coefficient (depends on penetration)\n        const penetrationFactor = Math.min(1, momentumRatio / 2);\n        const h_actual = coolant.h_eff * penetrationFactor;\n        \n        // Temperature reduction estimate\n        const T_reduction_estimate = penetrationFactor * coolant.coolingCapacity * 200; // \u00b0C\n        \n        return {\n            effectiveHTC_W_m2K: h_actual,\n            jetVelocity_m_s: V_jet,\n            momentumRatio,\n            penetrationFactor,\n            estimatedTempReduction_C: T_reduction_estimate,\n            frictionReduction_percent: coolant.friction_reduction * 100 * penetrationFactor,\n            coolantType,\n            recommendation: momentumRatio < 1.5 ? \n                'Increase flow rate or reduce nozzle diameter for better penetration' :\n                'Good coolant delivery'\n        };\n    },\n    \n    // Gateway registration\n    register: function() {\n        if (typeof PRISM_GATEWAY !== 'undefined') {\n            PRISM_GATEWAY.register('heat.conduction1D', 'PRISM_HEAT_TRANSFER_ENGINE.steadyStateConduction1D');\n            PRISM_GATEWAY.register('heat.transientLumped', 'PRISM_HEAT_TRANSFER_ENGINE.transientLumpedCapacitance');\n            PRISM_GATEWAY.register('heat.transientFDM', 'PRISM_HEAT_TRANSFER_ENGINE.transientConduction1D_FDM');\n            PRISM_GATEWAY.register('heat.convectionCoeff', 'PRISM_HEAT_TRANSFER_ENGINE.forcedConvectionCoefficient');\n            PRISM_GATEWAY.register('heat.coolant', 'PRISM_HEAT_TRANSFER_ENGINE.coolantEffectiveness');\n            console.log('[PRISM] PRISM_HEAT_TRANSFER_ENGINE registered: 5 routes');\n        }\n    }\n};\n\n\n/**\n * PRISM_THERMAL_EXPANSION_ENGINE\n * Thermal effects on dimensional accuracy\n * Source: MIT 2.75 (Precision Machine Design)\n */\nconst PRISM_THERMAL_EXPANSION_ENGINE = {\n    name: 'PRISM_THERMAL_EXPANSION_ENGINE',\n    version: '1.0.0',\n    source: 'MIT 2.75, Bryan Principles',\n    \n    /**\n     * Linear thermal expansion\n     * \u0394L = L \u00d7 \u03b1 \u00d7 \u0394T\n     */\n    linearExpansion: function(params) {\n        const {\n            originalLength: L,      // mm\n            temperatureChange: dT,  // \u00b0C\n            material,\n            CTE                     // Coefficient of thermal expansion (1/\u00b0C)\n        } = params;\n        \n        // CTE database (\u00b5m/m/\u00b0C = 10\u207b\u2076/\u00b0C)\n        const cteDatabase = {\n            'steel': 11.7e-6,\n            'stainless_steel': 17.3e-6,\n            'aluminum': 23.1e-6,\n            'brass': 19e-6,\n            'copper': 16.5e-6,\n            'cast_iron': 10.5e-6,\n            'granite': 6e-6,\n            'invar': 1.2e-6,\n            'super_invar': 0.6e-6,\n            'zerodur': 0.02e-6,\n            'ceramic': 7e-6,\n            'carbide': 5.5e-6\n        };\n        \n        const alpha = CTE || cteDatabase[material?.toLowerCase()] || 12e-6;\n        \n        const dL = L * alpha * dT;\n        \n        return {\n            expansion_mm: dL,\n            expansion_um: dL * 1000,\n            percentChange: (dL / L) * 100,\n            CTE_per_C: alpha,\n            material: material || 'default_steel',\n            temperatureForTolerance: (tolerance) => tolerance / (L * alpha)\n        };\n    },\n    \n    /**\n     * Thermal error analysis for machine tool\n     * Based on Bryan's principles\n     */\n    machineToolThermalError: function(params) {\n        const {\n            machineGeometry,     // {X_axis_length, Y_axis_length, Z_axis_length}\n            temperatureField,    // {X_gradient, Y_gradient, Z_gradient, spindle_delta}\n            materials = {}       // Material for each component\n        } = params;\n        \n        const { X_axis_length = 500, Y_axis_length = 400, Z_axis_length = 300 } = machineGeometry;\n        const { X_gradient = 1, Y_gradient = 0.5, Z_gradient = 0.8, spindle_delta = 5 } = temperatureField;\n        \n        // Default to cast iron for structure\n        const alpha_structure = 10.5e-6;\n        const alpha_spindle = 11.7e-6;\n        \n        // Positional errors from thermal expansion\n        const dX = X_axis_length * alpha_structure * X_gradient;\n        const dY = Y_axis_length * alpha_structure * Y_gradient;\n        const dZ = Z_axis_length * alpha_structure * Z_gradient;\n        \n        // Spindle growth (typically Z direction)\n        const spindle_length = 150; // mm approximate\n        const spindle_growth = spindle_length * alpha_spindle * spindle_delta;\n        \n        // Angular errors from temperature gradients\n        // \u03b1 = L \u00d7 \u03b1_CTE \u00d7 \u0394T_gradient / height\n        const height = 300; // mm structural height\n        const angular_X = Math.atan(X_axis_length * alpha_structure * X_gradient / height) * 1e6; // \u00b5rad\n        const angular_Y = Math.atan(Y_axis_length * alpha_structure * Y_gradient / height) * 1e6;\n        \n        // Total volumetric error (RSS)\n        const total_error = Math.sqrt(dX*dX + dY*dY + (dZ + spindle_growth)**2);\n        \n        return {\n            linearErrors_mm: { X: dX, Y: dY, Z: dZ + spindle_growth },\n            linearErrors_um: { X: dX*1000, Y: dY*1000, Z: (dZ + spindle_growth)*1000 },\n            spindleGrowth_um: spindle_growth * 1000,\n            angularErrors_urad: { X: angular_X, Y: angular_Y },\n            totalVolumetricError_um: total_error * 1000,\n            recommendations: this._thermalRecommendations(total_error * 1000, temperatureField)\n        };\n    },\n    \n    _thermalRecommendations: function(total_error_um, temps) {\n        const recs = [];\n        \n        if (total_error_um > 50) {\n            recs.push('Consider active thermal compensation');\n        }\n        if (temps.spindle_delta > 3) {\n            recs.push('Improve spindle cooling or increase warmup time');\n        }\n        if (temps.X_gradient > 1 || temps.Y_gradient > 1) {\n            recs.push('Check environmental temperature control');\n        }\n        if (total_error_um > 10) {\n            recs.push('Allow thermal stabilization before precision operations');\n        }\n        \n        return recs.length ? recs : ['Thermal errors within acceptable limits'];\n    },\n    \n    /**\n     * Thermal compensation calculation\n     */\n    thermalCompensation: function(params) {\n        const {\n            measuredTemperatures,    // Array of {sensor_id, temp, position}\n            referenceTemperatures,   // Array of {sensor_id, temp}\n            compensationMatrix       // Pre-calibrated thermal error model\n        } = params;\n        \n        // Calculate temperature changes from reference\n        const tempChanges = measuredTemperatures.map((m, i) => ({\n            sensor: m.sensor_id,\n            delta: m.temp - (referenceTemperatures[i]?.temp || 20),\n            position: m.position\n        }));\n        \n        // If no compensation matrix, use simple model\n        if (!compensationMatrix) {\n            const avg_delta = tempChanges.reduce((s, t) => s + t.delta, 0) / tempChanges.length;\n            return {\n                compensation_X_um: avg_delta * 10,  // Simple estimate\n                compensation_Y_um: avg_delta * 8,\n                compensation_Z_um: avg_delta * 12,\n                temperatureDeltas: tempChanges,\n                method: 'simple_average'\n            };\n        }\n        \n        // Apply compensation matrix (linear model)\n        // compensation = \u03a3(matrix_coeff \u00d7 temp_delta)\n        let comp_X = 0, comp_Y = 0, comp_Z = 0;\n        \n        for (let i = 0; i < tempChanges.length; i++) {\n            if (compensationMatrix[i]) {\n                comp_X += compensationMatrix[i].X * tempChanges[i].delta;\n                comp_Y += compensationMatrix[i].Y * tempChanges[i].delta;\n                comp_Z += compensationMatrix[i].Z * tempChanges[i].delta;\n            }\n        }\n        \n        return {\n            compensation_X_um: comp_X,\n            compensation_Y_um: comp_Y,\n            compensation_Z_um: comp_Z,\n            temperatureDeltas: tempChanges,\n            method: 'matrix_compensation'\n        };\n    },\n    \n    // Gateway registration\n    register: function() {\n        if (typeof PRISM_GATEWAY !== 'undefined') {\n            PRISM_GATEWAY.register('thermal.expansion', 'PRISM_THERMAL_EXPANSION_ENGINE.linearExpansion');\n            PRISM_GATEWAY.register('thermal.machineError', 'PRISM_THERMAL_EXPANSION_ENGINE.machineToolThermalError');\n            PRISM_GATEWAY.register('thermal.compensation', 'PRISM_THERMAL_EXPANSION_ENGINE.thermalCompensation');\n            console.log('[PRISM] PRISM_THERMAL_EXPANSION_ENGINE registered: 3 routes');\n        }\n    }\n};\n\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// REGISTRATION AND EXPORT\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nfunction registerSession4Part4() {\n    PRISM_CUTTING_THERMAL_ENGINE.register();\n    PRISM_HEAT_TRANSFER_ENGINE.register();\n    PRISM_THERMAL_EXPANSION_ENGINE.register();\n    \n    console.log('[Session 4 Part 4] Registered 3 modules, 11 gateway routes');\n    console.log('  - PRISM_CUTTING_THERMAL_ENGINE: Shear plane, Interface, Partition');\n    console.log('  - PRISM_HEAT_TRANSFER_ENGINE: Conduction, Convection, Coolant');\n    console.log('  - PRISM_THERMAL_EXPANSION_ENGINE: Expansion, Machine error, Compensation');\n}\n\n// Auto-register\nif (typeof window !== 'undefined') {\n    window.PRISM_CUTTING_THERMAL_ENGINE = PRISM_CUTTING_THERMAL_ENGINE;\n    window.PRISM_HEAT_TRANSFER_ENGINE = PRISM_HEAT_TRANSFER_ENGINE;\n    window.PRISM_THERMAL_EXPANSION_ENGINE = PRISM_THERMAL_EXPANSION_ENGINE;\n    registerSession4Part4();\n}\n\nconsole.log('[Session 4 Part 4] Thermal Analysis & Heat Transfer loaded - 3 modules');\n\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// SESSION 4 MASTER REGISTRATION\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nfunction registerAllSession4() {\n    registerSession4Part1();\n    registerSession4Part2();\n    registerSession4Part3();\n    registerSession4Part4();\n    console.log(\"[Session 4] All Physics & Dynamics modules registered\");\n    console.log(\"  - Part 1: Advanced Kinematics Engine\");\n    console.log(\"  - Part 2: Rigid Body Dynamics Engine\");\n    console.log(\"  - Part 3: Vibration & Chatter Analysis\");\n    console.log(\"  - Part 4: Thermal Analysis\");\n}\n\n// Auto-register Session 4\nif (typeof window !== \"undefined\") {\n    window.PRISM_ADVANCED_KINEMATICS_ENGINE = PRISM_ADVANCED_KINEMATICS_ENGINE;\n    window.PRISM_RIGID_BODY_DYNAMICS_ENGINE = PRISM_RIGID_BODY_DYNAMICS_ENGINE;\n    window.PRISM_VIBRATION_ANALYSIS_ENGINE = PRISM_VIBRATION_ANALYSIS_ENGINE;\n    window.PRISM_CHATTER_PREDICTION_ENGINE = PRISM_CHATTER_PREDICTION_ENGINE;\n    window.PRISM_CUTTING_MECHANICS_ENGINE = PRISM_CUTTING_MECHANICS_ENGINE;\n    window.PRISM_TOOL_LIFE_ENGINE = PRISM_TOOL_LIFE_ENGINE;\n    window.PRISM_SURFACE_FINISH_ENGINE = PRISM_SURFACE_FINISH_ENGINE;\n    window.PRISM_CUTTING_THERMAL_ENGINE = PRISM_CUTTING_THERMAL_ENGINE;\n    window.PRISM_HEAT_TRANSFER_ENGINE = PRISM_HEAT_TRANSFER_ENGINE;\n    window.PRISM_THERMAL_EXPANSION_ENGINE = PRISM_THERMAL_EXPANSION_ENGINE;\n    registerAllSession4();\n}\n\nconsole.log(\"[PRISM v8.83.001] Session 4 Physics & Dynamics loaded - 10 modules, 3,439 lines\");\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// SESSION 4 ENHANCEMENT: PHYSICS-INFORMED MACHINE LEARNING (PIML)\n// Cutting-edge 2024-2025 algorithms for chatter prediction\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n/**\n * \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n * PRISM SESSION 4 ENHANCEMENT: PHYSICS-INFORMED MACHINE LEARNING (PIML)\n * \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n * \n * Cutting-Edge Algorithms from 2024-2025 Research:\n * - Physics-Guided ML for Stability Lobe Diagrams (PGML-SLD)\n * - Semi-Discretization Method for Milling Dynamics\n * - Multi-Modal Data Fusion for Chatter Detection\n * - Online SLD Estimation with Continuous Learning\n * - Deep Neural Network Chatter Detection\n * \n * Sources:\n * - arXiv:2511.17894 - ML-based Online SLD Estimation (Nov 2025)\n * - Nature Scientific Reports - Multi-modal Chatter Detection (Jan 2025)\n * - Journal of Intelligent Manufacturing - PGML Stability Modeling (2022)\n * - Mechanical Systems and Signal Processing - Lightweight Deep Learning (2024)\n * \n * @version 1.0.0\n * @date January 18, 2026\n */\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// PHYSICS-INFORMED MACHINE LEARNING CHATTER ENGINE\n// Combines physics-based models with ML for superior accuracy\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nconst PRISM_PIML_CHATTER_ENGINE = {\n  name: 'PRISM_PIML_CHATTER_ENGINE',\n  version: '1.0.0',\n  source: 'arXiv:2511.17894, Nature Sci. Rep. 2025, J. Intell. Manuf. 2022',\n  algorithms: [\n    'Semi-Discretization Method (SDM)',\n    'Physics-Guided ML (PGML)',\n    'Continuous Learning SVM',\n    'Multi-Modal Data Fusion',\n    'ANN-NADAM SLD Prediction',\n    'Online Bayesian SLD Update',\n    'Fractal-Based Feature Extraction'\n  ],\n\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  // SEMI-DISCRETIZATION METHOD FOR MILLING STABILITY\n  // Source: Insperger & St\u00e9p\u00e1n (2002), arXiv:2511.17894\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n  /**\n   * Semi-Discretization Method for stability analysis\n   * Models milling as delay differential equation (DDE)\n   * \u1e8d(t) + 2\u03b6\u03c9\u2099\u1e8b(t) + \u03c9\u2099\u00b2x(t) = (Kc\u00b7ap/m)[x(t-T) - x(t)]\n   * \n   * @param {Object} system - Dynamic system parameters\n   * @param {Object} cutting - Cutting parameters\n   * @param {number} N - Number of discrete intervals per period\n   * @returns {Object} Stability analysis results\n   */\n  semiDiscretization: function(system, cutting, N = 40) {\n    const { mass, stiffness, damping } = system;\n    const { Kc, teeth, radialImmersion } = cutting;\n    \n    const wn = Math.sqrt(stiffness / mass);\n    const zeta = damping / (2 * Math.sqrt(stiffness * mass));\n    \n    // Specific cutting coefficient (averaged)\n    const g = radialImmersion || 1.0; // Radial immersion ratio\n    const h = Kc * g / (2 * Math.PI); // Average directional factor\n    \n    return {\n      /**\n       * Compute stability at given spindle speed and depth\n       */\n      checkStability: function(rpm, ap) {\n        const T = 60 / (rpm * teeth); // Tooth passing period\n        const dt = T / N; // Discrete time step\n        \n        // State transition matrix construction\n        // Using simplified first-order hold approximation\n        const wd = wn * Math.sqrt(1 - zeta * zeta);\n        const exp_term = Math.exp(-zeta * wn * dt);\n        \n        // Monodromy matrix (simplified 2x2 for SDOF)\n        const a11 = exp_term * (Math.cos(wd * dt) + zeta * wn / wd * Math.sin(wd * dt));\n        const a12 = exp_term * Math.sin(wd * dt) / wd;\n        const a21 = -exp_term * wn * wn / wd * Math.sin(wd * dt);\n        const a22 = exp_term * (Math.cos(wd * dt) - zeta * wn / wd * Math.sin(wd * dt));\n        \n        // Include cutting force effect (regenerative)\n        const Kc_term = h * ap / mass;\n        const b11 = Kc_term * (1 - a11);\n        const b21 = Kc_term * (-a21);\n        \n        // Build full monodromy matrix over one period (N steps)\n        // For stability, eigenvalues of monodromy matrix must be < 1\n        \n        // Simplified check: compute eigenvalues of single step matrix\n        const A = [\n          [a11 + b11, a12],\n          [a21 + b21, a22]\n        ];\n        \n        // Eigenvalue computation (2x2 case)\n        const trace = A[0][0] + A[1][1];\n        const det = A[0][0] * A[1][1] - A[0][1] * A[1][0];\n        const disc = trace * trace - 4 * det;\n        \n        let maxEig;\n        if (disc >= 0) {\n          const sqrt_disc = Math.sqrt(disc);\n          maxEig = Math.max(Math.abs((trace + sqrt_disc) / 2), \n                           Math.abs((trace - sqrt_disc) / 2));\n        } else {\n          // Complex eigenvalues\n          maxEig = Math.sqrt(det);\n        }\n        \n        // Stability margin (power raised to N for full period)\n        const periodicMaxEig = Math.pow(maxEig, N);\n        \n        return {\n          stable: periodicMaxEig < 1.0,\n          maxEigenvalue: periodicMaxEig,\n          stabilityMargin: 1.0 - periodicMaxEig,\n          rpm, ap\n        };\n      },\n      \n      /**\n       * Generate stability lobe diagram\n       */\n      generateSLD: function(rpmRange, apRange, resolution = 100) {\n        const [rpmMin, rpmMax] = rpmRange;\n        const [apMin, apMax] = apRange;\n        \n        const sld = {\n          stablePoints: [],\n          unstablePoints: [],\n          boundaryPoints: []\n        };\n        \n        for (let i = 0; i <= resolution; i++) {\n          const rpm = rpmMin + (rpmMax - rpmMin) * i / resolution;\n          \n          // Binary search for stability boundary\n          let low = apMin, high = apMax;\n          while (high - low > (apMax - apMin) / 1000) {\n            const mid = (low + high) / 2;\n            const result = this.checkStability(rpm, mid);\n            if (result.stable) {\n              low = mid;\n            } else {\n              high = mid;\n            }\n          }\n          \n          sld.boundaryPoints.push({ rpm, ap: (low + high) / 2 });\n        }\n        \n        return sld;\n      },\n      \n      params: { wn, zeta, h, teeth }\n    };\n  },\n\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  // PHYSICS-GUIDED MACHINE LEARNING (PGML)\n  // Source: J. Intelligent Manufacturing 2022\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n  /**\n   * PGML model that combines physics-based SLD with neural network\n   * Uses RCSA (Receptance Coupling Substructure Analysis) as physics base\n   * Neural network learns residuals between physics model and reality\n   */\n  pgmlStabilityModel: {\n    name: 'PGML_StabilityModel',\n    \n    /**\n     * Initialize PGML model with physics-based prior\n     */\n    initialize: function(physicsModel, mlConfig = {}) {\n      return {\n        physics: physicsModel,\n        ml: {\n          layers: mlConfig.layers || [32, 16, 8],\n          activation: mlConfig.activation || 'relu',\n          weights: null,\n          biases: null,\n          trained: false\n        },\n        trainingData: [],\n        validationData: []\n      };\n    },\n    \n    /**\n     * Generate synthetic training data from physics model\n     */\n    generatePhysicsData: function(model, rpmRange, apRange, numSamples = 1000) {\n      const data = [];\n      const sdm = PRISM_PIML_CHATTER_ENGINE.semiDiscretization(\n        model.physics.system,\n        model.physics.cutting\n      );\n      \n      for (let i = 0; i < numSamples; i++) {\n        const rpm = rpmRange[0] + Math.random() * (rpmRange[1] - rpmRange[0]);\n        const ap = apRange[0] + Math.random() * (apRange[1] - apRange[0]);\n        \n        const result = sdm.checkStability(rpm, ap);\n        \n        data.push({\n          input: [rpm / 10000, ap / 10], // Normalized inputs\n          output: [result.stable ? 1 : 0],\n          eigenvalue: result.maxEigenvalue\n        });\n      }\n      \n      return data;\n    },\n    \n    /**\n     * Train neural network on combined physics + experimental data\n     * Uses NADAM optimizer for better convergence on SLD lobes\n     */\n    train: function(model, experimentalData = [], options = {}) {\n      const epochs = options.epochs || 100;\n      const batchSize = options.batchSize || 32;\n      const learningRate = options.learningRate || 0.001;\n      \n      // Combine physics-generated and experimental data\n      const physicsData = this.generatePhysicsData(\n        model,\n        options.rpmRange || [1000, 20000],\n        options.apRange || [0.1, 10]\n      );\n      \n      // Weight experimental data higher (physics-informed)\n      const combinedData = [\n        ...physicsData.map(d => ({ ...d, weight: 1 })),\n        ...experimentalData.map(d => ({ ...d, weight: 5 })) // Higher weight for real data\n      ];\n      \n      // Initialize network weights\n      const layers = model.ml.layers;\n      model.ml.weights = [];\n      model.ml.biases = [];\n      \n      let prevSize = 2; // Input: [rpm, ap]\n      for (const layerSize of layers) {\n        model.ml.weights.push(this._initWeights(prevSize, layerSize));\n        model.ml.biases.push(new Array(layerSize).fill(0));\n        prevSize = layerSize;\n      }\n      // Output layer\n      model.ml.weights.push(this._initWeights(prevSize, 1));\n      model.ml.biases.push([0]);\n      \n      // NADAM optimizer state\n      const m = model.ml.weights.map(w => w.map(row => row.map(() => 0)));\n      const v = model.ml.weights.map(w => w.map(row => row.map(() => 0)));\n      const beta1 = 0.9, beta2 = 0.999, eps = 1e-8;\n      \n      // Training loop\n      for (let epoch = 0; epoch < epochs; epoch++) {\n        // Shuffle data\n        this._shuffle(combinedData);\n        \n        let totalLoss = 0;\n        \n        for (let i = 0; i < combinedData.length; i += batchSize) {\n          const batch = combinedData.slice(i, i + batchSize);\n          \n          for (const sample of batch) {\n            // Forward pass\n            const activations = this._forward(model, sample.input);\n            const output = activations[activations.length - 1][0];\n            \n            // Compute loss (weighted binary cross-entropy)\n            const target = sample.output[0];\n            const loss = -sample.weight * (\n              target * Math.log(output + eps) +\n              (1 - target) * Math.log(1 - output + eps)\n            );\n            totalLoss += loss;\n            \n            // Backward pass (simplified gradient computation)\n            const gradOutput = (output - target) * sample.weight;\n            \n            // Update weights using NADAM\n            for (let l = model.ml.weights.length - 1; l >= 0; l--) {\n              const grad = this._computeGradient(activations, l, gradOutput);\n              \n              for (let j = 0; j < model.ml.weights[l].length; j++) {\n                for (let k = 0; k < model.ml.weights[l][j].length; k++) {\n                  // NADAM update\n                  m[l][j][k] = beta1 * m[l][j][k] + (1 - beta1) * grad[j][k];\n                  v[l][j][k] = beta2 * v[l][j][k] + (1 - beta2) * grad[j][k] * grad[j][k];\n                  \n                  const mHat = m[l][j][k] / (1 - Math.pow(beta1, epoch + 1));\n                  const vHat = v[l][j][k] / (1 - Math.pow(beta2, epoch + 1));\n                  \n                  // Nesterov momentum\n                  const mNesterov = beta1 * mHat + (1 - beta1) * grad[j][k] / (1 - Math.pow(beta1, epoch + 1));\n                  \n                  model.ml.weights[l][j][k] -= learningRate * mNesterov / (Math.sqrt(vHat) + eps);\n                }\n              }\n            }\n          }\n        }\n        \n        if (epoch % 10 === 0) {\n          console.log(`[PGML] Epoch ${epoch}, Loss: ${(totalLoss / combinedData.length).toFixed(4)}`);\n        }\n      }\n      \n      model.ml.trained = true;\n      return model;\n    },\n    \n    /**\n     * Predict stability using trained PGML model\n     */\n    predict: function(model, rpm, ap) {\n      if (!model.ml.trained) {\n        throw new Error('PGML model not trained');\n      }\n      \n      const input = [rpm / 10000, ap / 10]; // Normalize\n      const activations = this._forward(model, input);\n      const probability = activations[activations.length - 1][0];\n      \n      return {\n        stable: probability > 0.5,\n        probability,\n        confidence: Math.abs(probability - 0.5) * 2,\n        rpm, ap\n      };\n    },\n    \n    /**\n     * Generate PGML-enhanced SLD\n     */\n    generateSLD: function(model, rpmRange, apRange, resolution = 100) {\n      const sld = {\n        points: [],\n        boundary: []\n      };\n      \n      for (let i = 0; i <= resolution; i++) {\n        const rpm = rpmRange[0] + (rpmRange[1] - rpmRange[0]) * i / resolution;\n        \n        // Binary search for boundary\n        let low = apRange[0], high = apRange[1];\n        while (high - low > 0.01) {\n          const mid = (low + high) / 2;\n          const result = this.predict(model, rpm, mid);\n          if (result.stable) {\n            low = mid;\n          } else {\n            high = mid;\n          }\n        }\n        \n        sld.boundary.push({ rpm, ap: (low + high) / 2 });\n      }\n      \n      return sld;\n    },\n    \n    // Helper functions\n    _initWeights: function(rows, cols) {\n      const weights = [];\n      const scale = Math.sqrt(2 / rows); // He initialization\n      for (let i = 0; i < rows; i++) {\n        weights.push([]);\n        for (let j = 0; j < cols; j++) {\n          weights[i].push((Math.random() - 0.5) * 2 * scale);\n        }\n      }\n      return weights;\n    },\n    \n    _forward: function(model, input) {\n      const activations = [input];\n      let current = input;\n      \n      for (let l = 0; l < model.ml.weights.length; l++) {\n        const W = model.ml.weights[l];\n        const b = model.ml.biases[l];\n        \n        const output = [];\n        for (let j = 0; j < W[0].length; j++) {\n          let sum = b[j];\n          for (let i = 0; i < current.length; i++) {\n            sum += current[i] * W[i][j];\n          }\n          // ReLU for hidden, sigmoid for output\n          if (l < model.ml.weights.length - 1) {\n            output.push(Math.max(0, sum)); // ReLU\n          } else {\n            output.push(1 / (1 + Math.exp(-sum))); // Sigmoid\n          }\n        }\n        activations.push(output);\n        current = output;\n      }\n      \n      return activations;\n    },\n    \n    _computeGradient: function(activations, layer, gradOutput) {\n      const grad = [];\n      const input = activations[layer];\n      \n      for (let i = 0; i < input.length; i++) {\n        grad.push([]);\n        for (let j = 0; j < activations[layer + 1].length; j++) {\n          grad[i].push(gradOutput * input[i]);\n        }\n      }\n      \n      return grad;\n    },\n    \n    _shuffle: function(array) {\n      for (let i = array.length - 1; i > 0; i--) {\n        const j = Math.floor(Math.random() * (i + 1));\n        [array[i], array[j]] = [array[j], array[i]];\n      }\n    }\n  },\n\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  // MULTI-MODAL DATA FUSION FOR CHATTER DETECTION\n  // Source: Nature Scientific Reports 2025\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n  /**\n   * Multi-modal chatter detection using fused sensor data\n   * Combines: vibration, force, current, acoustic signals\n   */\n  multiModalChatterDetector: {\n    name: 'MultiModal_ChatterDetector',\n    \n    /**\n     * Fuse multiple sensor signals with adaptive weighting\n     */\n    fuseSignals: function(signals, weights = null) {\n      const { vibration, force, current, acoustic } = signals;\n      \n      // Default adaptive weights based on signal quality\n      if (!weights) {\n        weights = this._computeAdaptiveWeights(signals);\n      }\n      \n      // Feature extraction from each signal\n      const features = {\n        vibration: vibration ? this._extractFeatures(vibration, 'vibration') : null,\n        force: force ? this._extractFeatures(force, 'force') : null,\n        current: current ? this._extractFeatures(current, 'current') : null,\n        acoustic: acoustic ? this._extractFeatures(acoustic, 'acoustic') : null\n      };\n      \n      // Weighted feature fusion\n      const fusedFeatures = [];\n      const featureTypes = ['rms', 'kurtosis', 'crestFactor', 'spectralCentroid', 'fractalDimension'];\n      \n      for (const fType of featureTypes) {\n        let weightedSum = 0;\n        let totalWeight = 0;\n        \n        for (const [signal, feat] of Object.entries(features)) {\n          if (feat && feat[fType] !== undefined) {\n            weightedSum += feat[fType] * weights[signal];\n            totalWeight += weights[signal];\n          }\n        }\n        \n        fusedFeatures.push(totalWeight > 0 ? weightedSum / totalWeight : 0);\n      }\n      \n      return {\n        features: fusedFeatures,\n        featureNames: featureTypes,\n        weights,\n        individualFeatures: features\n      };\n    },\n    \n    /**\n     * Detect chatter using fused features and hybrid neural network\n     */\n    detectChatter: function(fusedData, model = null) {\n      // Use pre-trained model or simple threshold-based detection\n      if (model && model.trained) {\n        return this._neuralNetworkDetect(fusedData, model);\n      }\n      \n      // Threshold-based detection using physics-informed rules\n      const features = fusedData.features;\n      const [rms, kurtosis, crestFactor, spectralCentroid, fractalDim] = features;\n      \n      // Chatter indicators (from research)\n      const chatterIndicators = {\n        highKurtosis: kurtosis > 4.0,           // Non-Gaussian => chatter\n        highCrestFactor: crestFactor > 5.0,     // Impulsive => chatter\n        frequencyShift: spectralCentroid > 0.3, // Shifted spectrum\n        lowFractal: fractalDim < 1.3            // Less complex signal\n      };\n      \n      const chatterScore = (\n        (chatterIndicators.highKurtosis ? 0.3 : 0) +\n        (chatterIndicators.highCrestFactor ? 0.3 : 0) +\n        (chatterIndicators.frequencyShift ? 0.2 : 0) +\n        (chatterIndicators.lowFractal ? 0.2 : 0)\n      );\n      \n      return {\n        chatterDetected: chatterScore > 0.5,\n        chatterScore,\n        indicators: chatterIndicators,\n        confidence: Math.abs(chatterScore - 0.5) * 2\n      };\n    },\n    \n    /**\n     * Structure Function Method (SFM) for fractal feature extraction\n     * Source: MDPI Sensors 2021\n     */\n    structureFunctionMethod: function(signal, maxOrder = 5) {\n      const n = signal.length;\n      const results = [];\n      \n      for (let order = 1; order <= maxOrder; order++) {\n        // Compute structure function S_q(\u03c4) for different lags\n        const lags = [1, 2, 4, 8, 16, 32];\n        const structureValues = [];\n        \n        for (const tau of lags) {\n          if (tau >= n) continue;\n          \n          let sum = 0;\n          for (let i = 0; i < n - tau; i++) {\n            sum += Math.pow(Math.abs(signal[i + tau] - signal[i]), order);\n          }\n          structureValues.push({\n            tau,\n            value: sum / (n - tau)\n          });\n        }\n        \n        // Estimate Hurst exponent from log-log slope\n        if (structureValues.length >= 2) {\n          const logTau = structureValues.map(s => Math.log(s.tau));\n          const logS = structureValues.map(s => Math.log(s.value + 1e-10));\n          \n          const slope = this._linearRegression(logTau, logS).slope;\n          results.push({\n            order,\n            hurstExponent: slope / order,\n            structureFunction: structureValues\n          });\n        }\n      }\n      \n      // Fractal dimension D = 2 - H (for 1D signal)\n      const avgHurst = results.reduce((sum, r) => sum + r.hurstExponent, 0) / results.length;\n      const fractalDimension = 2 - avgHurst;\n      \n      return {\n        fractalDimension,\n        hurstExponent: avgHurst,\n        structureAnalysis: results\n      };\n    },\n    \n    _extractFeatures: function(signal, type) {\n      const n = signal.length;\n      if (n === 0) return null;\n      \n      // RMS\n      const rms = Math.sqrt(signal.reduce((sum, x) => sum + x * x, 0) / n);\n      \n      // Mean\n      const mean = signal.reduce((sum, x) => sum + x, 0) / n;\n      \n      // Variance and std\n      const variance = signal.reduce((sum, x) => sum + (x - mean) ** 2, 0) / n;\n      const std = Math.sqrt(variance);\n      \n      // Kurtosis (normalized 4th moment)\n      const kurtosis = signal.reduce((sum, x) => sum + Math.pow((x - mean) / std, 4), 0) / n;\n      \n      // Crest factor (peak / RMS)\n      const peak = Math.max(...signal.map(Math.abs));\n      const crestFactor = peak / rms;\n      \n      // Spectral features (simplified - using signal variance as proxy)\n      const spectralCentroid = variance / (rms + 1e-10);\n      \n      // Fractal dimension\n      const fractal = this.structureFunctionMethod(signal);\n      \n      return {\n        rms,\n        mean,\n        std,\n        kurtosis,\n        crestFactor,\n        peak,\n        spectralCentroid,\n        fractalDimension: fractal.fractalDimension\n      };\n    },\n    \n    _computeAdaptiveWeights: function(signals) {\n      const weights = {};\n      let totalQuality = 0;\n      \n      for (const [name, signal] of Object.entries(signals)) {\n        if (signal && signal.length > 0) {\n          // Signal quality based on SNR estimate\n          const mean = signal.reduce((s, x) => s + x, 0) / signal.length;\n          const variance = signal.reduce((s, x) => s + (x - mean) ** 2, 0) / signal.length;\n          const snr = variance > 0 ? Math.abs(mean) / Math.sqrt(variance) : 0;\n          \n          weights[name] = 1 + snr;\n          totalQuality += weights[name];\n        } else {\n          weights[name] = 0;\n        }\n      }\n      \n      // Normalize\n      for (const name of Object.keys(weights)) {\n        weights[name] /= totalQuality || 1;\n      }\n      \n      return weights;\n    },\n    \n    _linearRegression: function(x, y) {\n      const n = x.length;\n      const sumX = x.reduce((a, b) => a + b, 0);\n      const sumY = y.reduce((a, b) => a + b, 0);\n      const sumXY = x.reduce((sum, xi, i) => sum + xi * y[i], 0);\n      const sumXX = x.reduce((sum, xi) => sum + xi * xi, 0);\n      \n      const slope = (n * sumXY - sumX * sumY) / (n * sumXX - sumX * sumX);\n      const intercept = (sumY - slope * sumX) / n;\n      \n      return { slope, intercept };\n    },\n    \n    _neuralNetworkDetect: function(fusedData, model) {\n      // Placeholder for trained neural network inference\n      // In production, this would use the trained PGML model\n      return this.detectChatter(fusedData, null);\n    }\n  },\n\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  // ONLINE CONTINUOUS LEARNING FOR SLD\n  // Source: ScienceDirect - Continuous Learning SVM (2015)\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n  /**\n   * Continuously updating SLD model that learns from production data\n   */\n  continuousLearningSLD: {\n    name: 'ContinuousLearning_SLD',\n    \n    /**\n     * Initialize continuous learning model\n     */\n    initialize: function(baseSLD, trustThreshold = 0.7) {\n      return {\n        baseSLD: baseSLD,\n        observations: [],\n        trust: new Map(), // Region trust scores\n        trustThreshold,\n        updateCount: 0\n      };\n    },\n    \n    /**\n     * Add new observation from production\n     */\n    addObservation: function(model, rpm, ap, stable, confidence = 1.0) {\n      model.observations.push({\n        rpm, ap, stable, confidence,\n        timestamp: Date.now()\n      });\n      \n      // Update local trust\n      const regionKey = `${Math.round(rpm / 500)}_${Math.round(ap * 10)}`;\n      const currentTrust = model.trust.get(regionKey) || 0;\n      model.trust.set(regionKey, Math.min(1, currentTrust + 0.1 * confidence));\n      \n      model.updateCount++;\n      \n      // Trigger retraining if enough new data\n      if (model.updateCount >= 10) {\n        this.retrain(model);\n        model.updateCount = 0;\n      }\n    },\n    \n    /**\n     * Retrain model with accumulated observations\n     * Uses Bayesian update to combine prior (physics) with observations\n     */\n    retrain: function(model) {\n      const recentObs = model.observations.slice(-100); // Last 100 observations\n      \n      if (recentObs.length < 5) return;\n      \n      console.log(`[ContinuousLearning] Retraining with ${recentObs.length} observations`);\n      \n      // Bayesian update of SLD boundary\n      // Prior: base SLD from physics model\n      // Likelihood: from observations\n      \n      // Group observations by RPM region\n      const regionUpdates = new Map();\n      \n      for (const obs of recentObs) {\n        const rpmRegion = Math.round(obs.rpm / 100) * 100;\n        if (!regionUpdates.has(rpmRegion)) {\n          regionUpdates.set(rpmRegion, { stable: [], unstable: [] });\n        }\n        \n        if (obs.stable) {\n          regionUpdates.get(rpmRegion).stable.push(obs.ap);\n        } else {\n          regionUpdates.get(rpmRegion).unstable.push(obs.ap);\n        }\n      }\n      \n      // Update boundary estimates\n      const newBoundary = [];\n      for (const point of model.baseSLD.boundary || model.baseSLD.boundaryPoints) {\n        const rpmRegion = Math.round(point.rpm / 100) * 100;\n        const updates = regionUpdates.get(rpmRegion);\n        \n        if (updates && (updates.stable.length > 0 || updates.unstable.length > 0)) {\n          // Bayesian update\n          const maxStable = Math.max(...updates.stable, 0);\n          const minUnstable = Math.min(...updates.unstable, Infinity);\n          \n          // Posterior estimate (weighted average of prior and observation)\n          const observedBoundary = (maxStable + minUnstable) / 2;\n          const trust = model.trust.get(`${rpmRegion / 500}_${Math.round(point.ap * 10)}`) || 0.5;\n          \n          const posteriorAp = point.ap * (1 - trust) + observedBoundary * trust;\n          \n          newBoundary.push({\n            rpm: point.rpm,\n            ap: posteriorAp,\n            confidence: trust\n          });\n        } else {\n          newBoundary.push({ ...point, confidence: 0.5 });\n        }\n      }\n      \n      model.updatedSLD = { boundary: newBoundary };\n      \n      return model;\n    },\n    \n    /**\n     * Predict stability with trust-weighted prediction\n     */\n    predict: function(model, rpm, ap) {\n      const regionKey = `${Math.round(rpm / 500)}_${Math.round(ap * 10)}`;\n      const trust = model.trust.get(regionKey) || 0.5;\n      \n      // Get boundary at this RPM\n      const sld = model.updatedSLD || model.baseSLD;\n      let boundary = null;\n      \n      for (let i = 0; i < sld.boundary.length - 1; i++) {\n        const p1 = sld.boundary[i];\n        const p2 = sld.boundary[i + 1];\n        \n        if (rpm >= p1.rpm && rpm <= p2.rpm) {\n          const t = (rpm - p1.rpm) / (p2.rpm - p1.rpm);\n          boundary = p1.ap + t * (p2.ap - p1.ap);\n          break;\n        }\n      }\n      \n      if (boundary === null) {\n        boundary = sld.boundary[0].ap;\n      }\n      \n      return {\n        stable: ap < boundary,\n        boundaryAp: boundary,\n        margin: boundary - ap,\n        trustScore: trust,\n        reliable: trust >= model.trustThreshold\n      };\n    }\n  },\n\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  // SELF-TEST\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n  selfTest: function() {\n    const results = [];\n    \n    // Test 1: Semi-discretization method\n    const system = { mass: 0.1, stiffness: 1e7, damping: 100 };\n    const cutting = { Kc: 1500e6, teeth: 4, radialImmersion: 0.5 };\n    const sdm = this.semiDiscretization(system, cutting);\n    \n    const stabilityResult = sdm.checkStability(10000, 2);\n    results.push({\n      name: 'Semi-Discretization Method',\n      passed: typeof stabilityResult.stable === 'boolean',\n      details: `RPM=10000, ap=2mm, stable=${stabilityResult.stable}`\n    });\n    \n    // Test 2: PGML initialization\n    const pgmlModel = this.pgmlStabilityModel.initialize(\n      { system, cutting },\n      { layers: [16, 8] }\n    );\n    results.push({\n      name: 'PGML Model Initialization',\n      passed: pgmlModel !== null && pgmlModel.physics !== null,\n      details: 'Model initialized with physics base'\n    });\n    \n    // Test 3: Multi-modal feature extraction\n    const testSignal = Array.from({ length: 1000 }, () => Math.random() - 0.5);\n    const fusedData = this.multiModalChatterDetector.fuseSignals({\n      vibration: testSignal,\n      force: null\n    });\n    results.push({\n      name: 'Multi-Modal Feature Extraction',\n      passed: fusedData.features.length === 5,\n      details: `Extracted ${fusedData.features.length} fused features`\n    });\n    \n    // Test 4: Fractal dimension computation\n    const fractal = this.multiModalChatterDetector.structureFunctionMethod(testSignal);\n    results.push({\n      name: 'Fractal Dimension (SFM)',\n      passed: fractal.fractalDimension > 0 && fractal.fractalDimension < 3,\n      details: `D = ${fractal.fractalDimension.toFixed(3)}`\n    });\n    \n    // Test 5: Continuous learning SLD\n    const baseSLD = sdm.generateSLD([5000, 15000], [0.5, 5], 20);\n    const clModel = this.continuousLearningSLD.initialize(baseSLD);\n    this.continuousLearningSLD.addObservation(clModel, 10000, 3, true, 0.9);\n    results.push({\n      name: 'Continuous Learning SLD',\n      passed: clModel.observations.length === 1,\n      details: 'Observation added and model updated'\n    });\n    \n    console.log('[PRISM_PIML_CHATTER_ENGINE] Self-test results:');\n    results.forEach(r => {\n      console.log(`  ${r.passed ? '\u2713' : '\u2717'} ${r.name}: ${r.details}`);\n    });\n    \n    return {\n      passed: results.every(r => r.passed),\n      results\n    };\n  }\n};\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// GATEWAY ROUTE REGISTRATION\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nconst SESSION4_PIML_ROUTES = {\n  // Semi-Discretization\n  'piml.sdm.create': 'PRISM_PIML_CHATTER_ENGINE.semiDiscretization',\n  \n  // PGML\n  'piml.pgml.initialize': 'PRISM_PIML_CHATTER_ENGINE.pgmlStabilityModel.initialize',\n  'piml.pgml.train': 'PRISM_PIML_CHATTER_ENGINE.pgmlStabilityModel.train',\n  'piml.pgml.predict': 'PRISM_PIML_CHATTER_ENGINE.pgmlStabilityModel.predict',\n  'piml.pgml.generateSLD': 'PRISM_PIML_CHATTER_ENGINE.pgmlStabilityModel.generateSLD',\n  \n  // Multi-Modal\n  'piml.multimodal.fuse': 'PRISM_PIML_CHATTER_ENGINE.multiModalChatterDetector.fuseSignals',\n  'piml.multimodal.detect': 'PRISM_PIML_CHATTER_ENGINE.multiModalChatterDetector.detectChatter',\n  'piml.multimodal.fractal': 'PRISM_PIML_CHATTER_ENGINE.multiModalChatterDetector.structureFunctionMethod',\n  \n  // Continuous Learning\n  'piml.continuous.initialize': 'PRISM_PIML_CHATTER_ENGINE.continuousLearningSLD.initialize',\n  'piml.continuous.addObservation': 'PRISM_PIML_CHATTER_ENGINE.continuousLearningSLD.addObservation',\n  'piml.continuous.predict': 'PRISM_PIML_CHATTER_ENGINE.continuousLearningSLD.predict',\n  'piml.continuous.retrain': 'PRISM_PIML_CHATTER_ENGINE.continuousLearningSLD.retrain',\n  \n  // Test\n  'piml.test': 'PRISM_PIML_CHATTER_ENGINE.selfTest'\n};\n\n// Registration function\nfunction registerSession4PIML() {\n  if (typeof PRISM_GATEWAY !== 'undefined') {\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// PRISM PHASE 1 - 220 COURSES UTILIZATION INTEGRATION\n// Added: v8.87.001 - January 18, 2026\n// 30 algorithms | 28 gateway routes | AI-enhanced Speed & Feed Calculator\n// Sources: MIT 15.099, MIT 18.433, MIT 6.036, MIT 18.086, MIT 2.008, MIT 2.830\n// Stanford CS229, Berkeley EE123, CMU 24-785\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n/**\n * \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n * PRISM PHASE 1 - COURSES UTILIZATION INTEGRATION\n * \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n * \n * Version: 1.0.0\n * Date: January 18, 2026\n * Build Target: v8.87.001\n * \n * PURPOSE: Integrate 30 Phase 1 algorithms from 220 university courses into PRISM\n * \n * PHASE 1 ALGORITHMS (30):\n * \u251c\u2500\u2500 Optimization: PSO, ACO, Genetic Algorithm\n * \u251c\u2500\u2500 Machine Learning: Linear Regression, Random Forest\n * \u251c\u2500\u2500 Signal Processing: FFT, Butterworth Filter\n * \u251c\u2500\u2500 Manufacturing: Taylor Tool Life, Merchant Force, Stability Lobes\n * \u2514\u2500\u2500 Additional: Newton, BFGS, K-Means, Kalman Filter\n * \n * PROTOCOLS FOLLOWED (v12.0):\n * \u251c\u2500\u2500 Protocol A: Gateway-First Development\n * \u251c\u2500\u2500 Protocol B: Unit-Safe Development  \n * \u251c\u2500\u2500 Protocol C: Compare-Safe Development\n * \u251c\u2500\u2500 Protocol E: Constants-First Development\n * \u251c\u2500\u2500 Protocol F: Validation-First Development\n * \u251c\u2500\u2500 Protocol J: Innovation-First Development\n * \u251c\u2500\u2500 Protocol K: Knowledge-First Development\n * \u251c\u2500\u2500 Protocol O: AI-First Development\n * \u2514\u2500\u2500 Protocol P: Learning-First Development\n * \n * SOURCES:\n * \u251c\u2500\u2500 MIT 15.099: PSO, Optimization\n * \u251c\u2500\u2500 MIT 18.433: ACO, Combinatorial Optimization\n * \u251c\u2500\u2500 MIT 6.036: Linear Regression, ML Fundamentals\n * \u251c\u2500\u2500 MIT 18.086: FFT, Signal Processing\n * \u251c\u2500\u2500 MIT 2.008: Taylor Tool Life, Merchant Force\n * \u251c\u2500\u2500 MIT 2.830: Stability Lobes, Chatter Analysis\n * \u251c\u2500\u2500 Stanford CS229: Random Forest, ML\n * \u251c\u2500\u2500 Berkeley EE123: Butterworth Filter, Signal Processing\n * \u2514\u2500\u2500 CMU 24-785: Genetic Algorithm\n * \n * \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n */\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// PHASE 1 MASTER COORDINATOR\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nconst PRISM_PHASE1_COORDINATOR = {\n    version: '1.0.0',\n    phase: 1,\n    name: 'Immediate Integration',\n    targetUtilization: 100,\n    algorithmsIntegrated: 0,\n    totalAlgorithms: 30,\n    \n    status: {\n        initialized: false,\n        gatewayRoutesRegistered: 0,\n        calculatorIntegrated: false,\n        chatterDetectionConnected: false,\n        toolLifeLinked: false,\n        learningPipelineActive: false\n    },\n    \n    /**\n     * Initialize Phase 1 Integration\n     * Protocol A: All calls through PRISM_GATEWAY\n     */\n    initialize: function() {\n        console.log('\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557');\n        console.log('\u2551  PRISM Phase 1 - 220 Courses Utilization Integration            \u2551');\n        console.log('\u2551  Target: 30 algorithms at 100% utilization                      \u2551');\n        console.log('\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d');\n        \n        // Step 1: Register all Phase 1 gateway routes\n        const routeResult = PRISM_PHASE1_GATEWAY_ROUTES.registerAll();\n        this.status.gatewayRoutesRegistered = routeResult.registered;\n        \n        // Step 2: Initialize AI-enhanced calculator\n        if (typeof PRISM_PHASE1_SPEED_FEED_CALCULATOR !== 'undefined') {\n            PRISM_PHASE1_SPEED_FEED_CALCULATOR.initialize();\n            this.status.calculatorIntegrated = true;\n        }\n        \n        // Step 3: Connect chatter detection system\n        if (typeof PRISM_PHASE1_CHATTER_SYSTEM !== 'undefined') {\n            PRISM_PHASE1_CHATTER_SYSTEM.initialize();\n            this.status.chatterDetectionConnected = true;\n        }\n        \n        // Step 4: Link tool life management\n        if (typeof PRISM_PHASE1_TOOL_LIFE_MANAGER !== 'undefined') {\n            PRISM_PHASE1_TOOL_LIFE_MANAGER.initialize();\n            this.status.toolLifeLinked = true;\n        }\n        \n        // Step 5: Activate learning pipeline\n        if (typeof PRISM_AI_LEARNING_PIPELINE !== 'undefined') {\n            this.status.learningPipelineActive = true;\n        }\n        \n        this.status.initialized = true;\n        this.algorithmsIntegrated = this._countIntegratedAlgorithms();\n        \n        console.log(`[Phase 1] Initialized: ${this.algorithmsIntegrated}/${this.totalAlgorithms} algorithms`);\n        console.log(`[Phase 1] Gateway routes: ${this.status.gatewayRoutesRegistered}`);\n        \n        return {\n            success: true,\n            algorithmsIntegrated: this.algorithmsIntegrated,\n            gatewayRoutes: this.status.gatewayRoutesRegistered,\n            status: this.status\n        };\n    },\n    \n    _countIntegratedAlgorithms: function() {\n        let count = 0;\n        const algorithms = [\n            'opt.pso', 'opt.aco', 'opt.genetic', 'opt.newton', 'opt.bfgs',\n            'ml.linear_regression', 'ml.random_forest', 'ml.kmeans',\n            'signal.fft', 'signal.butterworth', 'signal.stability_lobes',\n            'mfg.taylor_tool_life', 'mfg.merchant_force', 'mfg.mrr',\n            'ai.kalman.predict', 'physics.cutting_force', 'physics.tool_life'\n        ];\n        \n        if (typeof PRISM_GATEWAY !== 'undefined') {\n            algorithms.forEach(route => {\n                if (PRISM_GATEWAY.routes && PRISM_GATEWAY.routes[route]) {\n                    count++;\n                }\n            });\n        }\n        return count;\n    },\n    \n    /**\n     * Get Phase 1 status report\n     */\n    getStatus: function() {\n        return {\n            phase: this.phase,\n            name: this.name,\n            version: this.version,\n            progress: `${this.algorithmsIntegrated}/${this.totalAlgorithms}`,\n            utilization: Math.round((this.algorithmsIntegrated / this.totalAlgorithms) * 100) + '%',\n            status: this.status,\n            targetUtilization: this.targetUtilization + '%'\n        };\n    }\n};\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// PHASE 1 GATEWAY ROUTES REGISTRATION\n// Protocol A: Gateway-First Development\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nconst PRISM_PHASE1_GATEWAY_ROUTES = {\n    routes: {\n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        // OPTIMIZATION ALGORITHMS (MIT 15.099, MIT 18.433, CMU 24-785)\n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        'phase1.pso.speed_feed': 'PRISM_PHASE1_OPTIMIZERS.psoSpeedFeed',\n        'phase1.pso.multi_objective': 'PRISM_PHASE1_OPTIMIZERS.psoMultiObjective',\n        'phase1.aco.hole_sequence': 'PRISM_PHASE1_OPTIMIZERS.acoHoleSequence',\n        'phase1.aco.routing': 'PRISM_PHASE1_OPTIMIZERS.acoRouting',\n        'phase1.genetic.toolpath': 'PRISM_PHASE1_OPTIMIZERS.geneticToolpath',\n        'phase1.genetic.parameters': 'PRISM_PHASE1_OPTIMIZERS.geneticParameters',\n        'phase1.newton.optimize': 'PRISM_PHASE1_OPTIMIZERS.newtonOptimize',\n        'phase1.bfgs.optimize': 'PRISM_PHASE1_OPTIMIZERS.bfgsOptimize',\n        \n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        // MACHINE LEARNING (MIT 6.036, Stanford CS229)\n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        'phase1.ml.linear_predict': 'PRISM_PHASE1_ML.linearPredict',\n        'phase1.ml.ridge_predict': 'PRISM_PHASE1_ML.ridgePredict',\n        'phase1.ml.forest_predict': 'PRISM_PHASE1_ML.randomForestPredict',\n        'phase1.ml.forest_tool_life': 'PRISM_PHASE1_ML.forestToolLifePredict',\n        'phase1.ml.kmeans_cluster': 'PRISM_PHASE1_ML.kmeansCluster',\n        \n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        // SIGNAL PROCESSING (MIT 18.086, Berkeley EE123)\n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        'phase1.signal.fft_analyze': 'PRISM_PHASE1_SIGNAL.fftAnalyze',\n        'phase1.signal.fft_chatter': 'PRISM_PHASE1_SIGNAL.fftChatterDetect',\n        'phase1.signal.butterworth': 'PRISM_PHASE1_SIGNAL.butterworthFilter',\n        'phase1.signal.stability_lobes': 'PRISM_PHASE1_SIGNAL.stabilityLobes',\n        'phase1.signal.spectral_density': 'PRISM_PHASE1_SIGNAL.spectralDensity',\n        \n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        // MANUFACTURING PHYSICS (MIT 2.008, MIT 2.830)\n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        'phase1.mfg.taylor_tool_life': 'PRISM_PHASE1_MANUFACTURING.taylorToolLife',\n        'phase1.mfg.extended_taylor': 'PRISM_PHASE1_MANUFACTURING.extendedTaylor',\n        'phase1.mfg.merchant_force': 'PRISM_PHASE1_MANUFACTURING.merchantForce',\n        'phase1.mfg.kienzle_force': 'PRISM_PHASE1_MANUFACTURING.kienzleForce',\n        'phase1.mfg.mrr': 'PRISM_PHASE1_MANUFACTURING.materialRemovalRate',\n        'phase1.mfg.surface_finish': 'PRISM_PHASE1_MANUFACTURING.surfaceFinish',\n        'phase1.mfg.cutting_temperature': 'PRISM_PHASE1_MANUFACTURING.cuttingTemperature',\n        \n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        // INTEGRATED AI CALCULATOR\n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        'phase1.calc.speed_feed': 'PRISM_PHASE1_SPEED_FEED_CALCULATOR.calculate',\n        'phase1.calc.ai_optimize': 'PRISM_PHASE1_SPEED_FEED_CALCULATOR.aiOptimize',\n        'phase1.calc.full_analysis': 'PRISM_PHASE1_SPEED_FEED_CALCULATOR.fullAnalysis'\n    },\n    \n    registerAll: function() {\n        let registered = 0;\n        let failed = 0;\n        \n        if (typeof PRISM_GATEWAY === 'undefined') {\n            console.error('[Phase 1] PRISM_GATEWAY not found');\n            return { registered: 0, failed: Object.keys(this.routes).length };\n        }\n        \n        for (const [route, target] of Object.entries(this.routes)) {\n            try {\n                PRISM_GATEWAY.register(route, target);\n                registered++;\n            } catch (e) {\n                console.warn(`[Phase 1] Failed to register route: ${route}`);\n                failed++;\n            }\n        }\n        \n        console.log(`[Phase 1 Routes] Registered: ${registered}, Failed: ${failed}`);\n        return { registered, failed };\n    }\n};\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// PHASE 1 OPTIMIZATION ALGORITHMS\n// Sources: MIT 15.099, MIT 18.433, CMU 24-785\n// Protocol J: Innovation-First Development\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nconst PRISM_PHASE1_OPTIMIZERS = {\n    name: 'Phase 1 Optimization Algorithms',\n    version: '1.0.0',\n    source: 'MIT 15.099, MIT 18.433, CMU 24-785',\n    \n    /**\n     * PSO Speed/Feed Multi-Objective Optimization\n     * Source: MIT 15.099 - Introduction to Optimization\n     * Protocol B: Unit-Safe Development (metric internal)\n     */\n    psoSpeedFeed: function(params) {\n        const {\n            material,\n            tool,\n            machine,\n            objectives = ['productivity', 'tool_life', 'surface_finish'],\n            constraints = {}\n        } = params;\n        \n        // Protocol E: Constants-First Development\n        const PSO_CONFIG = {\n            particles: typeof PRISM_CONSTANTS !== 'undefined' ? \n                PRISM_CONSTANTS.AI.PSO_MAX_PARTICLES : 30,\n            iterations: typeof PRISM_CONSTANTS !== 'undefined' ? \n                PRISM_CONSTANTS.AI.PSO_MAX_ITERATIONS : 100,\n            w: 0.729,      // Inertia weight\n            c1: 1.49445,   // Cognitive parameter\n            c2: 1.49445    // Social parameter\n        };\n        \n        // Define search bounds (metric internal - Protocol B)\n        const bounds = {\n            speed: { min: 50, max: 500 },      // m/min\n            feed: { min: 0.05, max: 0.5 },     // mm/tooth\n            doc: { min: 0.5, max: 10 }         // mm\n        };\n        \n        // Apply material constraints\n        if (material && material.speedRange) {\n            bounds.speed.min = Math.max(bounds.speed.min, material.speedRange.min || 50);\n            bounds.speed.max = Math.min(bounds.speed.max, material.speedRange.max || 500);\n        }\n        \n        // Initialize particles\n        const particles = [];\n        for (let i = 0; i < PSO_CONFIG.particles; i++) {\n            particles.push({\n                position: {\n                    speed: bounds.speed.min + Math.random() * (bounds.speed.max - bounds.speed.min),\n                    feed: bounds.feed.min + Math.random() * (bounds.feed.max - bounds.feed.min),\n                    doc: bounds.doc.min + Math.random() * (bounds.doc.max - bounds.doc.min)\n                },\n                velocity: { speed: 0, feed: 0, doc: 0 },\n                bestPosition: null,\n                bestFitness: -Infinity\n            });\n            particles[i].bestPosition = { ...particles[i].position };\n        }\n        \n        let globalBest = { position: null, fitness: -Infinity };\n        \n        // PSO main loop\n        for (let iter = 0; iter < PSO_CONFIG.iterations; iter++) {\n            for (const particle of particles) {\n                // Evaluate fitness (multi-objective)\n                const fitness = this._evaluateSpeedFeedFitness(\n                    particle.position, material, tool, machine, objectives\n                );\n                \n                // Update personal best\n                if (fitness > particle.bestFitness) {\n                    particle.bestFitness = fitness;\n                    particle.bestPosition = { ...particle.position };\n                }\n                \n                // Update global best\n                if (fitness > globalBest.fitness) {\n                    globalBest.fitness = fitness;\n                    globalBest.position = { ...particle.position };\n                }\n            }\n            \n            // Update velocities and positions\n            for (const particle of particles) {\n                for (const dim of ['speed', 'feed', 'doc']) {\n                    const r1 = Math.random();\n                    const r2 = Math.random();\n                    \n                    particle.velocity[dim] = \n                        PSO_CONFIG.w * particle.velocity[dim] +\n                        PSO_CONFIG.c1 * r1 * (particle.bestPosition[dim] - particle.position[dim]) +\n                        PSO_CONFIG.c2 * r2 * (globalBest.position[dim] - particle.position[dim]);\n                    \n                    particle.position[dim] += particle.velocity[dim];\n                    \n                    // Clamp to bounds\n                    particle.position[dim] = Math.max(bounds[dim].min, \n                        Math.min(bounds[dim].max, particle.position[dim]));\n                }\n            }\n        }\n        \n        // Return optimized parameters with confidence\n        return {\n            optimizedParams: globalBest.position,\n            fitness: globalBest.fitness,\n            objectives: objectives,\n            source: 'MIT 15.099 - PSO Multi-Objective',\n            confidence: Math.min(0.95, 0.7 + globalBest.fitness * 0.25),\n            iterations: PSO_CONFIG.iterations,\n            particles: PSO_CONFIG.particles\n        };\n    },\n    \n    /**\n     * Evaluate fitness for speed/feed optimization\n     * Protocol O: AI-First Development\n     */\n    _evaluateSpeedFeedFitness: function(position, material, tool, machine, objectives) {\n        let fitness = 0;\n        const weights = {\n            productivity: 0.4,\n            tool_life: 0.35,\n            surface_finish: 0.25\n        };\n        \n        // Calculate MRR (productivity)\n        const mrr = position.speed * position.feed * position.doc;\n        const mrrNormalized = mrr / 100; // Normalize\n        \n        // Estimate tool life using Taylor equation\n        const toolLife = this._estimateToolLife(position.speed, material);\n        const toolLifeNormalized = Math.min(1, toolLife / 120); // Normalize to 120 min baseline\n        \n        // Estimate surface finish (lower is better)\n        const surfaceFinish = this._estimateSurfaceFinish(position.feed, tool);\n        const surfaceFinishNormalized = 1 - Math.min(1, surfaceFinish / 3.2); // Normalize to Ra 3.2\n        \n        // Weight objectives\n        if (objectives.includes('productivity')) {\n            fitness += weights.productivity * mrrNormalized;\n        }\n        if (objectives.includes('tool_life')) {\n            fitness += weights.tool_life * toolLifeNormalized;\n        }\n        if (objectives.includes('surface_finish')) {\n            fitness += weights.surface_finish * surfaceFinishNormalized;\n        }\n        \n        return fitness;\n    },\n    \n    _estimateToolLife: function(speed, material) {\n        // Taylor's equation: VT^n = C\n        const n = material?.taylorN || 0.25;\n        const C = material?.taylorC || 300;\n        return Math.pow(C / speed, 1 / n);\n    },\n    \n    _estimateSurfaceFinish: function(feed, tool) {\n        // Ra \u2248 f\u00b2 / (32 * r) for theoretical surface finish\n        const noseRadius = tool?.noseRadius || 0.8; // mm\n        return (feed * feed) / (32 * noseRadius) * 1000; // Convert to \u03bcm\n    },\n    \n    /**\n     * PSO Multi-Objective Generic Optimizer\n     */\n    psoMultiObjective: function(objectiveFunc, bounds, options = {}) {\n        const config = {\n            particles: options.particles || 30,\n            iterations: options.iterations || 100,\n            w: options.w || 0.729,\n            c1: options.c1 || 1.49445,\n            c2: options.c2 || 1.49445\n        };\n        \n        const dimensions = Object.keys(bounds);\n        const particles = [];\n        \n        // Initialize\n        for (let i = 0; i < config.particles; i++) {\n            const position = {};\n            const velocity = {};\n            for (const dim of dimensions) {\n                position[dim] = bounds[dim].min + Math.random() * (bounds[dim].max - bounds[dim].min);\n                velocity[dim] = 0;\n            }\n            particles.push({\n                position,\n                velocity,\n                bestPosition: { ...position },\n                bestFitness: -Infinity\n            });\n        }\n        \n        let globalBest = { position: null, fitness: -Infinity };\n        \n        // Main loop\n        for (let iter = 0; iter < config.iterations; iter++) {\n            for (const particle of particles) {\n                const fitness = objectiveFunc(particle.position);\n                \n                if (fitness > particle.bestFitness) {\n                    particle.bestFitness = fitness;\n                    particle.bestPosition = { ...particle.position };\n                }\n                \n                if (fitness > globalBest.fitness) {\n                    globalBest.fitness = fitness;\n                    globalBest.position = { ...particle.position };\n                }\n            }\n            \n            for (const particle of particles) {\n                for (const dim of dimensions) {\n                    const r1 = Math.random();\n                    const r2 = Math.random();\n                    \n                    particle.velocity[dim] = \n                        config.w * particle.velocity[dim] +\n                        config.c1 * r1 * (particle.bestPosition[dim] - particle.position[dim]) +\n                        config.c2 * r2 * (globalBest.position[dim] - particle.position[dim]);\n                    \n                    particle.position[dim] = Math.max(bounds[dim].min,\n                        Math.min(bounds[dim].max, particle.position[dim] + particle.velocity[dim]));\n                }\n            }\n        }\n        \n        return {\n            optimal: globalBest.position,\n            fitness: globalBest.fitness,\n            iterations: config.iterations,\n            source: 'MIT 15.099 - PSO'\n        };\n    },\n    \n    /**\n     * ACO Hole Sequence Optimization\n     * Source: MIT 18.433 - Combinatorial Optimization\n     */\n    acoHoleSequence: function(holes, options = {}) {\n        const config = {\n            ants: options.ants || 20,\n            iterations: options.iterations || 50,\n            alpha: options.alpha || 1.0,      // Pheromone importance\n            beta: options.beta || 2.0,        // Distance importance\n            rho: options.rho || 0.1,          // Evaporation rate\n            Q: options.Q || 100               // Pheromone deposit factor\n        };\n        \n        const n = holes.length;\n        if (n < 2) return { sequence: holes.map((_, i) => i), distance: 0 };\n        \n        // Calculate distance matrix\n        const dist = [];\n        for (let i = 0; i < n; i++) {\n            dist[i] = [];\n            for (let j = 0; j < n; j++) {\n                if (i === j) {\n                    dist[i][j] = Infinity;\n                } else {\n                    const dx = holes[i].x - holes[j].x;\n                    const dy = holes[i].y - holes[j].y;\n                    const dz = (holes[i].z || 0) - (holes[j].z || 0);\n                    dist[i][j] = Math.sqrt(dx*dx + dy*dy + dz*dz);\n                }\n            }\n        }\n        \n        // Initialize pheromone matrix\n        const tau = [];\n        const tau0 = 1 / (n * this._nearestNeighborDistance(holes, dist));\n        for (let i = 0; i < n; i++) {\n            tau[i] = [];\n            for (let j = 0; j < n; j++) {\n                tau[i][j] = tau0;\n            }\n        }\n        \n        let bestSequence = null;\n        let bestDistance = Infinity;\n        \n        // Main ACO loop\n        for (let iter = 0; iter < config.iterations; iter++) {\n            const antSolutions = [];\n            \n            // Each ant constructs a solution\n            for (let ant = 0; ant < config.ants; ant++) {\n                const visited = new Set();\n                const sequence = [];\n                \n                // Start from random hole\n                let current = Math.floor(Math.random() * n);\n                sequence.push(current);\n                visited.add(current);\n                \n                // Visit remaining holes\n                while (sequence.length < n) {\n                    const probabilities = [];\n                    let totalProb = 0;\n                    \n                    for (let j = 0; j < n; j++) {\n                        if (!visited.has(j)) {\n                            const tauVal = Math.pow(tau[current][j], config.alpha);\n                            const etaVal = Math.pow(1 / dist[current][j], config.beta);\n                            probabilities[j] = tauVal * etaVal;\n                            totalProb += probabilities[j];\n                        } else {\n                            probabilities[j] = 0;\n                        }\n                    }\n                    \n                    // Roulette wheel selection\n                    let r = Math.random() * totalProb;\n                    let next = -1;\n                    for (let j = 0; j < n; j++) {\n                        if (probabilities[j] > 0) {\n                            r -= probabilities[j];\n                            if (r <= 0) {\n                                next = j;\n                                break;\n                            }\n                        }\n                    }\n                    \n                    if (next === -1) {\n                        // Fallback: pick first unvisited\n                        for (let j = 0; j < n; j++) {\n                            if (!visited.has(j)) {\n                                next = j;\n                                break;\n                            }\n                        }\n                    }\n                    \n                    sequence.push(next);\n                    visited.add(next);\n                    current = next;\n                }\n                \n                // Calculate total distance\n                let totalDist = 0;\n                for (let i = 0; i < sequence.length - 1; i++) {\n                    totalDist += dist[sequence[i]][sequence[i + 1]];\n                }\n                \n                antSolutions.push({ sequence, distance: totalDist });\n                \n                if (totalDist < bestDistance) {\n                    bestDistance = totalDist;\n                    bestSequence = [...sequence];\n                }\n            }\n            \n            // Evaporate pheromones\n            for (let i = 0; i < n; i++) {\n                for (let j = 0; j < n; j++) {\n                    tau[i][j] *= (1 - config.rho);\n                }\n            }\n            \n            // Deposit pheromones\n            for (const sol of antSolutions) {\n                const deposit = config.Q / sol.distance;\n                for (let i = 0; i < sol.sequence.length - 1; i++) {\n                    const from = sol.sequence[i];\n                    const to = sol.sequence[i + 1];\n                    tau[from][to] += deposit;\n                    tau[to][from] += deposit;\n                }\n            }\n        }\n        \n        return {\n            sequence: bestSequence,\n            distance: bestDistance,\n            improvement: ((this._nearestNeighborDistance(holes, dist) - bestDistance) / \n                this._nearestNeighborDistance(holes, dist) * 100).toFixed(1) + '%',\n            source: 'MIT 18.433 - ACO'\n        };\n    },\n    \n    _nearestNeighborDistance: function(holes, dist) {\n        const n = holes.length;\n        if (n < 2) return 0;\n        \n        const visited = new Set([0]);\n        let current = 0;\n        let totalDist = 0;\n        \n        while (visited.size < n) {\n            let nearest = -1;\n            let nearestDist = Infinity;\n            \n            for (let j = 0; j < n; j++) {\n                if (!visited.has(j) && dist[current][j] < nearestDist) {\n                    nearest = j;\n                    nearestDist = dist[current][j];\n                }\n            }\n            \n            if (nearest !== -1) {\n                totalDist += nearestDist;\n                visited.add(nearest);\n                current = nearest;\n            }\n        }\n        \n        return totalDist;\n    },\n    \n    /**\n     * ACO General Routing Optimization\n     */\n    acoRouting: function(nodes, edges, options = {}) {\n        // Wrapper for general graph routing\n        return this.acoHoleSequence(nodes, options);\n    },\n    \n    /**\n     * Genetic Algorithm for Toolpath Optimization\n     * Source: CMU 24-785 - Engineering Optimization\n     */\n    geneticToolpath: function(toolpathPoints, options = {}) {\n        const config = {\n            populationSize: options.populationSize || 50,\n            generations: options.generations || 100,\n            crossoverRate: options.crossoverRate || 0.8,\n            mutationRate: options.mutationRate || 0.1,\n            elitismRate: options.elitismRate || 0.1\n        };\n        \n        const n = toolpathPoints.length;\n        if (n < 3) return { sequence: toolpathPoints.map((_, i) => i), fitness: 0 };\n        \n        // Initialize population\n        let population = [];\n        for (let i = 0; i < config.populationSize; i++) {\n            const individual = this._shuffleArray([...Array(n).keys()]);\n            const fitness = this._evaluateToolpathFitness(individual, toolpathPoints);\n            population.push({ sequence: individual, fitness });\n        }\n        \n        // Sort by fitness (descending)\n        population.sort((a, b) => b.fitness - a.fitness);\n        \n        // Evolution loop\n        for (let gen = 0; gen < config.generations; gen++) {\n            const newPopulation = [];\n            \n            // Elitism\n            const eliteCount = Math.floor(config.populationSize * config.elitismRate);\n            for (let i = 0; i < eliteCount; i++) {\n                newPopulation.push({ ...population[i] });\n            }\n            \n            // Crossover and mutation\n            while (newPopulation.length < config.populationSize) {\n                // Tournament selection\n                const parent1 = this._tournamentSelect(population, 3);\n                const parent2 = this._tournamentSelect(population, 3);\n                \n                let child;\n                if (Math.random() < config.crossoverRate) {\n                    child = this._orderCrossover(parent1.sequence, parent2.sequence);\n                } else {\n                    child = [...parent1.sequence];\n                }\n                \n                // Mutation\n                if (Math.random() < config.mutationRate) {\n                    this._swapMutation(child);\n                }\n                \n                const fitness = this._evaluateToolpathFitness(child, toolpathPoints);\n                newPopulation.push({ sequence: child, fitness });\n            }\n            \n            population = newPopulation;\n            population.sort((a, b) => b.fitness - a.fitness);\n        }\n        \n        return {\n            sequence: population[0].sequence,\n            fitness: population[0].fitness,\n            generations: config.generations,\n            source: 'CMU 24-785 - Genetic Algorithm'\n        };\n    },\n    \n    _shuffleArray: function(array) {\n        for (let i = array.length - 1; i > 0; i--) {\n            const j = Math.floor(Math.random() * (i + 1));\n            [array[i], array[j]] = [array[j], array[i]];\n        }\n        return array;\n    },\n    \n    _evaluateToolpathFitness: function(sequence, points) {\n        let totalDist = 0;\n        for (let i = 0; i < sequence.length - 1; i++) {\n            const p1 = points[sequence[i]];\n            const p2 = points[sequence[i + 1]];\n            const dx = p1.x - p2.x;\n            const dy = p1.y - p2.y;\n            const dz = (p1.z || 0) - (p2.z || 0);\n            totalDist += Math.sqrt(dx*dx + dy*dy + dz*dz);\n        }\n        return totalDist > 0 ? 1000 / totalDist : 0; // Fitness inversely proportional to distance\n    },\n    \n    _tournamentSelect: function(population, tournamentSize) {\n        let best = null;\n        for (let i = 0; i < tournamentSize; i++) {\n            const candidate = population[Math.floor(Math.random() * population.length)];\n            if (!best || candidate.fitness > best.fitness) {\n                best = candidate;\n            }\n        }\n        return best;\n    },\n    \n    _orderCrossover: function(parent1, parent2) {\n        const n = parent1.length;\n        const start = Math.floor(Math.random() * n);\n        const end = start + Math.floor(Math.random() * (n - start));\n        \n        const child = new Array(n).fill(-1);\n        \n        // Copy segment from parent1\n        for (let i = start; i <= end; i++) {\n            child[i] = parent1[i];\n        }\n        \n        // Fill remaining from parent2\n        let j = (end + 1) % n;\n        for (let i = 0; i < n; i++) {\n            const idx = (end + 1 + i) % n;\n            if (!child.includes(parent2[idx])) {\n                while (child[j] !== -1) {\n                    j = (j + 1) % n;\n                }\n                child[j] = parent2[idx];\n            }\n        }\n        \n        return child;\n    },\n    \n    _swapMutation: function(sequence) {\n        const i = Math.floor(Math.random() * sequence.length);\n        const j = Math.floor(Math.random() * sequence.length);\n        [sequence[i], sequence[j]] = [sequence[j], sequence[i]];\n    },\n    \n    /**\n     * Genetic Algorithm for Parameter Optimization\n     */\n    geneticParameters: function(objectiveFunc, bounds, options = {}) {\n        const config = {\n            populationSize: options.populationSize || 50,\n            generations: options.generations || 100,\n            crossoverRate: options.crossoverRate || 0.8,\n            mutationRate: options.mutationRate || 0.15\n        };\n        \n        const dimensions = Object.keys(bounds);\n        \n        // Initialize population\n        let population = [];\n        for (let i = 0; i < config.populationSize; i++) {\n            const individual = {};\n            for (const dim of dimensions) {\n                individual[dim] = bounds[dim].min + Math.random() * (bounds[dim].max - bounds[dim].min);\n            }\n            const fitness = objectiveFunc(individual);\n            population.push({ params: individual, fitness });\n        }\n        \n        population.sort((a, b) => b.fitness - a.fitness);\n        \n        for (let gen = 0; gen < config.generations; gen++) {\n            const newPopulation = [];\n            \n            // Elitism\n            newPopulation.push({ ...population[0] });\n            newPopulation.push({ ...population[1] });\n            \n            while (newPopulation.length < config.populationSize) {\n                const parent1 = this._tournamentSelect(population, 3);\n                const parent2 = this._tournamentSelect(population, 3);\n                \n                const child = {};\n                for (const dim of dimensions) {\n                    // BLX-alpha crossover\n                    const alpha = 0.5;\n                    const min = Math.min(parent1.params[dim], parent2.params[dim]);\n                    const max = Math.max(parent1.params[dim], parent2.params[dim]);\n                    const range = max - min;\n                    child[dim] = min - alpha * range + Math.random() * (1 + 2 * alpha) * range;\n                    \n                    // Mutation\n                    if (Math.random() < config.mutationRate) {\n                        child[dim] += (Math.random() - 0.5) * (bounds[dim].max - bounds[dim].min) * 0.1;\n                    }\n                    \n                    // Clamp\n                    child[dim] = Math.max(bounds[dim].min, Math.min(bounds[dim].max, child[dim]));\n                }\n                \n                const fitness = objectiveFunc(child);\n                newPopulation.push({ params: child, fitness });\n            }\n            \n            population = newPopulation;\n            population.sort((a, b) => b.fitness - a.fitness);\n        }\n        \n        return {\n            optimal: population[0].params,\n            fitness: population[0].fitness,\n            generations: config.generations,\n            source: 'CMU 24-785 - Genetic Algorithm'\n        };\n    },\n    \n    /**\n     * Newton's Method Optimization\n     * Source: MIT 6.251J - Mathematical Programming\n     */\n    newtonOptimize: function(f, gradient, hessian, x0, options = {}) {\n        const config = {\n            maxIter: options.maxIter || 100,\n            tol: typeof PRISM_CONSTANTS !== 'undefined' ? \n                PRISM_CONSTANTS.TOLERANCE.CONVERGENCE : 1e-8\n        };\n        \n        let x = Array.isArray(x0) ? [...x0] : [x0];\n        \n        for (let i = 0; i < config.maxIter; i++) {\n            const g = gradient(x);\n            const H = hessian(x);\n            \n            // Solve H * delta = -g\n            const delta = this._solveLinearSystem(H, g.map(v => -v));\n            \n            // Update x\n            for (let j = 0; j < x.length; j++) {\n                x[j] += delta[j];\n            }\n            \n            // Check convergence\n            const norm = Math.sqrt(delta.reduce((sum, d) => sum + d * d, 0));\n            if (norm < config.tol) {\n                return {\n                    optimal: x,\n                    value: f(x),\n                    iterations: i + 1,\n                    converged: true,\n                    source: 'MIT 6.251J - Newton Method'\n                };\n            }\n        }\n        \n        return {\n            optimal: x,\n            value: f(x),\n            iterations: config.maxIter,\n            converged: false,\n            source: 'MIT 6.251J - Newton Method'\n        };\n    },\n    \n    _solveLinearSystem: function(A, b) {\n        // Simple Gaussian elimination for small systems\n        const n = b.length;\n        const augmented = A.map((row, i) => [...row, b[i]]);\n        \n        // Forward elimination\n        for (let i = 0; i < n; i++) {\n            // Find pivot\n            let maxRow = i;\n            for (let k = i + 1; k < n; k++) {\n                if (Math.abs(augmented[k][i]) > Math.abs(augmented[maxRow][i])) {\n                    maxRow = k;\n                }\n            }\n            [augmented[i], augmented[maxRow]] = [augmented[maxRow], augmented[i]];\n            \n            // Eliminate\n            for (let k = i + 1; k < n; k++) {\n                const factor = augmented[k][i] / augmented[i][i];\n                for (let j = i; j <= n; j++) {\n                    augmented[k][j] -= factor * augmented[i][j];\n                }\n            }\n        }\n        \n        // Back substitution\n        const x = new Array(n).fill(0);\n        for (let i = n - 1; i >= 0; i--) {\n            x[i] = augmented[i][n];\n            for (let j = i + 1; j < n; j++) {\n                x[i] -= augmented[i][j] * x[j];\n            }\n            x[i] /= augmented[i][i];\n        }\n        \n        return x;\n    },\n    \n    /**\n     * BFGS Quasi-Newton Optimization\n     * Source: MIT 6.251J - Mathematical Programming\n     */\n    bfgsOptimize: function(f, gradient, x0, options = {}) {\n        const config = {\n            maxIter: options.maxIter || 200,\n            tol: typeof PRISM_CONSTANTS !== 'undefined' ? \n                PRISM_CONSTANTS.TOLERANCE.CONVERGENCE : 1e-8\n        };\n        \n        let x = Array.isArray(x0) ? [...x0] : [x0];\n        const n = x.length;\n        \n        // Initialize inverse Hessian approximation as identity\n        let H = [];\n        for (let i = 0; i < n; i++) {\n            H[i] = new Array(n).fill(0);\n            H[i][i] = 1;\n        }\n        \n        let g = gradient(x);\n        \n        for (let iter = 0; iter < config.maxIter; iter++) {\n            // Check convergence\n            const gNorm = Math.sqrt(g.reduce((sum, v) => sum + v * v, 0));\n            if (gNorm < config.tol) {\n                return {\n                    optimal: x,\n                    value: f(x),\n                    iterations: iter,\n                    converged: true,\n                    source: 'MIT 6.251J - BFGS'\n                };\n            }\n            \n            // Search direction: p = -H * g\n            const p = new Array(n).fill(0);\n            for (let i = 0; i < n; i++) {\n                for (let j = 0; j < n; j++) {\n                    p[i] -= H[i][j] * g[j];\n                }\n            }\n            \n            // Line search (simple backtracking)\n            let alpha = 1;\n            const c = 0.0001;\n            const rho = 0.5;\n            const fx = f(x);\n            const slope = g.reduce((sum, gi, i) => sum + gi * p[i], 0);\n            \n            while (f(x.map((xi, i) => xi + alpha * p[i])) > fx + c * alpha * slope) {\n                alpha *= rho;\n                if (alpha < 1e-10) break;\n            }\n            \n            // Update x\n            const s = p.map(pi => alpha * pi);\n            const xNew = x.map((xi, i) => xi + s[i]);\n            const gNew = gradient(xNew);\n            const y = gNew.map((gi, i) => gi - g[i]);\n            \n            // BFGS update\n            const sy = s.reduce((sum, si, i) => sum + si * y[i], 0);\n            if (Math.abs(sy) > 1e-10) {\n                const Hy = new Array(n).fill(0);\n                for (let i = 0; i < n; i++) {\n                    for (let j = 0; j < n; j++) {\n                        Hy[i] += H[i][j] * y[j];\n                    }\n                }\n                \n                const yHy = y.reduce((sum, yi, i) => sum + yi * Hy[i], 0);\n                \n                for (let i = 0; i < n; i++) {\n                    for (let j = 0; j < n; j++) {\n                        H[i][j] += (sy + yHy) * s[i] * s[j] / (sy * sy) -\n                            (Hy[i] * s[j] + s[i] * Hy[j]) / sy;\n                    }\n                }\n            }\n            \n            x = xNew;\n            g = gNew;\n        }\n        \n        return {\n            optimal: x,\n            value: f(x),\n            iterations: config.maxIter,\n            converged: false,\n            source: 'MIT 6.251J - BFGS'\n        };\n    }\n};\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// PHASE 1 MACHINE LEARNING ALGORITHMS\n// Sources: MIT 6.036, Stanford CS229\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nconst PRISM_PHASE1_ML = {\n    name: 'Phase 1 Machine Learning Algorithms',\n    version: '1.0.0',\n    source: 'MIT 6.036, Stanford CS229',\n    \n    /**\n     * Linear Regression Prediction\n     * Source: MIT 6.036 - Introduction to Machine Learning\n     */\n    linearPredict: function(X, y, xNew) {\n        // Fit linear regression using normal equations: w = (X'X)^-1 X'y\n        const n = X.length;\n        const m = X[0].length;\n        \n        // Add bias column\n        const Xb = X.map(row => [1, ...row]);\n        const xNewB = [1, ...xNew];\n        \n        // X'X\n        const XtX = this._matrixMultiply(this._transpose(Xb), Xb);\n        \n        // (X'X)^-1\n        const XtXInv = this._matrixInverse(XtX);\n        \n        // X'y\n        const Xty = this._matrixVectorMultiply(this._transpose(Xb), y);\n        \n        // w = (X'X)^-1 X'y\n        const w = this._matrixVectorMultiply(XtXInv, Xty);\n        \n        // Predict\n        const prediction = xNewB.reduce((sum, xi, i) => sum + xi * w[i], 0);\n        \n        return {\n            prediction,\n            weights: w,\n            source: 'MIT 6.036 - Linear Regression'\n        };\n    }",
      "methods": [],
      "lines": 2747
    },
    {
      "name": "PRISM_HEAT_TRANSFER_ENGINE",
      "category": "engines",
      "refs": 305,
      "status": "FOUND",
      "code": "const PRISM_HEAT_TRANSFER_ENGINE = {\n    name: 'PRISM_HEAT_TRANSFER_ENGINE',\n    version: '1.0.0',\n    source: 'MIT 2.51, MIT 16.050',\n    \n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // CONDUCTION\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    \n    /**\n     * 1D steady-state conduction (Fourier's law)\n     * q = -k \u00d7 dT/dx\n     */\n    steadyStateConduction1D: function(params) {\n        const {\n            thermalConductivity: k, // W/(m\u00b7K)\n            length: L,              // m\n            crossSectionArea: A,    // m\u00b2\n            T_hot,                  // \u00b0C\n            T_cold                  // \u00b0C\n        } = params;\n        \n        const dT = T_hot - T_cold;\n        const q = k * A * dT / L; // W\n        const R_thermal = L / (k * A); // K/W\n        \n        return {\n            heatFlux_W: q,\n            heatFlux_W_m2: k * dT / L,\n            thermalResistance_K_W: R_thermal,\n            temperatureGradient_K_m: -dT / L,\n            temperatureProfile: (x) => T_hot - (dT / L) * x\n        };\n    },\n    \n    /**\n     * 1D transient conduction (lumped capacitance)\n     * Valid when Bi < 0.1\n     */\n    transientLumpedCapacitance: function(params) {\n        const {\n            mass: m,                    // kg\n            specificHeat: c,            // J/(kg\u00b7K)\n            surfaceArea: A_s,           // m\u00b2\n            heatTransferCoeff: h,       // W/(m\u00b2\u00b7K)\n            T_initial,                  // \u00b0C\n            T_ambient,                  // \u00b0C\n            time: t                     // s\n        } = params;\n        \n        // Time constant\n        const tau = m * c / (h * A_s);\n        \n        // Temperature at time t\n        const T = T_ambient + (T_initial - T_ambient) * Math.exp(-t / tau);\n        \n        // Cooling/heating rate\n        const dT_dt = -(T_initial - T_ambient) / tau * Math.exp(-t / tau);\n        \n        // Time to reach target temperature\n        const timeToTemp = (T_target) => {\n            const ratio = (T_target - T_ambient) / (T_initial - T_ambient);\n            return ratio > 0 ? -tau * Math.log(ratio) : Infinity;\n        };\n        \n        return {\n            temperature_C: T,\n            timeConstant_s: tau,\n            coolingRate_C_s: Math.abs(dT_dt),\n            percentComplete: (1 - Math.exp(-t / tau)) * 100,\n            time95percent_s: 3 * tau,\n            temperatureFunction: (time) => T_ambient + (T_initial - T_ambient) * Math.exp(-time / tau),\n            timeToTarget: timeToTemp\n        };\n    },\n    \n    /**\n     * 1D transient conduction with FDM (finite difference)\n     * @param {Object} params - Material, geometry, boundary conditions\n     * @param {Object} config - Numerical parameters\n     * @returns {Object} Temperature field evolution\n     */\n    transientConduction1D_FDM: function(params, config) {\n        const {\n            thermalConductivity: k,\n            density: rho,\n            specificHeat: c,\n            length: L,\n            T_initial,\n            T_left,          // Left boundary (Dirichlet)\n            T_right,         // Right boundary (Dirichlet)\n            q_left,          // Left heat flux (Neumann) - alternative\n            h_right,         // Convection at right (Robin) - alternative\n            T_inf            // Ambient for convection\n        } = params;\n        \n        const {\n            nx = 50,         // Spatial nodes\n            dt = 0.1,        // Time step (s)\n            duration = 100   // Total simulation time (s)\n        } = config;\n        \n        const alpha = k / (rho * c); // Thermal diffusivity\n        const dx = L / (nx - 1);\n        \n        // Stability check (Fo \u2264 0.5 for explicit)\n        const Fo = alpha * dt / (dx * dx);\n        if (Fo > 0.5) {\n            console.warn(`Fourier number ${Fo.toFixed(3)} > 0.5. Reduce dt for stability.`);\n        }\n        \n        // Initialize temperature array\n        let T = Array(nx).fill(T_initial);\n        const history = [{ time: 0, T: [...T] }];\n        \n        const numSteps = Math.floor(duration / dt);\n        \n        for (let step = 0; step < numSteps; step++) {\n            const T_new = [...T];\n            \n            // Interior points (explicit FTCS)\n            for (let i = 1; i < nx - 1; i++) {\n                T_new[i] = T[i] + Fo * (T[i+1] - 2*T[i] + T[i-1]);\n            }\n            \n            // Boundary conditions\n            if (T_left !== undefined) {\n                T_new[0] = T_left;\n            } else if (q_left !== undefined) {\n                // Neumann: q = -k dT/dx\n                T_new[0] = T_new[1] + q_left * dx / k;\n            }\n            \n            if (T_right !== undefined) {\n                T_new[nx-1] = T_right;\n            } else if (h_right !== undefined && T_inf !== undefined) {\n                // Robin: q = h(T - T_inf)\n                const Bi = h_right * dx / k;\n                T_new[nx-1] = (T_new[nx-2] + Bi * T_inf) / (1 + Bi);\n            }\n            \n            T = T_new;\n            \n            // Store at intervals\n            if (step % Math.max(1, Math.floor(numSteps / 100)) === 0) {\n                history.push({ time: (step + 1) * dt, T: [...T] });\n            }\n        }\n        \n        return {\n            finalTemperature: T,\n            history,\n            fourierNumber: Fo,\n            dx,\n            dt,\n            maxTemp: Math.max(...T),\n            minTemp: Math.min(...T),\n            positions: Array(nx).fill(0).map((_, i) => i * dx)\n        };\n    },\n    \n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // CONVECTION\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    \n    /**\n     * Forced convection heat transfer coefficient\n     * @param {Object} params - Flow and geometry parameters\n     * @returns {Object} Heat transfer coefficient and related values\n     */\n    forcedConvectionCoefficient: function(params) {\n        const {\n            velocity: U,            // m/s\n            characteristicLength: L, // m\n            fluidType = 'air'       // or 'water', 'oil', 'coolant'\n        } = params;\n        \n        // Fluid properties at ~20-25\u00b0C\n        const fluids = {\n            'air': { rho: 1.2, mu: 1.8e-5, k: 0.026, cp: 1006, Pr: 0.71 },\n            'water': { rho: 1000, mu: 1e-3, k: 0.6, cp: 4186, Pr: 7 },\n            'oil': { rho: 870, mu: 0.03, k: 0.14, cp: 1880, Pr: 400 },\n            'coolant': { rho: 1050, mu: 2e-3, k: 0.5, cp: 3500, Pr: 14 }\n        };\n        \n        const fluid = fluids[fluidType] || fluids.water;\n        \n        // Reynolds number\n        const Re = fluid.rho * U * L / fluid.mu;\n        \n        // Flow regime\n        const flowRegime = Re < 2300 ? 'laminar' : Re < 4000 ? 'transition' : 'turbulent';\n        \n        // Nusselt number correlations\n        let Nu;\n        if (Re < 2300) {\n            // Laminar flow over flat plate\n            Nu = 0.664 * Math.pow(Re, 0.5) * Math.pow(fluid.Pr, 1/3);\n        } else if (Re < 5e5) {\n            // Turbulent flat plate (Colburn)\n            Nu = 0.0296 * Math.pow(Re, 0.8) * Math.pow(fluid.Pr, 1/3);\n        } else {\n            // Fully turbulent (Dittus-Boelter)\n            Nu = 0.023 * Math.pow(Re, 0.8) * Math.pow(fluid.Pr, 0.4);\n        }\n        \n        // Heat transfer coefficient\n        const h = Nu * fluid.k / L;\n        \n        return {\n            heatTransferCoeff_W_m2K: h,\n            reynoldsNumber: Re,\n            nusseltNumber: Nu,\n            prandtlNumber: fluid.Pr,\n            flowRegime,\n            fluid: fluidType,\n            thermalBoundaryLayer_mm: L * 1000 / Math.pow(Re, 0.5) * Math.pow(fluid.Pr, 1/3)\n        };\n    },\n    \n    /**\n     * Coolant effectiveness in machining\n     */\n    coolantEffectiveness: function(params) {\n        const {\n            cuttingSpeed: V,         // m/min\n            flowRate: Q,             // L/min\n            coolantType = 'water_based',\n            nozzleDiameter: d_n = 3, // mm\n            nozzleDistance: L_n = 50 // mm from cutting zone\n        } = params;\n        \n        // Coolant properties\n        const coolants = {\n            'water_based': { h_eff: 10000, coolingCapacity: 1.0, friction_reduction: 0.15 },\n            'straight_oil': { h_eff: 3000, coolingCapacity: 0.4, friction_reduction: 0.25 },\n            'synthetic': { h_eff: 8000, coolingCapacity: 0.8, friction_reduction: 0.20 },\n            'semi_synthetic': { h_eff: 7000, coolingCapacity: 0.7, friction_reduction: 0.22 },\n            'mql': { h_eff: 2000, coolingCapacity: 0.15, friction_reduction: 0.30 }\n        };\n        \n        const coolant = coolants[coolantType] || coolants.water_based;\n        \n        // Jet velocity\n        const A_nozzle = Math.PI * (d_n/2/1000) ** 2; // m\u00b2\n        const V_jet = (Q / 60000) / A_nozzle; // m/s\n        \n        // Momentum ratio (jet penetration)\n        const V_chip = V / 60; // m/s\n        const momentumRatio = V_jet / V_chip;\n        \n        // Effective heat transfer coefficient (depends on penetration)\n        const penetrationFactor = Math.min(1, momentumRatio / 2);\n        const h_actual = coolant.h_eff * penetrationFactor;\n        \n        // Temperature reduction estimate\n        const T_reduction_estimate = penetrationFactor * coolant.coolingCapacity * 200; // \u00b0C\n        \n        return {\n            effectiveHTC_W_m2K: h_actual,\n            jetVelocity_m_s: V_jet,\n            momentumRatio,\n            penetrationFactor,\n            estimatedTempReduction_C: T_reduction_estimate,\n            frictionReduction_percent: coolant.friction_reduction * 100 * penetrationFactor,\n            coolantType,\n            recommendation: momentumRatio < 1.5 ? \n                'Increase flow rate or reduce nozzle diameter for better penetration' :\n                'Good coolant delivery'\n        };\n    },\n    \n    // Gateway registration\n    register: function() {\n        if (typeof PRISM_GATEWAY !== 'undefined') {\n            PRISM_GATEWAY.register('heat.conduction1D', 'PRISM_HEAT_TRANSFER_ENGINE.steadyStateConduction1D');\n            PRISM_GATEWAY.register('heat.transientLumped', 'PRISM_HEAT_TRANSFER_ENGINE.transientLumpedCapacitance');\n            PRISM_GATEWAY.register('heat.transientFDM', 'PRISM_HEAT_TRANSFER_ENGINE.transientConduction1D_FDM');\n            PRISM_GATEWAY.register('heat.convectionCoeff', 'PRISM_HEAT_TRANSFER_ENGINE.forcedConvectionCoefficient');\n            PRISM_GATEWAY.register('heat.coolant', 'PRISM_HEAT_TRANSFER_ENGINE.coolantEffectiveness');\n            console.log('[PRISM] PRISM_HEAT_TRANSFER_ENGINE registered: 5 routes');\n        }\n    }\n};\n\n\n/**\n * PRISM_THERMAL_EXPANSION_ENGINE\n * Thermal effects on dimensional accuracy\n * Source: MIT 2.75 (Precision Machine Design)\n */\nconst PRISM_THERMAL_EXPANSION_ENGINE = {\n    name: 'PRISM_THERMAL_EXPANSION_ENGINE',\n    version: '1.0.0',\n    source: 'MIT 2.75, Bryan Principles',\n    \n    /**\n     * Linear thermal expansion\n     * \u0394L = L \u00d7 \u03b1 \u00d7 \u0394T\n     */\n    linearExpansion: function(params) {\n        const {\n            originalLength: L,      // mm\n            temperatureChange: dT,  // \u00b0C\n            material,\n            CTE                     // Coefficient of thermal expansion (1/\u00b0C)\n        } = params;\n        \n        // CTE database (\u00b5m/m/\u00b0C = 10\u207b\u2076/\u00b0C)\n        const cteDatabase = {\n            'steel': 11.7e-6,\n            'stainless_steel': 17.3e-6,\n            'aluminum': 23.1e-6,\n            'brass': 19e-6,\n            'copper': 16.5e-6,\n            'cast_iron': 10.5e-6,\n            'granite': 6e-6,\n            'invar': 1.2e-6,\n            'super_invar': 0.6e-6,\n            'zerodur': 0.02e-6,\n            'ceramic': 7e-6,\n            'carbide': 5.5e-6\n        };\n        \n        const alpha = CTE || cteDatabase[material?.toLowerCase()] || 12e-6;\n        \n        const dL = L * alpha * dT;\n        \n        return {\n            expansion_mm: dL,\n            expansion_um: dL * 1000,\n            percentChange: (dL / L) * 100,\n            CTE_per_C: alpha,\n            material: material || 'default_steel',\n            temperatureForTolerance: (tolerance) => tolerance / (L * alpha)\n        };\n    },\n    \n    /**\n     * Thermal error analysis for machine tool\n     * Based on Bryan's principles\n     */\n    machineToolThermalError: function(params) {\n        const {\n            machineGeometry,     // {X_axis_length, Y_axis_length, Z_axis_length}\n            temperatureField,    // {X_gradient, Y_gradient, Z_gradient, spindle_delta}\n            materials = {}       // Material for each component\n        } = params;\n        \n        const { X_axis_length = 500, Y_axis_length = 400, Z_axis_length = 300 } = machineGeometry;\n        const { X_gradient = 1, Y_gradient = 0.5, Z_gradient = 0.8, spindle_delta = 5 } = temperatureField;\n        \n        // Default to cast iron for structure\n        const alpha_structure = 10.5e-6;\n        const alpha_spindle = 11.7e-6;\n        \n        // Positional errors from thermal expansion\n        const dX = X_axis_length * alpha_structure * X_gradient;\n        const dY = Y_axis_length * alpha_structure * Y_gradient;\n        const dZ = Z_axis_length * alpha_structure * Z_gradient;\n        \n        // Spindle growth (typically Z direction)\n        const spindle_length = 150; // mm approximate\n        const spindle_growth = spindle_length * alpha_spindle * spindle_delta;\n        \n        // Angular errors from temperature gradients\n        // \u03b1 = L \u00d7 \u03b1_CTE \u00d7 \u0394T_gradient / height\n        const height = 300; // mm structural height\n        const angular_X = Math.atan(X_axis_length * alpha_structure * X_gradient / height) * 1e6; // \u00b5rad\n        const angular_Y = Math.atan(Y_axis_length * alpha_structure * Y_gradient / height) * 1e6;\n        \n        // Total volumetric error (RSS)\n        const total_error = Math.sqrt(dX*dX + dY*dY + (dZ + spindle_growth)**2);\n        \n        return {\n            linearErrors_mm: { X: dX, Y: dY, Z: dZ + spindle_growth },\n            linearErrors_um: { X: dX*1000, Y: dY*1000, Z: (dZ + spindle_growth)*1000 },\n            spindleGrowth_um: spindle_growth * 1000,\n            angularErrors_urad: { X: angular_X, Y: angular_Y },\n            totalVolumetricError_um: total_error * 1000,\n            recommendations: this._thermalRecommendations(total_error * 1000, temperatureField)\n        };\n    },\n    \n    _thermalRecommendations: function(total_error_um, temps) {\n        const recs = [];\n        \n        if (total_error_um > 50) {\n            recs.push('Consider active thermal compensation');\n        }\n        if (temps.spindle_delta > 3) {\n            recs.push('Improve spindle cooling or increase warmup time');\n        }\n        if (temps.X_gradient > 1 || temps.Y_gradient > 1) {\n            recs.push('Check environmental temperature control');\n        }\n        if (total_error_um > 10) {\n            recs.push('Allow thermal stabilization before precision operations');\n        }\n        \n        return recs.length ? recs : ['Thermal errors within acceptable limits'];\n    },\n    \n    /**\n     * Thermal compensation calculation\n     */\n    thermalCompensation: function(params) {\n        const {\n            measuredTemperatures,    // Array of {sensor_id, temp, position}\n            referenceTemperatures,   // Array of {sensor_id, temp}\n            compensationMatrix       // Pre-calibrated thermal error model\n        } = params;\n        \n        // Calculate temperature changes from reference\n        const tempChanges = measuredTemperatures.map((m, i) => ({\n            sensor: m.sensor_id,\n            delta: m.temp - (referenceTemperatures[i]?.temp || 20),\n            position: m.position\n        }));\n        \n        // If no compensation matrix, use simple model\n        if (!compensationMatrix) {\n            const avg_delta = tempChanges.reduce((s, t) => s + t.delta, 0) / tempChanges.length;\n            return {\n                compensation_X_um: avg_delta * 10,  // Simple estimate\n                compensation_Y_um: avg_delta * 8,\n                compensation_Z_um: avg_delta * 12,\n                temperatureDeltas: tempChanges,\n                method: 'simple_average'\n            };\n        }\n        \n        // Apply compensation matrix (linear model)\n        // compensation = \u03a3(matrix_coeff \u00d7 temp_delta)\n        let comp_X = 0, comp_Y = 0, comp_Z = 0;\n        \n        for (let i = 0; i < tempChanges.length; i++) {\n            if (compensationMatrix[i]) {\n                comp_X += compensationMatrix[i].X * tempChanges[i].delta;\n                comp_Y += compensationMatrix[i].Y * tempChanges[i].delta;\n                comp_Z += compensationMatrix[i].Z * tempChanges[i].delta;\n            }\n        }\n        \n        return {\n            compensation_X_um: comp_X,\n            compensation_Y_um: comp_Y,\n            compensation_Z_um: comp_Z,\n            temperatureDeltas: tempChanges,\n            method: 'matrix_compensation'\n        };\n    },\n    \n    // Gateway registration\n    register: function() {\n        if (typeof PRISM_GATEWAY !== 'undefined') {\n            PRISM_GATEWAY.register('thermal.expansion', 'PRISM_THERMAL_EXPANSION_ENGINE.linearExpansion');\n            PRISM_GATEWAY.register('thermal.machineError', 'PRISM_THERMAL_EXPANSION_ENGINE.machineToolThermalError');\n            PRISM_GATEWAY.register('thermal.compensation', 'PRISM_THERMAL_EXPANSION_ENGINE.thermalCompensation');\n            console.log('[PRISM] PRISM_THERMAL_EXPANSION_ENGINE registered: 3 routes');\n        }\n    }\n}",
      "methods": [],
      "lines": 463
    },
    {
      "name": "PRISM_THERMAL_EXPANSION_ENGINE",
      "category": "engines",
      "refs": 303,
      "status": "FOUND",
      "code": "const PRISM_THERMAL_EXPANSION_ENGINE = {\n    name: 'PRISM_THERMAL_EXPANSION_ENGINE',\n    version: '1.0.0',\n    source: 'MIT 2.75, Bryan Principles',\n    \n    /**\n     * Linear thermal expansion\n     * \u0394L = L \u00d7 \u03b1 \u00d7 \u0394T\n     */\n    linearExpansion: function(params) {\n        const {\n            originalLength: L,      // mm\n            temperatureChange: dT,  // \u00b0C\n            material,\n            CTE                     // Coefficient of thermal expansion (1/\u00b0C)\n        } = params;\n        \n        // CTE database (\u00b5m/m/\u00b0C = 10\u207b\u2076/\u00b0C)\n        const cteDatabase = {\n            'steel': 11.7e-6,\n            'stainless_steel': 17.3e-6,\n            'aluminum': 23.1e-6,\n            'brass': 19e-6,\n            'copper': 16.5e-6,\n            'cast_iron': 10.5e-6,\n            'granite': 6e-6,\n            'invar': 1.2e-6,\n            'super_invar': 0.6e-6,\n            'zerodur': 0.02e-6,\n            'ceramic': 7e-6,\n            'carbide': 5.5e-6\n        };\n        \n        const alpha = CTE || cteDatabase[material?.toLowerCase()] || 12e-6;\n        \n        const dL = L * alpha * dT;\n        \n        return {\n            expansion_mm: dL,\n            expansion_um: dL * 1000,\n            percentChange: (dL / L) * 100,\n            CTE_per_C: alpha,\n            material: material || 'default_steel',\n            temperatureForTolerance: (tolerance) => tolerance / (L * alpha)\n        };\n    },\n    \n    /**\n     * Thermal error analysis for machine tool\n     * Based on Bryan's principles\n     */\n    machineToolThermalError: function(params) {\n        const {\n            machineGeometry,     // {X_axis_length, Y_axis_length, Z_axis_length}\n            temperatureField,    // {X_gradient, Y_gradient, Z_gradient, spindle_delta}\n            materials = {}       // Material for each component\n        } = params;\n        \n        const { X_axis_length = 500, Y_axis_length = 400, Z_axis_length = 300 } = machineGeometry;\n        const { X_gradient = 1, Y_gradient = 0.5, Z_gradient = 0.8, spindle_delta = 5 } = temperatureField;\n        \n        // Default to cast iron for structure\n        const alpha_structure = 10.5e-6;\n        const alpha_spindle = 11.7e-6;\n        \n        // Positional errors from thermal expansion\n        const dX = X_axis_length * alpha_structure * X_gradient;\n        const dY = Y_axis_length * alpha_structure * Y_gradient;\n        const dZ = Z_axis_length * alpha_structure * Z_gradient;\n        \n        // Spindle growth (typically Z direction)\n        const spindle_length = 150; // mm approximate\n        const spindle_growth = spindle_length * alpha_spindle * spindle_delta;\n        \n        // Angular errors from temperature gradients\n        // \u03b1 = L \u00d7 \u03b1_CTE \u00d7 \u0394T_gradient / height\n        const height = 300; // mm structural height\n        const angular_X = Math.atan(X_axis_length * alpha_structure * X_gradient / height) * 1e6; // \u00b5rad\n        const angular_Y = Math.atan(Y_axis_length * alpha_structure * Y_gradient / height) * 1e6;\n        \n        // Total volumetric error (RSS)\n        const total_error = Math.sqrt(dX*dX + dY*dY + (dZ + spindle_growth)**2);\n        \n        return {\n            linearErrors_mm: { X: dX, Y: dY, Z: dZ + spindle_growth },\n            linearErrors_um: { X: dX*1000, Y: dY*1000, Z: (dZ + spindle_growth)*1000 },\n            spindleGrowth_um: spindle_growth * 1000,\n            angularErrors_urad: { X: angular_X, Y: angular_Y },\n            totalVolumetricError_um: total_error * 1000,\n            recommendations: this._thermalRecommendations(total_error * 1000, temperatureField)\n        };\n    },\n    \n    _thermalRecommendations: function(total_error_um, temps) {\n        const recs = [];\n        \n        if (total_error_um > 50) {\n            recs.push('Consider active thermal compensation');\n        }\n        if (temps.spindle_delta > 3) {\n            recs.push('Improve spindle cooling or increase warmup time');\n        }\n        if (temps.X_gradient > 1 || temps.Y_gradient > 1) {\n            recs.push('Check environmental temperature control');\n        }\n        if (total_error_um > 10) {\n            recs.push('Allow thermal stabilization before precision operations');\n        }\n        \n        return recs.length ? recs : ['Thermal errors within acceptable limits'];\n    },\n    \n    /**\n     * Thermal compensation calculation\n     */\n    thermalCompensation: function(params) {\n        const {\n            measuredTemperatures,    // Array of {sensor_id, temp, position}\n            referenceTemperatures,   // Array of {sensor_id, temp}\n            compensationMatrix       // Pre-calibrated thermal error model\n        } = params;\n        \n        // Calculate temperature changes from reference\n        const tempChanges = measuredTemperatures.map((m, i) => ({\n            sensor: m.sensor_id,\n            delta: m.temp - (referenceTemperatures[i]?.temp || 20),\n            position: m.position\n        }));\n        \n        // If no compensation matrix, use simple model\n        if (!compensationMatrix) {\n            const avg_delta = tempChanges.reduce((s, t) => s + t.delta, 0) / tempChanges.length;\n            return {\n                compensation_X_um: avg_delta * 10,  // Simple estimate\n                compensation_Y_um: avg_delta * 8,\n                compensation_Z_um: avg_delta * 12,\n                temperatureDeltas: tempChanges,\n                method: 'simple_average'\n            };\n        }\n        \n        // Apply compensation matrix (linear model)\n        // compensation = \u03a3(matrix_coeff \u00d7 temp_delta)\n        let comp_X = 0, comp_Y = 0, comp_Z = 0;\n        \n        for (let i = 0; i < tempChanges.length; i++) {\n            if (compensationMatrix[i]) {\n                comp_X += compensationMatrix[i].X * tempChanges[i].delta;\n                comp_Y += compensationMatrix[i].Y * tempChanges[i].delta;\n                comp_Z += compensationMatrix[i].Z * tempChanges[i].delta;\n            }\n        }\n        \n        return {\n            compensation_X_um: comp_X,\n            compensation_Y_um: comp_Y,\n            compensation_Z_um: comp_Z,\n            temperatureDeltas: tempChanges,\n            method: 'matrix_compensation'\n        };\n    },\n    \n    // Gateway registration\n    register: function() {\n        if (typeof PRISM_GATEWAY !== 'undefined') {\n            PRISM_GATEWAY.register('thermal.expansion', 'PRISM_THERMAL_EXPANSION_ENGINE.linearExpansion');\n            PRISM_GATEWAY.register('thermal.machineError', 'PRISM_THERMAL_EXPANSION_ENGINE.machineToolThermalError');\n            PRISM_GATEWAY.register('thermal.compensation', 'PRISM_THERMAL_EXPANSION_ENGINE.thermalCompensation');\n            console.log('[PRISM] PRISM_THERMAL_EXPANSION_ENGINE registered: 3 routes');\n        }\n    }\n};\n\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// REGISTRATION AND EXPORT\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nfunction registerSession4Part4() {\n    PRISM_CUTTING_THERMAL_ENGINE.register();\n    PRISM_HEAT_TRANSFER_ENGINE.register();\n    PRISM_THERMAL_EXPANSION_ENGINE.register();\n    \n    console.log('[Session 4 Part 4] Registered 3 modules, 11 gateway routes');\n    console.log('  - PRISM_CUTTING_THERMAL_ENGINE: Shear plane, Interface, Partition');\n    console.log('  - PRISM_HEAT_TRANSFER_ENGINE: Conduction, Convection, Coolant');\n    console.log('  - PRISM_THERMAL_EXPANSION_ENGINE: Expansion, Machine error, Compensation');\n}\n\n// Auto-register\nif (typeof window !== 'undefined') {\n    window.PRISM_CUTTING_THERMAL_ENGINE = PRISM_CUTTING_THERMAL_ENGINE;\n    window.PRISM_HEAT_TRANSFER_ENGINE = PRISM_HEAT_TRANSFER_ENGINE;\n    window.PRISM_THERMAL_EXPANSION_ENGINE = PRISM_THERMAL_EXPANSION_ENGINE;\n    registerSession4Part4();\n}\n\nconsole.log('[Session 4 Part 4] Thermal Analysis & Heat Transfer loaded - 3 modules');\n\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// SESSION 4 MASTER REGISTRATION\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nfunction registerAllSession4() {\n    registerSession4Part1();\n    registerSession4Part2();\n    registerSession4Part3();\n    registerSession4Part4();\n    console.log(\"[Session 4] All Physics & Dynamics modules registered\");\n    console.log(\"  - Part 1: Advanced Kinematics Engine\");\n    console.log(\"  - Part 2: Rigid Body Dynamics Engine\");\n    console.log(\"  - Part 3: Vibration & Chatter Analysis\");\n    console.log(\"  - Part 4: Thermal Analysis\");\n}\n\n// Auto-register Session 4\nif (typeof window !== \"undefined\") {\n    window.PRISM_ADVANCED_KINEMATICS_ENGINE = PRISM_ADVANCED_KINEMATICS_ENGINE;\n    window.PRISM_RIGID_BODY_DYNAMICS_ENGINE = PRISM_RIGID_BODY_DYNAMICS_ENGINE;\n    window.PRISM_VIBRATION_ANALYSIS_ENGINE = PRISM_VIBRATION_ANALYSIS_ENGINE;\n    window.PRISM_CHATTER_PREDICTION_ENGINE = PRISM_CHATTER_PREDICTION_ENGINE;\n    window.PRISM_CUTTING_MECHANICS_ENGINE = PRISM_CUTTING_MECHANICS_ENGINE;\n    window.PRISM_TOOL_LIFE_ENGINE = PRISM_TOOL_LIFE_ENGINE;\n    window.PRISM_SURFACE_FINISH_ENGINE = PRISM_SURFACE_FINISH_ENGINE;\n    window.PRISM_CUTTING_THERMAL_ENGINE = PRISM_CUTTING_THERMAL_ENGINE;\n    window.PRISM_HEAT_TRANSFER_ENGINE = PRISM_HEAT_TRANSFER_ENGINE;\n    window.PRISM_THERMAL_EXPANSION_ENGINE = PRISM_THERMAL_EXPANSION_ENGINE;\n    registerAllSession4();\n}\n\nconsole.log(\"[PRISM v8.83.001] Session 4 Physics & Dynamics loaded - 10 modules, 3,439 lines\");\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// SESSION 4 ENHANCEMENT: PHYSICS-INFORMED MACHINE LEARNING (PIML)\n// Cutting-edge 2024-2025 algorithms for chatter prediction\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n/**\n * \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n * PRISM SESSION 4 ENHANCEMENT: PHYSICS-INFORMED MACHINE LEARNING (PIML)\n * \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n * \n * Cutting-Edge Algorithms from 2024-2025 Research:\n * - Physics-Guided ML for Stability Lobe Diagrams (PGML-SLD)\n * - Semi-Discretization Method for Milling Dynamics\n * - Multi-Modal Data Fusion for Chatter Detection\n * - Online SLD Estimation with Continuous Learning\n * - Deep Neural Network Chatter Detection\n * \n * Sources:\n * - arXiv:2511.17894 - ML-based Online SLD Estimation (Nov 2025)\n * - Nature Scientific Reports - Multi-modal Chatter Detection (Jan 2025)\n * - Journal of Intelligent Manufacturing - PGML Stability Modeling (2022)\n * - Mechanical Systems and Signal Processing - Lightweight Deep Learning (2024)\n * \n * @version 1.0.0\n * @date January 18, 2026\n */\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// PHYSICS-INFORMED MACHINE LEARNING CHATTER ENGINE\n// Combines physics-based models with ML for superior accuracy\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nconst PRISM_PIML_CHATTER_ENGINE = {\n  name: 'PRISM_PIML_CHATTER_ENGINE',\n  version: '1.0.0',\n  source: 'arXiv:2511.17894, Nature Sci. Rep. 2025, J. Intell. Manuf. 2022',\n  algorithms: [\n    'Semi-Discretization Method (SDM)',\n    'Physics-Guided ML (PGML)',\n    'Continuous Learning SVM',\n    'Multi-Modal Data Fusion',\n    'ANN-NADAM SLD Prediction',\n    'Online Bayesian SLD Update',\n    'Fractal-Based Feature Extraction'\n  ],\n\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  // SEMI-DISCRETIZATION METHOD FOR MILLING STABILITY\n  // Source: Insperger & St\u00e9p\u00e1n (2002), arXiv:2511.17894\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n  /**\n   * Semi-Discretization Method for stability analysis\n   * Models milling as delay differential equation (DDE)\n   * \u1e8d(t) + 2\u03b6\u03c9\u2099\u1e8b(t) + \u03c9\u2099\u00b2x(t) = (Kc\u00b7ap/m)[x(t-T) - x(t)]\n   * \n   * @param {Object} system - Dynamic system parameters\n   * @param {Object} cutting - Cutting parameters\n   * @param {number} N - Number of discrete intervals per period\n   * @returns {Object} Stability analysis results\n   */\n  semiDiscretization: function(system, cutting, N = 40) {\n    const { mass, stiffness, damping } = system;\n    const { Kc, teeth, radialImmersion } = cutting;\n    \n    const wn = Math.sqrt(stiffness / mass);\n    const zeta = damping / (2 * Math.sqrt(stiffness * mass));\n    \n    // Specific cutting coefficient (averaged)\n    const g = radialImmersion || 1.0; // Radial immersion ratio\n    const h = Kc * g / (2 * Math.PI); // Average directional factor\n    \n    return {\n      /**\n       * Compute stability at given spindle speed and depth\n       */\n      checkStability: function(rpm, ap) {\n        const T = 60 / (rpm * teeth); // Tooth passing period\n        const dt = T / N; // Discrete time step\n        \n        // State transition matrix construction\n        // Using simplified first-order hold approximation\n        const wd = wn * Math.sqrt(1 - zeta * zeta);\n        const exp_term = Math.exp(-zeta * wn * dt);\n        \n        // Monodromy matrix (simplified 2x2 for SDOF)\n        const a11 = exp_term * (Math.cos(wd * dt) + zeta * wn / wd * Math.sin(wd * dt));\n        const a12 = exp_term * Math.sin(wd * dt) / wd;\n        const a21 = -exp_term * wn * wn / wd * Math.sin(wd * dt);\n        const a22 = exp_term * (Math.cos(wd * dt) - zeta * wn / wd * Math.sin(wd * dt));\n        \n        // Include cutting force effect (regenerative)\n        const Kc_term = h * ap / mass;\n        const b11 = Kc_term * (1 - a11);\n        const b21 = Kc_term * (-a21);\n        \n        // Build full monodromy matrix over one period (N steps)\n        // For stability, eigenvalues of monodromy matrix must be < 1\n        \n        // Simplified check: compute eigenvalues of single step matrix\n        const A = [\n          [a11 + b11, a12],\n          [a21 + b21, a22]\n        ];\n        \n        // Eigenvalue computation (2x2 case)\n        const trace = A[0][0] + A[1][1];\n        const det = A[0][0] * A[1][1] - A[0][1] * A[1][0];\n        const disc = trace * trace - 4 * det;\n        \n        let maxEig;\n        if (disc >= 0) {\n          const sqrt_disc = Math.sqrt(disc);\n          maxEig = Math.max(Math.abs((trace + sqrt_disc) / 2), \n                           Math.abs((trace - sqrt_disc) / 2));\n        } else {\n          // Complex eigenvalues\n          maxEig = Math.sqrt(det);\n        }\n        \n        // Stability margin (power raised to N for full period)\n        const periodicMaxEig = Math.pow(maxEig, N);\n        \n        return {\n          stable: periodicMaxEig < 1.0,\n          maxEigenvalue: periodicMaxEig,\n          stabilityMargin: 1.0 - periodicMaxEig,\n          rpm, ap\n        };\n      },\n      \n      /**\n       * Generate stability lobe diagram\n       */\n      generateSLD: function(rpmRange, apRange, resolution = 100) {\n        const [rpmMin, rpmMax] = rpmRange;\n        const [apMin, apMax] = apRange;\n        \n        const sld = {\n          stablePoints: [],\n          unstablePoints: [],\n          boundaryPoints: []\n        };\n        \n        for (let i = 0; i <= resolution; i++) {\n          const rpm = rpmMin + (rpmMax - rpmMin) * i / resolution;\n          \n          // Binary search for stability boundary\n          let low = apMin, high = apMax;\n          while (high - low > (apMax - apMin) / 1000) {\n            const mid = (low + high) / 2;\n            const result = this.checkStability(rpm, mid);\n            if (result.stable) {\n              low = mid;\n            } else {\n              high = mid;\n            }\n          }\n          \n          sld.boundaryPoints.push({ rpm, ap: (low + high) / 2 });\n        }\n        \n        return sld;\n      },\n      \n      params: { wn, zeta, h, teeth }\n    };\n  },\n\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  // PHYSICS-GUIDED MACHINE LEARNING (PGML)\n  // Source: J. Intelligent Manufacturing 2022\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n  /**\n   * PGML model that combines physics-based SLD with neural network\n   * Uses RCSA (Receptance Coupling Substructure Analysis) as physics base\n   * Neural network learns residuals between physics model and reality\n   */\n  pgmlStabilityModel: {\n    name: 'PGML_StabilityModel',\n    \n    /**\n     * Initialize PGML model with physics-based prior\n     */\n    initialize: function(physicsModel, mlConfig = {}) {\n      return {\n        physics: physicsModel,\n        ml: {\n          layers: mlConfig.layers || [32, 16, 8],\n          activation: mlConfig.activation || 'relu',\n          weights: null,\n          biases: null,\n          trained: false\n        },\n        trainingData: [],\n        validationData: []\n      };\n    },\n    \n    /**\n     * Generate synthetic training data from physics model\n     */\n    generatePhysicsData: function(model, rpmRange, apRange, numSamples = 1000) {\n      const data = [];\n      const sdm = PRISM_PIML_CHATTER_ENGINE.semiDiscretization(\n        model.physics.system,\n        model.physics.cutting\n      );\n      \n      for (let i = 0; i < numSamples; i++) {\n        const rpm = rpmRange[0] + Math.random() * (rpmRange[1] - rpmRange[0]);\n        const ap = apRange[0] + Math.random() * (apRange[1] - apRange[0]);\n        \n        const result = sdm.checkStability(rpm, ap);\n        \n        data.push({\n          input: [rpm / 10000, ap / 10], // Normalized inputs\n          output: [result.stable ? 1 : 0],\n          eigenvalue: result.maxEigenvalue\n        });\n      }\n      \n      return data;\n    },\n    \n    /**\n     * Train neural network on combined physics + experimental data\n     * Uses NADAM optimizer for better convergence on SLD lobes\n     */\n    train: function(model, experimentalData = [], options = {}) {\n      const epochs = options.epochs || 100;\n      const batchSize = options.batchSize || 32;\n      const learningRate = options.learningRate || 0.001;\n      \n      // Combine physics-generated and experimental data\n      const physicsData = this.generatePhysicsData(\n        model,\n        options.rpmRange || [1000, 20000],\n        options.apRange || [0.1, 10]\n      );\n      \n      // Weight experimental data higher (physics-informed)\n      const combinedData = [\n        ...physicsData.map(d => ({ ...d, weight: 1 })),\n        ...experimentalData.map(d => ({ ...d, weight: 5 })) // Higher weight for real data\n      ];\n      \n      // Initialize network weights\n      const layers = model.ml.layers;\n      model.ml.weights = [];\n      model.ml.biases = [];\n      \n      let prevSize = 2; // Input: [rpm, ap]\n      for (const layerSize of layers) {\n        model.ml.weights.push(this._initWeights(prevSize, layerSize));\n        model.ml.biases.push(new Array(layerSize).fill(0));\n        prevSize = layerSize;\n      }\n      // Output layer\n      model.ml.weights.push(this._initWeights(prevSize, 1));\n      model.ml.biases.push([0]);\n      \n      // NADAM optimizer state\n      const m = model.ml.weights.map(w => w.map(row => row.map(() => 0)));\n      const v = model.ml.weights.map(w => w.map(row => row.map(() => 0)));\n      const beta1 = 0.9, beta2 = 0.999, eps = 1e-8;\n      \n      // Training loop\n      for (let epoch = 0; epoch < epochs; epoch++) {\n        // Shuffle data\n        this._shuffle(combinedData);\n        \n        let totalLoss = 0;\n        \n        for (let i = 0; i < combinedData.length; i += batchSize) {\n          const batch = combinedData.slice(i, i + batchSize);\n          \n          for (const sample of batch) {\n            // Forward pass\n            const activations = this._forward(model, sample.input);\n            const output = activations[activations.length - 1][0];\n            \n            // Compute loss (weighted binary cross-entropy)\n            const target = sample.output[0];\n            const loss = -sample.weight * (\n              target * Math.log(output + eps) +\n              (1 - target) * Math.log(1 - output + eps)\n            );\n            totalLoss += loss;\n            \n            // Backward pass (simplified gradient computation)\n            const gradOutput = (output - target) * sample.weight;\n            \n            // Update weights using NADAM\n            for (let l = model.ml.weights.length - 1; l >= 0; l--) {\n              const grad = this._computeGradient(activations, l, gradOutput);\n              \n              for (let j = 0; j < model.ml.weights[l].length; j++) {\n                for (let k = 0; k < model.ml.weights[l][j].length; k++) {\n                  // NADAM update\n                  m[l][j][k] = beta1 * m[l][j][k] + (1 - beta1) * grad[j][k];\n                  v[l][j][k] = beta2 * v[l][j][k] + (1 - beta2) * grad[j][k] * grad[j][k];\n                  \n                  const mHat = m[l][j][k] / (1 - Math.pow(beta1, epoch + 1));\n                  const vHat = v[l][j][k] / (1 - Math.pow(beta2, epoch + 1));\n                  \n                  // Nesterov momentum\n                  const mNesterov = beta1 * mHat + (1 - beta1) * grad[j][k] / (1 - Math.pow(beta1, epoch + 1));\n                  \n                  model.ml.weights[l][j][k] -= learningRate * mNesterov / (Math.sqrt(vHat) + eps);\n                }\n              }\n            }\n          }\n        }\n        \n        if (epoch % 10 === 0) {\n          console.log(`[PGML] Epoch ${epoch}, Loss: ${(totalLoss / combinedData.length).toFixed(4)}`);\n        }\n      }\n      \n      model.ml.trained = true;\n      return model;\n    },\n    \n    /**\n     * Predict stability using trained PGML model\n     */\n    predict: function(model, rpm, ap) {\n      if (!model.ml.trained) {\n        throw new Error('PGML model not trained');\n      }\n      \n      const input = [rpm / 10000, ap / 10]; // Normalize\n      const activations = this._forward(model, input);\n      const probability = activations[activations.length - 1][0];\n      \n      return {\n        stable: probability > 0.5,\n        probability,\n        confidence: Math.abs(probability - 0.5) * 2,\n        rpm, ap\n      };\n    },\n    \n    /**\n     * Generate PGML-enhanced SLD\n     */\n    generateSLD: function(model, rpmRange, apRange, resolution = 100) {\n      const sld = {\n        points: [],\n        boundary: []\n      };\n      \n      for (let i = 0; i <= resolution; i++) {\n        const rpm = rpmRange[0] + (rpmRange[1] - rpmRange[0]) * i / resolution;\n        \n        // Binary search for boundary\n        let low = apRange[0], high = apRange[1];\n        while (high - low > 0.01) {\n          const mid = (low + high) / 2;\n          const result = this.predict(model, rpm, mid);\n          if (result.stable) {\n            low = mid;\n          } else {\n            high = mid;\n          }\n        }\n        \n        sld.boundary.push({ rpm, ap: (low + high) / 2 });\n      }\n      \n      return sld;\n    },\n    \n    // Helper functions\n    _initWeights: function(rows, cols) {\n      const weights = [];\n      const scale = Math.sqrt(2 / rows); // He initialization\n      for (let i = 0; i < rows; i++) {\n        weights.push([]);\n        for (let j = 0; j < cols; j++) {\n          weights[i].push((Math.random() - 0.5) * 2 * scale);\n        }\n      }\n      return weights;\n    },\n    \n    _forward: function(model, input) {\n      const activations = [input];\n      let current = input;\n      \n      for (let l = 0; l < model.ml.weights.length; l++) {\n        const W = model.ml.weights[l];\n        const b = model.ml.biases[l];\n        \n        const output = [];\n        for (let j = 0; j < W[0].length; j++) {\n          let sum = b[j];\n          for (let i = 0; i < current.length; i++) {\n            sum += current[i] * W[i][j];\n          }\n          // ReLU for hidden, sigmoid for output\n          if (l < model.ml.weights.length - 1) {\n            output.push(Math.max(0, sum)); // ReLU\n          } else {\n            output.push(1 / (1 + Math.exp(-sum))); // Sigmoid\n          }\n        }\n        activations.push(output);\n        current = output;\n      }\n      \n      return activations;\n    },\n    \n    _computeGradient: function(activations, layer, gradOutput) {\n      const grad = [];\n      const input = activations[layer];\n      \n      for (let i = 0; i < input.length; i++) {\n        grad.push([]);\n        for (let j = 0; j < activations[layer + 1].length; j++) {\n          grad[i].push(gradOutput * input[i]);\n        }\n      }\n      \n      return grad;\n    },\n    \n    _shuffle: function(array) {\n      for (let i = array.length - 1; i > 0; i--) {\n        const j = Math.floor(Math.random() * (i + 1));\n        [array[i], array[j]] = [array[j], array[i]];\n      }\n    }\n  },\n\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  // MULTI-MODAL DATA FUSION FOR CHATTER DETECTION\n  // Source: Nature Scientific Reports 2025\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n  /**\n   * Multi-modal chatter detection using fused sensor data\n   * Combines: vibration, force, current, acoustic signals\n   */\n  multiModalChatterDetector: {\n    name: 'MultiModal_ChatterDetector',\n    \n    /**\n     * Fuse multiple sensor signals with adaptive weighting\n     */\n    fuseSignals: function(signals, weights = null) {\n      const { vibration, force, current, acoustic } = signals;\n      \n      // Default adaptive weights based on signal quality\n      if (!weights) {\n        weights = this._computeAdaptiveWeights(signals);\n      }\n      \n      // Feature extraction from each signal\n      const features = {\n        vibration: vibration ? this._extractFeatures(vibration, 'vibration') : null,\n        force: force ? this._extractFeatures(force, 'force') : null,\n        current: current ? this._extractFeatures(current, 'current') : null,\n        acoustic: acoustic ? this._extractFeatures(acoustic, 'acoustic') : null\n      };\n      \n      // Weighted feature fusion\n      const fusedFeatures = [];\n      const featureTypes = ['rms', 'kurtosis', 'crestFactor', 'spectralCentroid', 'fractalDimension'];\n      \n      for (const fType of featureTypes) {\n        let weightedSum = 0;\n        let totalWeight = 0;\n        \n        for (const [signal, feat] of Object.entries(features)) {\n          if (feat && feat[fType] !== undefined) {\n            weightedSum += feat[fType] * weights[signal];\n            totalWeight += weights[signal];\n          }\n        }\n        \n        fusedFeatures.push(totalWeight > 0 ? weightedSum / totalWeight : 0);\n      }\n      \n      return {\n        features: fusedFeatures,\n        featureNames: featureTypes,\n        weights,\n        individualFeatures: features\n      };\n    },\n    \n    /**\n     * Detect chatter using fused features and hybrid neural network\n     */\n    detectChatter: function(fusedData, model = null) {\n      // Use pre-trained model or simple threshold-based detection\n      if (model && model.trained) {\n        return this._neuralNetworkDetect(fusedData, model);\n      }\n      \n      // Threshold-based detection using physics-informed rules\n      const features = fusedData.features;\n      const [rms, kurtosis, crestFactor, spectralCentroid, fractalDim] = features;\n      \n      // Chatter indicators (from research)\n      const chatterIndicators = {\n        highKurtosis: kurtosis > 4.0,           // Non-Gaussian => chatter\n        highCrestFactor: crestFactor > 5.0,     // Impulsive => chatter\n        frequencyShift: spectralCentroid > 0.3, // Shifted spectrum\n        lowFractal: fractalDim < 1.3            // Less complex signal\n      };\n      \n      const chatterScore = (\n        (chatterIndicators.highKurtosis ? 0.3 : 0) +\n        (chatterIndicators.highCrestFactor ? 0.3 : 0) +\n        (chatterIndicators.frequencyShift ? 0.2 : 0) +\n        (chatterIndicators.lowFractal ? 0.2 : 0)\n      );\n      \n      return {\n        chatterDetected: chatterScore > 0.5,\n        chatterScore,\n        indicators: chatterIndicators,\n        confidence: Math.abs(chatterScore - 0.5) * 2\n      };\n    },\n    \n    /**\n     * Structure Function Method (SFM) for fractal feature extraction\n     * Source: MDPI Sensors 2021\n     */\n    structureFunctionMethod: function(signal, maxOrder = 5) {\n      const n = signal.length;\n      const results = [];\n      \n      for (let order = 1; order <= maxOrder; order++) {\n        // Compute structure function S_q(\u03c4) for different lags\n        const lags = [1, 2, 4, 8, 16, 32];\n        const structureValues = [];\n        \n        for (const tau of lags) {\n          if (tau >= n) continue;\n          \n          let sum = 0;\n          for (let i = 0; i < n - tau; i++) {\n            sum += Math.pow(Math.abs(signal[i + tau] - signal[i]), order);\n          }\n          structureValues.push({\n            tau,\n            value: sum / (n - tau)\n          });\n        }\n        \n        // Estimate Hurst exponent from log-log slope\n        if (structureValues.length >= 2) {\n          const logTau = structureValues.map(s => Math.log(s.tau));\n          const logS = structureValues.map(s => Math.log(s.value + 1e-10));\n          \n          const slope = this._linearRegression(logTau, logS).slope;\n          results.push({\n            order,\n            hurstExponent: slope / order,\n            structureFunction: structureValues\n          });\n        }\n      }\n      \n      // Fractal dimension D = 2 - H (for 1D signal)\n      const avgHurst = results.reduce((sum, r) => sum + r.hurstExponent, 0) / results.length;\n      const fractalDimension = 2 - avgHurst;\n      \n      return {\n        fractalDimension,\n        hurstExponent: avgHurst,\n        structureAnalysis: results\n      };\n    },\n    \n    _extractFeatures: function(signal, type) {\n      const n = signal.length;\n      if (n === 0) return null;\n      \n      // RMS\n      const rms = Math.sqrt(signal.reduce((sum, x) => sum + x * x, 0) / n);\n      \n      // Mean\n      const mean = signal.reduce((sum, x) => sum + x, 0) / n;\n      \n      // Variance and std\n      const variance = signal.reduce((sum, x) => sum + (x - mean) ** 2, 0) / n;\n      const std = Math.sqrt(variance);\n      \n      // Kurtosis (normalized 4th moment)\n      const kurtosis = signal.reduce((sum, x) => sum + Math.pow((x - mean) / std, 4), 0) / n;\n      \n      // Crest factor (peak / RMS)\n      const peak = Math.max(...signal.map(Math.abs));\n      const crestFactor = peak / rms;\n      \n      // Spectral features (simplified - using signal variance as proxy)\n      const spectralCentroid = variance / (rms + 1e-10);\n      \n      // Fractal dimension\n      const fractal = this.structureFunctionMethod(signal);\n      \n      return {\n        rms,\n        mean,\n        std,\n        kurtosis,\n        crestFactor,\n        peak,\n        spectralCentroid,\n        fractalDimension: fractal.fractalDimension\n      };\n    },\n    \n    _computeAdaptiveWeights: function(signals) {\n      const weights = {};\n      let totalQuality = 0;\n      \n      for (const [name, signal] of Object.entries(signals)) {\n        if (signal && signal.length > 0) {\n          // Signal quality based on SNR estimate\n          const mean = signal.reduce((s, x) => s + x, 0) / signal.length;\n          const variance = signal.reduce((s, x) => s + (x - mean) ** 2, 0) / signal.length;\n          const snr = variance > 0 ? Math.abs(mean) / Math.sqrt(variance) : 0;\n          \n          weights[name] = 1 + snr;\n          totalQuality += weights[name];\n        } else {\n          weights[name] = 0;\n        }\n      }\n      \n      // Normalize\n      for (const name of Object.keys(weights)) {\n        weights[name] /= totalQuality || 1;\n      }\n      \n      return weights;\n    },\n    \n    _linearRegression: function(x, y) {\n      const n = x.length;\n      const sumX = x.reduce((a, b) => a + b, 0);\n      const sumY = y.reduce((a, b) => a + b, 0);\n      const sumXY = x.reduce((sum, xi, i) => sum + xi * y[i], 0);\n      const sumXX = x.reduce((sum, xi) => sum + xi * xi, 0);\n      \n      const slope = (n * sumXY - sumX * sumY) / (n * sumXX - sumX * sumX);\n      const intercept = (sumY - slope * sumX) / n;\n      \n      return { slope, intercept };\n    },\n    \n    _neuralNetworkDetect: function(fusedData, model) {\n      // Placeholder for trained neural network inference\n      // In production, this would use the trained PGML model\n      return this.detectChatter(fusedData, null);\n    }\n  },\n\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  // ONLINE CONTINUOUS LEARNING FOR SLD\n  // Source: ScienceDirect - Continuous Learning SVM (2015)\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n  /**\n   * Continuously updating SLD model that learns from production data\n   */\n  continuousLearningSLD: {\n    name: 'ContinuousLearning_SLD',\n    \n    /**\n     * Initialize continuous learning model\n     */\n    initialize: function(baseSLD, trustThreshold = 0.7) {\n      return {\n        baseSLD: baseSLD,\n        observations: [],\n        trust: new Map(), // Region trust scores\n        trustThreshold,\n        updateCount: 0\n      };\n    },\n    \n    /**\n     * Add new observation from production\n     */\n    addObservation: function(model, rpm, ap, stable, confidence = 1.0) {\n      model.observations.push({\n        rpm, ap, stable, confidence,\n        timestamp: Date.now()\n      });\n      \n      // Update local trust\n      const regionKey = `${Math.round(rpm / 500)}_${Math.round(ap * 10)}`;\n      const currentTrust = model.trust.get(regionKey) || 0;\n      model.trust.set(regionKey, Math.min(1, currentTrust + 0.1 * confidence));\n      \n      model.updateCount++;\n      \n      // Trigger retraining if enough new data\n      if (model.updateCount >= 10) {\n        this.retrain(model);\n        model.updateCount = 0;\n      }\n    },\n    \n    /**\n     * Retrain model with accumulated observations\n     * Uses Bayesian update to combine prior (physics) with observations\n     */\n    retrain: function(model) {\n      const recentObs = model.observations.slice(-100); // Last 100 observations\n      \n      if (recentObs.length < 5) return;\n      \n      console.log(`[ContinuousLearning] Retraining with ${recentObs.length} observations`);\n      \n      // Bayesian update of SLD boundary\n      // Prior: base SLD from physics model\n      // Likelihood: from observations\n      \n      // Group observations by RPM region\n      const regionUpdates = new Map();\n      \n      for (const obs of recentObs) {\n        const rpmRegion = Math.round(obs.rpm / 100) * 100;\n        if (!regionUpdates.has(rpmRegion)) {\n          regionUpdates.set(rpmRegion, { stable: [], unstable: [] });\n        }\n        \n        if (obs.stable) {\n          regionUpdates.get(rpmRegion).stable.push(obs.ap);\n        } else {\n          regionUpdates.get(rpmRegion).unstable.push(obs.ap);\n        }\n      }\n      \n      // Update boundary estimates\n      const newBoundary = [];\n      for (const point of model.baseSLD.boundary || model.baseSLD.boundaryPoints) {\n        const rpmRegion = Math.round(point.rpm / 100) * 100;\n        const updates = regionUpdates.get(rpmRegion);\n        \n        if (updates && (updates.stable.length > 0 || updates.unstable.length > 0)) {\n          // Bayesian update\n          const maxStable = Math.max(...updates.stable, 0);\n          const minUnstable = Math.min(...updates.unstable, Infinity);\n          \n          // Posterior estimate (weighted average of prior and observation)\n          const observedBoundary = (maxStable + minUnstable) / 2;\n          const trust = model.trust.get(`${rpmRegion / 500}_${Math.round(point.ap * 10)}`) || 0.5;\n          \n          const posteriorAp = point.ap * (1 - trust) + observedBoundary * trust;\n          \n          newBoundary.push({\n            rpm: point.rpm,\n            ap: posteriorAp,\n            confidence: trust\n          });\n        } else {\n          newBoundary.push({ ...point, confidence: 0.5 });\n        }\n      }\n      \n      model.updatedSLD = { boundary: newBoundary };\n      \n      return model;\n    },\n    \n    /**\n     * Predict stability with trust-weighted prediction\n     */\n    predict: function(model, rpm, ap) {\n      const regionKey = `${Math.round(rpm / 500)}_${Math.round(ap * 10)}`;\n      const trust = model.trust.get(regionKey) || 0.5;\n      \n      // Get boundary at this RPM\n      const sld = model.updatedSLD || model.baseSLD;\n      let boundary = null;\n      \n      for (let i = 0; i < sld.boundary.length - 1; i++) {\n        const p1 = sld.boundary[i];\n        const p2 = sld.boundary[i + 1];\n        \n        if (rpm >= p1.rpm && rpm <= p2.rpm) {\n          const t = (rpm - p1.rpm) / (p2.rpm - p1.rpm);\n          boundary = p1.ap + t * (p2.ap - p1.ap);\n          break;\n        }\n      }\n      \n      if (boundary === null) {\n        boundary = sld.boundary[0].ap;\n      }\n      \n      return {\n        stable: ap < boundary,\n        boundaryAp: boundary,\n        margin: boundary - ap,\n        trustScore: trust,\n        reliable: trust >= model.trustThreshold\n      };\n    }\n  },\n\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  // SELF-TEST\n  // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n  selfTest: function() {\n    const results = [];\n    \n    // Test 1: Semi-discretization method\n    const system = { mass: 0.1, stiffness: 1e7, damping: 100 };\n    const cutting = { Kc: 1500e6, teeth: 4, radialImmersion: 0.5 };\n    const sdm = this.semiDiscretization(system, cutting);\n    \n    const stabilityResult = sdm.checkStability(10000, 2);\n    results.push({\n      name: 'Semi-Discretization Method',\n      passed: typeof stabilityResult.stable === 'boolean',\n      details: `RPM=10000, ap=2mm, stable=${stabilityResult.stable}`\n    });\n    \n    // Test 2: PGML initialization\n    const pgmlModel = this.pgmlStabilityModel.initialize(\n      { system, cutting },\n      { layers: [16, 8] }\n    );\n    results.push({\n      name: 'PGML Model Initialization',\n      passed: pgmlModel !== null && pgmlModel.physics !== null,\n      details: 'Model initialized with physics base'\n    });\n    \n    // Test 3: Multi-modal feature extraction\n    const testSignal = Array.from({ length: 1000 }, () => Math.random() - 0.5);\n    const fusedData = this.multiModalChatterDetector.fuseSignals({\n      vibration: testSignal,\n      force: null\n    });\n    results.push({\n      name: 'Multi-Modal Feature Extraction',\n      passed: fusedData.features.length === 5,\n      details: `Extracted ${fusedData.features.length} fused features`\n    });\n    \n    // Test 4: Fractal dimension computation\n    const fractal = this.multiModalChatterDetector.structureFunctionMethod(testSignal);\n    results.push({\n      name: 'Fractal Dimension (SFM)',\n      passed: fractal.fractalDimension > 0 && fractal.fractalDimension < 3,\n      details: `D = ${fractal.fractalDimension.toFixed(3)}`\n    });\n    \n    // Test 5: Continuous learning SLD\n    const baseSLD = sdm.generateSLD([5000, 15000], [0.5, 5], 20);\n    const clModel = this.continuousLearningSLD.initialize(baseSLD);\n    this.continuousLearningSLD.addObservation(clModel, 10000, 3, true, 0.9);\n    results.push({\n      name: 'Continuous Learning SLD',\n      passed: clModel.observations.length === 1,\n      details: 'Observation added and model updated'\n    });\n    \n    console.log('[PRISM_PIML_CHATTER_ENGINE] Self-test results:');\n    results.forEach(r => {\n      console.log(`  ${r.passed ? '\u2713' : '\u2717'} ${r.name}: ${r.details}`);\n    });\n    \n    return {\n      passed: results.every(r => r.passed),\n      results\n    };\n  }\n};\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// GATEWAY ROUTE REGISTRATION\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nconst SESSION4_PIML_ROUTES = {\n  // Semi-Discretization\n  'piml.sdm.create': 'PRISM_PIML_CHATTER_ENGINE.semiDiscretization',\n  \n  // PGML\n  'piml.pgml.initialize': 'PRISM_PIML_CHATTER_ENGINE.pgmlStabilityModel.initialize',\n  'piml.pgml.train': 'PRISM_PIML_CHATTER_ENGINE.pgmlStabilityModel.train',\n  'piml.pgml.predict': 'PRISM_PIML_CHATTER_ENGINE.pgmlStabilityModel.predict',\n  'piml.pgml.generateSLD': 'PRISM_PIML_CHATTER_ENGINE.pgmlStabilityModel.generateSLD',\n  \n  // Multi-Modal\n  'piml.multimodal.fuse': 'PRISM_PIML_CHATTER_ENGINE.multiModalChatterDetector.fuseSignals',\n  'piml.multimodal.detect': 'PRISM_PIML_CHATTER_ENGINE.multiModalChatterDetector.detectChatter',\n  'piml.multimodal.fractal': 'PRISM_PIML_CHATTER_ENGINE.multiModalChatterDetector.structureFunctionMethod',\n  \n  // Continuous Learning\n  'piml.continuous.initialize': 'PRISM_PIML_CHATTER_ENGINE.continuousLearningSLD.initialize',\n  'piml.continuous.addObservation': 'PRISM_PIML_CHATTER_ENGINE.continuousLearningSLD.addObservation',\n  'piml.continuous.predict': 'PRISM_PIML_CHATTER_ENGINE.continuousLearningSLD.predict',\n  'piml.continuous.retrain': 'PRISM_PIML_CHATTER_ENGINE.continuousLearningSLD.retrain',\n  \n  // Test\n  'piml.test': 'PRISM_PIML_CHATTER_ENGINE.selfTest'\n};\n\n// Registration function\nfunction registerSession4PIML() {\n  if (typeof PRISM_GATEWAY !== 'undefined') {\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// PRISM PHASE 1 - 220 COURSES UTILIZATION INTEGRATION\n// Added: v8.87.001 - January 18, 2026\n// 30 algorithms | 28 gateway routes | AI-enhanced Speed & Feed Calculator\n// Sources: MIT 15.099, MIT 18.433, MIT 6.036, MIT 18.086, MIT 2.008, MIT 2.830\n// Stanford CS229, Berkeley EE123, CMU 24-785\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n/**\n * \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n * PRISM PHASE 1 - COURSES UTILIZATION INTEGRATION\n * \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n * \n * Version: 1.0.0\n * Date: January 18, 2026\n * Build Target: v8.87.001\n * \n * PURPOSE: Integrate 30 Phase 1 algorithms from 220 university courses into PRISM\n * \n * PHASE 1 ALGORITHMS (30):\n * \u251c\u2500\u2500 Optimization: PSO, ACO, Genetic Algorithm\n * \u251c\u2500\u2500 Machine Learning: Linear Regression, Random Forest\n * \u251c\u2500\u2500 Signal Processing: FFT, Butterworth Filter\n * \u251c\u2500\u2500 Manufacturing: Taylor Tool Life, Merchant Force, Stability Lobes\n * \u2514\u2500\u2500 Additional: Newton, BFGS, K-Means, Kalman Filter\n * \n * PROTOCOLS FOLLOWED (v12.0):\n * \u251c\u2500\u2500 Protocol A: Gateway-First Development\n * \u251c\u2500\u2500 Protocol B: Unit-Safe Development  \n * \u251c\u2500\u2500 Protocol C: Compare-Safe Development\n * \u251c\u2500\u2500 Protocol E: Constants-First Development\n * \u251c\u2500\u2500 Protocol F: Validation-First Development\n * \u251c\u2500\u2500 Protocol J: Innovation-First Development\n * \u251c\u2500\u2500 Protocol K: Knowledge-First Development\n * \u251c\u2500\u2500 Protocol O: AI-First Development\n * \u2514\u2500\u2500 Protocol P: Learning-First Development\n * \n * SOURCES:\n * \u251c\u2500\u2500 MIT 15.099: PSO, Optimization\n * \u251c\u2500\u2500 MIT 18.433: ACO, Combinatorial Optimization\n * \u251c\u2500\u2500 MIT 6.036: Linear Regression, ML Fundamentals\n * \u251c\u2500\u2500 MIT 18.086: FFT, Signal Processing\n * \u251c\u2500\u2500 MIT 2.008: Taylor Tool Life, Merchant Force\n * \u251c\u2500\u2500 MIT 2.830: Stability Lobes, Chatter Analysis\n * \u251c\u2500\u2500 Stanford CS229: Random Forest, ML\n * \u251c\u2500\u2500 Berkeley EE123: Butterworth Filter, Signal Processing\n * \u2514\u2500\u2500 CMU 24-785: Genetic Algorithm\n * \n * \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n */\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// PHASE 1 MASTER COORDINATOR\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nconst PRISM_PHASE1_COORDINATOR = {\n    version: '1.0.0',\n    phase: 1,\n    name: 'Immediate Integration',\n    targetUtilization: 100,\n    algorithmsIntegrated: 0,\n    totalAlgorithms: 30,\n    \n    status: {\n        initialized: false,\n        gatewayRoutesRegistered: 0,\n        calculatorIntegrated: false,\n        chatterDetectionConnected: false,\n        toolLifeLinked: false,\n        learningPipelineActive: false\n    },\n    \n    /**\n     * Initialize Phase 1 Integration\n     * Protocol A: All calls through PRISM_GATEWAY\n     */\n    initialize: function() {\n        console.log('\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557');\n        console.log('\u2551  PRISM Phase 1 - 220 Courses Utilization Integration            \u2551');\n        console.log('\u2551  Target: 30 algorithms at 100% utilization                      \u2551');\n        console.log('\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d');\n        \n        // Step 1: Register all Phase 1 gateway routes\n        const routeResult = PRISM_PHASE1_GATEWAY_ROUTES.registerAll();\n        this.status.gatewayRoutesRegistered = routeResult.registered;\n        \n        // Step 2: Initialize AI-enhanced calculator\n        if (typeof PRISM_PHASE1_SPEED_FEED_CALCULATOR !== 'undefined') {\n            PRISM_PHASE1_SPEED_FEED_CALCULATOR.initialize();\n            this.status.calculatorIntegrated = true;\n        }\n        \n        // Step 3: Connect chatter detection system\n        if (typeof PRISM_PHASE1_CHATTER_SYSTEM !== 'undefined') {\n            PRISM_PHASE1_CHATTER_SYSTEM.initialize();\n            this.status.chatterDetectionConnected = true;\n        }\n        \n        // Step 4: Link tool life management\n        if (typeof PRISM_PHASE1_TOOL_LIFE_MANAGER !== 'undefined') {\n            PRISM_PHASE1_TOOL_LIFE_MANAGER.initialize();\n            this.status.toolLifeLinked = true;\n        }\n        \n        // Step 5: Activate learning pipeline\n        if (typeof PRISM_AI_LEARNING_PIPELINE !== 'undefined') {\n            this.status.learningPipelineActive = true;\n        }\n        \n        this.status.initialized = true;\n        this.algorithmsIntegrated = this._countIntegratedAlgorithms();\n        \n        console.log(`[Phase 1] Initialized: ${this.algorithmsIntegrated}/${this.totalAlgorithms} algorithms`);\n        console.log(`[Phase 1] Gateway routes: ${this.status.gatewayRoutesRegistered}`);\n        \n        return {\n            success: true,\n            algorithmsIntegrated: this.algorithmsIntegrated,\n            gatewayRoutes: this.status.gatewayRoutesRegistered,\n            status: this.status\n        };\n    },\n    \n    _countIntegratedAlgorithms: function() {\n        let count = 0;\n        const algorithms = [\n            'opt.pso', 'opt.aco', 'opt.genetic', 'opt.newton', 'opt.bfgs',\n            'ml.linear_regression', 'ml.random_forest', 'ml.kmeans',\n            'signal.fft', 'signal.butterworth', 'signal.stability_lobes',\n            'mfg.taylor_tool_life', 'mfg.merchant_force', 'mfg.mrr',\n            'ai.kalman.predict', 'physics.cutting_force', 'physics.tool_life'\n        ];\n        \n        if (typeof PRISM_GATEWAY !== 'undefined') {\n            algorithms.forEach(route => {\n                if (PRISM_GATEWAY.routes && PRISM_GATEWAY.routes[route]) {\n                    count++;\n                }\n            });\n        }\n        return count;\n    },\n    \n    /**\n     * Get Phase 1 status report\n     */\n    getStatus: function() {\n        return {\n            phase: this.phase,\n            name: this.name,\n            version: this.version,\n            progress: `${this.algorithmsIntegrated}/${this.totalAlgorithms}`,\n            utilization: Math.round((this.algorithmsIntegrated / this.totalAlgorithms) * 100) + '%',\n            status: this.status,\n            targetUtilization: this.targetUtilization + '%'\n        };\n    }\n};\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// PHASE 1 GATEWAY ROUTES REGISTRATION\n// Protocol A: Gateway-First Development\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nconst PRISM_PHASE1_GATEWAY_ROUTES = {\n    routes: {\n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        // OPTIMIZATION ALGORITHMS (MIT 15.099, MIT 18.433, CMU 24-785)\n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        'phase1.pso.speed_feed': 'PRISM_PHASE1_OPTIMIZERS.psoSpeedFeed',\n        'phase1.pso.multi_objective': 'PRISM_PHASE1_OPTIMIZERS.psoMultiObjective',\n        'phase1.aco.hole_sequence': 'PRISM_PHASE1_OPTIMIZERS.acoHoleSequence',\n        'phase1.aco.routing': 'PRISM_PHASE1_OPTIMIZERS.acoRouting',\n        'phase1.genetic.toolpath': 'PRISM_PHASE1_OPTIMIZERS.geneticToolpath',\n        'phase1.genetic.parameters': 'PRISM_PHASE1_OPTIMIZERS.geneticParameters',\n        'phase1.newton.optimize': 'PRISM_PHASE1_OPTIMIZERS.newtonOptimize',\n        'phase1.bfgs.optimize': 'PRISM_PHASE1_OPTIMIZERS.bfgsOptimize',\n        \n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        // MACHINE LEARNING (MIT 6.036, Stanford CS229)\n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        'phase1.ml.linear_predict': 'PRISM_PHASE1_ML.linearPredict',\n        'phase1.ml.ridge_predict': 'PRISM_PHASE1_ML.ridgePredict',\n        'phase1.ml.forest_predict': 'PRISM_PHASE1_ML.randomForestPredict',\n        'phase1.ml.forest_tool_life': 'PRISM_PHASE1_ML.forestToolLifePredict',\n        'phase1.ml.kmeans_cluster': 'PRISM_PHASE1_ML.kmeansCluster',\n        \n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        // SIGNAL PROCESSING (MIT 18.086, Berkeley EE123)\n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        'phase1.signal.fft_analyze': 'PRISM_PHASE1_SIGNAL.fftAnalyze',\n        'phase1.signal.fft_chatter': 'PRISM_PHASE1_SIGNAL.fftChatterDetect',\n        'phase1.signal.butterworth': 'PRISM_PHASE1_SIGNAL.butterworthFilter',\n        'phase1.signal.stability_lobes': 'PRISM_PHASE1_SIGNAL.stabilityLobes',\n        'phase1.signal.spectral_density': 'PRISM_PHASE1_SIGNAL.spectralDensity',\n        \n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        // MANUFACTURING PHYSICS (MIT 2.008, MIT 2.830)\n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        'phase1.mfg.taylor_tool_life': 'PRISM_PHASE1_MANUFACTURING.taylorToolLife',\n        'phase1.mfg.extended_taylor': 'PRISM_PHASE1_MANUFACTURING.extendedTaylor',\n        'phase1.mfg.merchant_force': 'PRISM_PHASE1_MANUFACTURING.merchantForce',\n        'phase1.mfg.kienzle_force': 'PRISM_PHASE1_MANUFACTURING.kienzleForce',\n        'phase1.mfg.mrr': 'PRISM_PHASE1_MANUFACTURING.materialRemovalRate',\n        'phase1.mfg.surface_finish': 'PRISM_PHASE1_MANUFACTURING.surfaceFinish',\n        'phase1.mfg.cutting_temperature': 'PRISM_PHASE1_MANUFACTURING.cuttingTemperature',\n        \n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        // INTEGRATED AI CALCULATOR\n        // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        'phase1.calc.speed_feed': 'PRISM_PHASE1_SPEED_FEED_CALCULATOR.calculate',\n        'phase1.calc.ai_optimize': 'PRISM_PHASE1_SPEED_FEED_CALCULATOR.aiOptimize',\n        'phase1.calc.full_analysis': 'PRISM_PHASE1_SPEED_FEED_CALCULATOR.fullAnalysis'\n    },\n    \n    registerAll: function() {\n        let registered = 0;\n        let failed = 0;\n        \n        if (typeof PRISM_GATEWAY === 'undefined') {\n            console.error('[Phase 1] PRISM_GATEWAY not found');\n            return { registered: 0, failed: Object.keys(this.routes).length };\n        }\n        \n        for (const [route, target] of Object.entries(this.routes)) {\n            try {\n                PRISM_GATEWAY.register(route, target);\n                registered++;\n            } catch (e) {\n                console.warn(`[Phase 1] Failed to register route: ${route}`);\n                failed++;\n            }\n        }\n        \n        console.log(`[Phase 1 Routes] Registered: ${registered}, Failed: ${failed}`);\n        return { registered, failed };\n    }\n};\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// PHASE 1 OPTIMIZATION ALGORITHMS\n// Sources: MIT 15.099, MIT 18.433, CMU 24-785\n// Protocol J: Innovation-First Development\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nconst PRISM_PHASE1_OPTIMIZERS = {\n    name: 'Phase 1 Optimization Algorithms',\n    version: '1.0.0',\n    source: 'MIT 15.099, MIT 18.433, CMU 24-785',\n    \n    /**\n     * PSO Speed/Feed Multi-Objective Optimization\n     * Source: MIT 15.099 - Introduction to Optimization\n     * Protocol B: Unit-Safe Development (metric internal)\n     */\n    psoSpeedFeed: function(params) {\n        const {\n            material,\n            tool,\n            machine,\n            objectives = ['productivity', 'tool_life', 'surface_finish'],\n            constraints = {}\n        } = params;\n        \n        // Protocol E: Constants-First Development\n        const PSO_CONFIG = {\n            particles: typeof PRISM_CONSTANTS !== 'undefined' ? \n                PRISM_CONSTANTS.AI.PSO_MAX_PARTICLES : 30,\n            iterations: typeof PRISM_CONSTANTS !== 'undefined' ? \n                PRISM_CONSTANTS.AI.PSO_MAX_ITERATIONS : 100,\n            w: 0.729,      // Inertia weight\n            c1: 1.49445,   // Cognitive parameter\n            c2: 1.49445    // Social parameter\n        };\n        \n        // Define search bounds (metric internal - Protocol B)\n        const bounds = {\n            speed: { min: 50, max: 500 },      // m/min\n            feed: { min: 0.05, max: 0.5 },     // mm/tooth\n            doc: { min: 0.5, max: 10 }         // mm\n        };\n        \n        // Apply material constraints\n        if (material && material.speedRange) {\n            bounds.speed.min = Math.max(bounds.speed.min, material.speedRange.min || 50);\n            bounds.speed.max = Math.min(bounds.speed.max, material.speedRange.max || 500);\n        }\n        \n        // Initialize particles\n        const particles = [];\n        for (let i = 0; i < PSO_CONFIG.particles; i++) {\n            particles.push({\n                position: {\n                    speed: bounds.speed.min + Math.random() * (bounds.speed.max - bounds.speed.min),\n                    feed: bounds.feed.min + Math.random() * (bounds.feed.max - bounds.feed.min),\n                    doc: bounds.doc.min + Math.random() * (bounds.doc.max - bounds.doc.min)\n                },\n                velocity: { speed: 0, feed: 0, doc: 0 },\n                bestPosition: null,\n                bestFitness: -Infinity\n            });\n            particles[i].bestPosition = { ...particles[i].position };\n        }\n        \n        let globalBest = { position: null, fitness: -Infinity };\n        \n        // PSO main loop\n        for (let iter = 0; iter < PSO_CONFIG.iterations; iter++) {\n            for (const particle of particles) {\n                // Evaluate fitness (multi-objective)\n                const fitness = this._evaluateSpeedFeedFitness(\n                    particle.position, material, tool, machine, objectives\n                );\n                \n                // Update personal best\n                if (fitness > particle.bestFitness) {\n                    particle.bestFitness = fitness;\n                    particle.bestPosition = { ...particle.position };\n                }\n                \n                // Update global best\n                if (fitness > globalBest.fitness) {\n                    globalBest.fitness = fitness;\n                    globalBest.position = { ...particle.position };\n                }\n            }\n            \n            // Update velocities and positions\n            for (const particle of particles) {\n                for (const dim of ['speed', 'feed', 'doc']) {\n                    const r1 = Math.random();\n                    const r2 = Math.random();\n                    \n                    particle.velocity[dim] = \n                        PSO_CONFIG.w * particle.velocity[dim] +\n                        PSO_CONFIG.c1 * r1 * (particle.bestPosition[dim] - particle.position[dim]) +\n                        PSO_CONFIG.c2 * r2 * (globalBest.position[dim] - particle.position[dim]);\n                    \n                    particle.position[dim] += particle.velocity[dim];\n                    \n                    // Clamp to bounds\n                    particle.position[dim] = Math.max(bounds[dim].min, \n                        Math.min(bounds[dim].max, particle.position[dim]));\n                }\n            }\n        }\n        \n        // Return optimized parameters with confidence\n        return {\n            optimizedParams: globalBest.position,\n            fitness: globalBest.fitness,\n            objectives: objectives,\n            source: 'MIT 15.099 - PSO Multi-Objective',\n            confidence: Math.min(0.95, 0.7 + globalBest.fitness * 0.25),\n            iterations: PSO_CONFIG.iterations,\n            particles: PSO_CONFIG.particles\n        };\n    },\n    \n    /**\n     * Evaluate fitness for speed/feed optimization\n     * Protocol O: AI-First Development\n     */\n    _evaluateSpeedFeedFitness: function(position, material, tool, machine, objectives) {\n        let fitness = 0;\n        const weights = {\n            productivity: 0.4,\n            tool_life: 0.35,\n            surface_finish: 0.25\n        };\n        \n        // Calculate MRR (productivity)\n        const mrr = position.speed * position.feed * position.doc;\n        const mrrNormalized = mrr / 100; // Normalize\n        \n        // Estimate tool life using Taylor equation\n        const toolLife = this._estimateToolLife(position.speed, material);\n        const toolLifeNormalized = Math.min(1, toolLife / 120); // Normalize to 120 min baseline\n        \n        // Estimate surface finish (lower is better)\n        const surfaceFinish = this._estimateSurfaceFinish(position.feed, tool);\n        const surfaceFinishNormalized = 1 - Math.min(1, surfaceFinish / 3.2); // Normalize to Ra 3.2\n        \n        // Weight objectives\n        if (objectives.includes('productivity')) {\n            fitness += weights.productivity * mrrNormalized;\n        }\n        if (objectives.includes('tool_life')) {\n            fitness += weights.tool_life * toolLifeNormalized;\n        }\n        if (objectives.includes('surface_finish')) {\n            fitness += weights.surface_finish * surfaceFinishNormalized;\n        }\n        \n        return fitness;\n    },\n    \n    _estimateToolLife: function(speed, material) {\n        // Taylor's equation: VT^n = C\n        const n = material?.taylorN || 0.25;\n        const C = material?.taylorC || 300;\n        return Math.pow(C / speed, 1 / n);\n    }",
      "methods": [],
      "lines": 1555
    },
    {
      "name": "PRISM_SURFACE_FINISH_ENGINE",
      "category": "engines",
      "refs": 317,
      "status": "FOUND",
      "code": "const PRISM_SURFACE_FINISH_ENGINE = {\n  version: '1.0.0',\n\n  // SURFACE FINISH DATABASE - ISO 1302 / ASME Y14.36\n\n  database: {\n    // ISO N-Number to Ra conversion\n    nNumberToRa: {\n      N1:  { ra_um: 0.025, ra_uin: 1,    description: 'Super finish, lapping' },\n      N2:  { ra_um: 0.05,  ra_uin: 2,    description: 'Super finish, honing' },\n      N3:  { ra_um: 0.1,   ra_uin: 4,    description: 'Mirror finish, polishing' },\n      N4:  { ra_um: 0.2,   ra_uin: 8,    description: 'Fine grinding, lapping' },\n      N5:  { ra_um: 0.4,   ra_uin: 16,   description: 'Precision grinding' },\n      N6:  { ra_um: 0.8,   ra_uin: 32,   description: 'Grinding, fine turning' },\n      N7:  { ra_um: 1.6,   ra_uin: 63,   description: 'Fine machining' },\n      N8:  { ra_um: 3.2,   ra_uin: 125,  description: 'Standard machining' },\n      N9:  { ra_um: 6.3,   ra_uin: 250,  description: 'Roughing' },\n      N10: { ra_um: 12.5,  ra_uin: 500,  description: 'Heavy roughing' },\n      N11: { ra_um: 25,    ra_uin: 1000, description: 'Casting, forging' },\n      N12: { ra_um: 50,    ra_uin: 2000, description: 'Rough casting' }\n    },\n    // Triangle symbols (older notation)\n    triangleSymbols: {\n      '\u25bd':     { ra_uin: 1000, description: 'Rough - remove material' },\n      '\u25bd\u25bd':    { ra_uin: 250,  description: 'Medium finish' },\n      '\u25bd\u25bd\u25bd':   { ra_uin: 63,   description: 'Fine finish' },\n      '\u25bd\u25bd\u25bd\u25bd':  { ra_uin: 16,   description: 'Very fine finish' }\n    },\n    // Common surface finish specifications\n    commonSpecs: {\n      'as_cast':        { ra_uin: 500,  ra_um: 12.5 },\n      'sand_cast':      { ra_uin: 1000, ra_um: 25 },\n      'investment_cast': { ra_uin: 125,  ra_um: 3.2 },\n      'rough_turn':     { ra_uin: 250,  ra_um: 6.3 },\n      'finish_turn':    { ra_uin: 63,   ra_um: 1.6 },\n      'precision_turn': { ra_uin: 32,   ra_um: 0.8 },\n      'rough_mill':     { ra_uin: 250,  ra_um: 6.3 },\n      'finish_mill':    { ra_uin: 63,   ra_um: 1.6 },\n      'ball_end_mill':  { ra_uin: 32,   ra_um: 0.8 },\n      'surface_grind':  { ra_uin: 16,   ra_um: 0.4 },\n      'cylindrical_grind': { ra_uin: 8, ra_um: 0.2 },\n      'centerless_grind': { ra_uin: 8,  ra_um: 0.2 },\n      'hone':           { ra_uin: 4,    ra_um: 0.1 },\n      'lap':            { ra_uin: 2,    ra_um: 0.05 },\n      'superfinish':    { ra_uin: 1,    ra_um: 0.025 },\n      'polish':         { ra_uin: 4,    ra_um: 0.1 },\n      'electropolish':  { ra_uin: 8,    ra_um: 0.2 }\n    },\n    // Ra to Rz approximate conversion (Rz \u2248 4-7 \u00d7 Ra)\n    raToRzFactor: 5.0\n  },\n  // FINISH TO MACHINING STRATEGY MAPPING\n\n  finishToStrategy: {\n    // Ultra-fine finishes (Ra < 0.4 \u03bcm / < 16 \u03bcin)\n    ultraFine: {\n      raRange: { min: 0, max: 0.4 },\n      strategies: [\n        { name: 'GRINDING', type: 'grinding', priority: 1 },\n        { name: 'HONING', type: 'honing', priority: 2 },\n        { name: 'LAPPING', type: 'lapping', priority: 3 },\n        { name: 'POLISHING', type: 'polish', priority: 4 }\n      ],\n      parameters: {\n        stepover: 0.05,  // mm\n        feedMultiplier: 0.3,\n        speedMultiplier: 1.2,\n        springPasses: 2\n      }\n    },\n    // Fine finishes (Ra 0.4-1.6 \u03bcm / 16-63 \u03bcin)\n    fine: {\n      raRange: { min: 0.4, max: 1.6 },\n      strategies: [\n        { name: 'FINISH_MILL', type: 'finish', priority: 1 },\n        { name: 'PRECISION_TURN', type: 'finish_turn', priority: 1 },\n        { name: 'LIGHT_GRINDING', type: 'grinding', priority: 2 }\n      ],\n      parameters: {\n        stepover: 0.15,  // mm\n        feedMultiplier: 0.5,\n        speedMultiplier: 1.1,\n        springPasses: 1\n      }\n    },\n    // Standard finishes (Ra 1.6-6.3 \u03bcm / 63-250 \u03bcin)\n    standard: {\n      raRange: { min: 1.6, max: 6.3 },\n      strategies: [\n        { name: 'FINISH_CONTOUR', type: 'finish', priority: 1 },\n        { name: 'FINISH_TURN', type: 'finish_turn', priority: 1 },\n        { name: 'ADAPTIVE_FINISH', type: 'hsm_finish', priority: 2 }\n      ],\n      parameters: {\n        stepover: 0.3,  // mm\n        feedMultiplier: 0.75,\n        speedMultiplier: 1.0,\n        springPasses: 0\n      }\n    },\n    // Rough finishes (Ra > 6.3 \u03bcm / > 250 \u03bcin)\n    rough: {\n      raRange: { min: 6.3, max: 100 },\n      strategies: [\n        { name: 'ADAPTIVE_ROUGH', type: 'hsm', priority: 1 },\n        { name: 'ROUGH_TURN', type: 'rough_turn', priority: 1 },\n        { name: 'FACING', type: 'face', priority: 2 }\n      ],\n      parameters: {\n        stepover: 0.5,  // as fraction of diameter\n        feedMultiplier: 1.0,\n        speedMultiplier: 1.0,\n        springPasses: 0\n      }\n    }\n  },\n  // SURFACE FINISH SYMBOL RECOGNITION\n\n  recognizeSymbol(symbolOrText) {\n    // Check for triangle symbols\n    if (this.database.triangleSymbols[symbolOrText]) {\n      return this.database.triangleSymbols[symbolOrText];\n    }\n    // Check for N-number\n    const nMatch = symbolOrText.match(/N(\\d+)/i);\n    if (nMatch) {\n      const nNum = 'N' + nMatch[1];\n      return this.database.nNumberToRa[nNum];\n    }\n    // Check for Ra value\n    const raMatch = symbolOrText.match(/Ra\\s*[=:]?\\s*(\\d+(?:\\.\\d+)?)/i);\n    if (raMatch) {\n      const raValue = parseFloat(raMatch[1]);\n      return this._raToFinishSpec(raValue);\n    }\n    // Check for microinch value\n    const uinMatch = symbolOrText.match(/(\\d+)\\s*(?:\u03bcin|\u00b5in|microinch)/i);\n    if (uinMatch) {\n      const uinValue = parseInt(uinMatch[1]);\n      return this._microinchToFinishSpec(uinValue);\n    }\n    return null;\n  },\n  _raToFinishSpec(raValue) {\n    // Determine if \u03bcm or \u03bcin based on value magnitude\n    const isMetric = raValue < 50; // Assume < 50 is \u03bcm\n    const ra_um = isMetric ? raValue : raValue * 0.0254;\n    const ra_uin = isMetric ? raValue / 0.0254 : raValue;\n\n    return {\n      ra_um: ra_um,\n      ra_uin: ra_uin,\n      rz_um: ra_um * this.database.raToRzFactor,\n      rz_uin: ra_uin * this.database.raToRzFactor\n    };\n  },\n  _microinchToFinishSpec(uinValue) {\n    return {\n      ra_um: uinValue * 0.0254,\n      ra_uin: uinValue,\n      rz_um: uinValue * 0.0254 * this.database.raToRzFactor,\n      rz_uin: uinValue * this.database.raToRzFactor\n    };\n  },\n  // MACHINING STRATEGY RECOMMENDATION\n\n  recommendStrategy(targetFinish, material = 'steel', featureType = 'surface') {\n    const finishSpec = typeof targetFinish === 'object' ? targetFinish : this.recognizeSymbol(targetFinish);\n\n    if (!finishSpec) {\n      return { error: 'Unable to parse finish specification' };\n    }\n    const ra_um = finishSpec.ra_um;\n\n    // Determine finish category\n    let category;\n    if (ra_um <= 0.4) {\n      category = this.finishToStrategy.ultraFine;\n    } else if (ra_um <= 1.6) {\n      category = this.finishToStrategy.fine;\n    } else if (ra_um <= 6.3) {\n      category = this.finishToStrategy.standard;\n    } else {\n      category = this.finishToStrategy.rough;\n    }\n    // Adjust for material\n    const materialAdjustments = this._getMaterialAdjustments(material);\n\n    // Adjust for feature type\n    const featureAdjustments = this._getFeatureAdjustments(featureType);\n\n    return {\n      targetFinish: finishSpec,\n      category: Object.keys(this.finishToStrategy).find(k => this.finishToStrategy[k] === category),\n      strategies: category.strategies,\n      parameters: {\n        ...category.parameters,\n        feedMultiplier: category.parameters.feedMultiplier * materialAdjustments.feedFactor,\n        speedMultiplier: category.parameters.speedMultiplier * materialAdjustments.speedFactor\n      },\n      notes: this._generateNotes(finishSpec, material, featureType)\n    };\n  },\n  _getMaterialAdjustments(material) {\n    const adjustments = {\n      aluminum:  { feedFactor: 1.3, speedFactor: 1.5 },\n      steel:     { feedFactor: 1.0, speedFactor: 1.0 },\n      stainless: { feedFactor: 0.7, speedFactor: 0.8 },\n      titanium:  { feedFactor: 0.5, speedFactor: 0.6 },\n      brass:     { feedFactor: 1.2, speedFactor: 1.3 },\n      plastic:   { feedFactor: 1.5, speedFactor: 2.0 },\n      cast_iron: { feedFactor: 0.9, speedFactor: 0.9 }\n    };\n    return adjustments[material] || adjustments.steel;\n  },\n  _getFeatureAdjustments(featureType) {\n    const adjustments = {\n      surface:  { stepoverFactor: 1.0 },\n      pocket:   { stepoverFactor: 0.9 },\n      contour:  { stepoverFactor: 0.8 },\n      bore:     { stepoverFactor: 0.7 },\n      fillet:   { stepoverFactor: 0.6 }\n    };\n    return adjustments[featureType] || adjustments.surface;\n  },\n  _generateNotes(finishSpec, material, featureType) {\n    const notes = [];\n\n    if (finishSpec.ra_um <= 0.4) {\n      notes.push('Consider secondary finishing operation (grinding/polishing)');\n    }\n    if (material === 'aluminum' && finishSpec.ra_um <= 1.6) {\n      notes.push('Diamond tooling recommended for best aluminum finish');\n    }\n    if (featureType === 'bore' && finishSpec.ra_um <= 0.8) {\n      notes.push('Consider honing or precision boring for bore finish');\n    }\n    return notes;\n  },\n  // ACHIEVABLE FINISH CALCULATOR\n\n  calculateAchievableFinish(params) {\n    const {\n      toolDiameter,\n      feedPerTooth,\n      cornerRadius = 0,\n      operation = 'face_mill'\n    } = params;\n\n    // Theoretical finish for face milling: Ra \u2248 f\u00b2 / (32 \u00d7 r)\n    // Where f = feed per rev, r = tool nose radius\n\n    if (operation === 'face_mill' || operation === 'end_mill') {\n      const effectiveRadius = cornerRadius || toolDiameter / 2;\n      const feedPerRev = feedPerTooth * 4; // Assume 4 flutes\n      const theoreticalRa = (feedPerRev * feedPerRev) / (32 * effectiveRadius);\n\n      return {\n        theoretical_ra_um: theoreticalRa * 1000, // Convert to \u03bcm\n        theoretical_ra_uin: theoreticalRa * 1000 / 0.0254,\n        practical_ra_um: theoreticalRa * 1000 * 1.5, // 50% worse in practice\n        practical_ra_uin: theoreticalRa * 1000 * 1.5 / 0.0254,\n        formula: 'Ra = f\u00b2 / (32 \u00d7 r)',\n        notes: 'Practical finish typically 1.5x theoretical due to vibration, tool wear'\n      };\n    }\n    if (operation === 'turn') {\n      const noseRadius = cornerRadius || 0.4; // Default 0.4mm nose radius\n      const theoreticalRa = (feedPerTooth * feedPerTooth) / (32 * noseRadius);\n\n      return {\n        theoretical_ra_um: theoreticalRa * 1000,\n        theoretical_ra_uin: theoreticalRa * 1000 / 0.0254,\n        notes: 'For turning, use insert nose radius for calculation'\n      };\n    }\n    return null;\n  },\n  // CONVERSION UTILITIES\n\n  convert: {\n    raToRz(ra, factor = 5.0) { return ra * factor; },\n    rzToRa(rz, factor = 5.0) { return rz / factor; },\n    umToUin(um) { return um / 0.0254; },\n    uinToUm(uin) { return uin * 0.0254; },\n    nToRa(nNumber) {\n      const spec = PRISM_SURFACE_FINISH_ENGINE.database.nNumberToRa[nNumber];\n      return spec ? { ra_um: spec.ra_um, ra_uin: spec.ra_uin } : null;\n    }\n  }\n}",
      "methods": [],
      "lines": 291
    },
    {
      "name": "PRISM_ADVANCED_KINEMATICS_ENGINE",
      "category": "engines",
      "refs": 313,
      "status": "FOUND",
      "code": "const PRISM_ADVANCED_KINEMATICS_ENGINE = {\n    name: 'PRISM_ADVANCED_KINEMATICS_ENGINE',\n    version: '1.0.0',\n    source: 'MIT 16.07, Stanford CS 223A',\n    \n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // HOMOGENEOUS TRANSFORMATION MATRICES\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    \n    /**\n     * Create rotation matrix about X axis\n     * @param {number} theta - Angle in radians\n     * @returns {Array} 4x4 homogeneous transformation matrix\n     */\n    rotX: function(theta) {\n        const c = Math.cos(theta);\n        const s = Math.sin(theta);\n        return [\n            [1, 0,  0, 0],\n            [0, c, -s, 0],\n            [0, s,  c, 0],\n            [0, 0,  0, 1]\n        ];\n    },\n    \n    /**\n     * Create rotation matrix about Y axis\n     */\n    rotY: function(theta) {\n        const c = Math.cos(theta);\n        const s = Math.sin(theta);\n        return [\n            [ c, 0, s, 0],\n            [ 0, 1, 0, 0],\n            [-s, 0, c, 0],\n            [ 0, 0, 0, 1]\n        ];\n    },\n    \n    /**\n     * Create rotation matrix about Z axis\n     */\n    rotZ: function(theta) {\n        const c = Math.cos(theta);\n        const s = Math.sin(theta);\n        return [\n            [c, -s, 0, 0],\n            [s,  c, 0, 0],\n            [0,  0, 1, 0],\n            [0,  0, 0, 1]\n        ];\n    },\n    \n    /**\n     * Create translation matrix\n     */\n    translate: function(dx, dy, dz) {\n        return [\n            [1, 0, 0, dx],\n            [0, 1, 0, dy],\n            [0, 0, 1, dz],\n            [0, 0, 0, 1]\n        ];\n    },\n    \n    /**\n     * Multiply two 4x4 matrices\n     */\n    matMul4x4: function(A, B) {\n        const result = [[0,0,0,0], [0,0,0,0], [0,0,0,0], [0,0,0,0]];\n        for (let i = 0; i < 4; i++) {\n            for (let j = 0; j < 4; j++) {\n                for (let k = 0; k < 4; k++) {\n                    result[i][j] += A[i][k] * B[k][j];\n                }\n            }\n        }\n        return result;\n    },\n    \n    /**\n     * Chain multiple transformations\n     */\n    chainTransforms: function(...transforms) {\n        return transforms.reduce((acc, T) => this.matMul4x4(acc, T));\n    },\n    \n    /**\n     * Transform a point using 4x4 matrix\n     */\n    transformPoint: function(T, point) {\n        const p = [point.x || point[0], point.y || point[1], point.z || point[2], 1];\n        const result = [0, 0, 0, 0];\n        for (let i = 0; i < 4; i++) {\n            for (let j = 0; j < 4; j++) {\n                result[i] += T[i][j] * p[j];\n            }\n        }\n        return { x: result[0], y: result[1], z: result[2] };\n    },\n    \n    /**\n     * Invert a homogeneous transformation matrix\n     * For pure rotation + translation: inv(T) = [R^T, -R^T * t; 0, 1]\n     */\n    invertTransform: function(T) {\n        // Extract rotation (3x3) and translation\n        const R = [\n            [T[0][0], T[0][1], T[0][2]],\n            [T[1][0], T[1][1], T[1][2]],\n            [T[2][0], T[2][1], T[2][2]]\n        ];\n        const t = [T[0][3], T[1][3], T[2][3]];\n        \n        // R^T (rotation part is orthogonal)\n        const RT = [\n            [R[0][0], R[1][0], R[2][0]],\n            [R[0][1], R[1][1], R[2][1]],\n            [R[0][2], R[1][2], R[2][2]]\n        ];\n        \n        // -R^T * t\n        const tNew = [\n            -(RT[0][0]*t[0] + RT[0][1]*t[1] + RT[0][2]*t[2]),\n            -(RT[1][0]*t[0] + RT[1][1]*t[1] + RT[1][2]*t[2]),\n            -(RT[2][0]*t[0] + RT[2][1]*t[1] + RT[2][2]*t[2])\n        ];\n        \n        return [\n            [RT[0][0], RT[0][1], RT[0][2], tNew[0]],\n            [RT[1][0], RT[1][1], RT[1][2], tNew[1]],\n            [RT[2][0], RT[2][1], RT[2][2], tNew[2]],\n            [0, 0, 0, 1]\n        ];\n    },\n    \n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // DENAVIT-HARTENBERG PARAMETERS\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    \n    /**\n     * Create DH transformation matrix\n     * @param {Object} params - {theta, d, a, alpha} DH parameters\n     * @returns {Array} 4x4 transformation matrix\n     */\n    dhTransform: function(params) {\n        const { theta, d, a, alpha } = params;\n        const ct = Math.cos(theta);\n        const st = Math.sin(theta);\n        const ca = Math.cos(alpha);\n        const sa = Math.sin(alpha);\n        \n        return [\n            [ct, -st*ca,  st*sa, a*ct],\n            [st,  ct*ca, -ct*sa, a*st],\n            [0,   sa,     ca,    d   ],\n            [0,   0,      0,     1   ]\n        ];\n    },\n    \n    /**\n     * Forward kinematics using DH parameters\n     * @param {Array} dhTable - Array of {theta, d, a, alpha, type}\n     * @param {Array} jointValues - Joint positions (radians for revolute, mm for prismatic)\n     * @returns {Object} End effector pose\n     */\n    forwardKinematicsDH: function(dhTable, jointValues) {\n        let T = [[1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1]]; // Identity\n        const transforms = [];\n        \n        for (let i = 0; i < dhTable.length; i++) {\n            const dh = { ...dhTable[i] };\n            \n            // Apply joint value based on joint type\n            if (dhTable[i].type === 'revolute') {\n                dh.theta = (dh.theta || 0) + jointValues[i];\n            } else if (dhTable[i].type === 'prismatic') {\n                dh.d = (dh.d || 0) + jointValues[i];\n            }\n            \n            const Ti = this.dhTransform(dh);\n            T = this.matMul4x4(T, Ti);\n            transforms.push({ joint: i, T: JSON.parse(JSON.stringify(T)) });\n        }\n        \n        // Extract position and orientation\n        const position = { x: T[0][3], y: T[1][3], z: T[2][3] };\n        const rotation = [\n            [T[0][0], T[0][1], T[0][2]],\n            [T[1][0], T[1][1], T[1][2]],\n            [T[2][0], T[2][1], T[2][2]]\n        ];\n        \n        // Extract Euler angles (ZYX convention)\n        const euler = this.rotationToEuler(rotation);\n        \n        return {\n            position,\n            rotation,\n            euler,\n            transform: T,\n            intermediateTransforms: transforms\n        };\n    },\n    \n    /**\n     * Extract Euler angles from rotation matrix (ZYX convention)\n     */\n    rotationToEuler: function(R) {\n        let roll, pitch, yaw;\n        \n        // Check for gimbal lock\n        if (Math.abs(R[2][0]) >= 1 - 1e-10) {\n            yaw = 0;\n            if (R[2][0] < 0) {\n                pitch = Math.PI / 2;\n                roll = Math.atan2(R[0][1], R[0][2]);\n            } else {\n                pitch = -Math.PI / 2;\n                roll = Math.atan2(-R[0][1], -R[0][2]);\n            }\n        } else {\n            pitch = Math.asin(-R[2][0]);\n            roll = Math.atan2(R[2][1] / Math.cos(pitch), R[2][2] / Math.cos(pitch));\n            yaw = Math.atan2(R[1][0] / Math.cos(pitch), R[0][0] / Math.cos(pitch));\n        }\n        \n        return {\n            roll: roll * 180 / Math.PI,\n            pitch: pitch * 180 / Math.PI,\n            yaw: yaw * 180 / Math.PI\n        };\n    },\n    \n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // JACOBIAN COMPUTATION\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    \n    /**\n     * Compute geometric Jacobian matrix\n     * @param {Array} dhTable - DH parameters\n     * @param {Array} jointValues - Current joint positions\n     * @returns {Object} Jacobian matrix and related info\n     */\n    computeJacobian: function(dhTable, jointValues) {\n        const n = dhTable.length;\n        const J = [];\n        \n        // Compute all intermediate transforms\n        const fk = this.forwardKinematicsDH(dhTable, jointValues);\n        const transforms = fk.intermediateTransforms;\n        const pn = [fk.position.x, fk.position.y, fk.position.z]; // End effector position\n        \n        // Build Jacobian column by column\n        for (let i = 0; i < n; i++) {\n            // Get z-axis of frame i-1 (before joint i)\n            let zi, oi;\n            if (i === 0) {\n                zi = [0, 0, 1]; // Base frame z-axis\n                oi = [0, 0, 0]; // Base frame origin\n            } else {\n                const Ti = transforms[i - 1].T;\n                zi = [Ti[0][2], Ti[1][2], Ti[2][2]];\n                oi = [Ti[0][3], Ti[1][3], Ti[2][3]];\n            }\n            \n            if (dhTable[i].type === 'revolute') {\n                // For revolute: Jv = z \u00d7 (p - o), Jw = z\n                const pMinusO = [pn[0] - oi[0], pn[1] - oi[1], pn[2] - oi[2]];\n                const Jv = this.cross3(zi, pMinusO);\n                J.push([Jv[0], Jv[1], Jv[2], zi[0], zi[1], zi[2]]);\n            } else {\n                // For prismatic: Jv = z, Jw = 0\n                J.push([zi[0], zi[1], zi[2], 0, 0, 0]);\n            }\n        }\n        \n        // Transpose to get 6\u00d7n matrix\n        const Jt = this.transpose(J);\n        \n        // Compute condition number for singularity detection\n        const conditionNumber = this.estimateConditionNumber(Jt);\n        \n        return {\n            jacobian: Jt,\n            linearPart: Jt.slice(0, 3),\n            angularPart: Jt.slice(3, 6),\n            conditionNumber,\n            nearSingularity: conditionNumber > 100\n        };\n    },\n    \n    /**\n     * Cross product of two 3D vectors\n     */\n    cross3: function(a, b) {\n        return [\n            a[1]*b[2] - a[2]*b[1],\n            a[2]*b[0] - a[0]*b[2],\n            a[0]*b[1] - a[1]*b[0]\n        ];\n    },\n    \n    /**\n     * Transpose matrix\n     */\n    transpose: function(A) {\n        if (!A || !A.length) return [];\n        return A[0].map((_, j) => A.map(row => row[j]));\n    },\n    \n    /**\n     * Estimate condition number (ratio of max to min singular value approximation)\n     */\n    estimateConditionNumber: function(J) {\n        // Compute J * J^T\n        const JJt = this.matMul(J, this.transpose(J));\n        \n        // Power iteration for max eigenvalue\n        let v = Array(JJt.length).fill(1);\n        for (let iter = 0; iter < 20; iter++) {\n            const Av = JJt.map(row => row.reduce((s, a, j) => s + a * v[j], 0));\n            const norm = Math.sqrt(Av.reduce((s, x) => s + x * x, 0));\n            v = Av.map(x => x / norm);\n        }\n        const maxEig = v.reduce((s, vi, i) => \n            s + vi * JJt[i].reduce((ss, a, j) => ss + a * v[j], 0), 0);\n        \n        // Inverse power iteration for min eigenvalue\n        const JJtInv = this.pseudoInverse(JJt);\n        if (!JJtInv) return Infinity;\n        \n        let w = Array(JJtInv.length).fill(1);\n        for (let iter = 0; iter < 20; iter++) {\n            const Aw = JJtInv.map(row => row.reduce((s, a, j) => s + a * w[j], 0));\n            const norm = Math.sqrt(Aw.reduce((s, x) => s + x * x, 0));\n            if (norm < 1e-10) return Infinity;\n            w = Aw.map(x => x / norm);\n        }\n        const minEigInv = w.reduce((s, wi, i) => \n            s + wi * JJtInv[i].reduce((ss, a, j) => ss + a * w[j], 0), 0);\n        const minEig = 1 / minEigInv;\n        \n        return Math.sqrt(maxEig / Math.max(minEig, 1e-10));\n    },\n    \n    /**\n     * Matrix multiplication\n     */\n    matMul: function(A, B) {\n        const m = A.length, n = B[0].length, p = B.length;\n        const C = Array(m).fill(null).map(() => Array(n).fill(0));\n        for (let i = 0; i < m; i++) {\n            for (let j = 0; j < n; j++) {\n                for (let k = 0; k < p; k++) {\n                    C[i][j] += A[i][k] * B[k][j];\n                }\n            }\n        }\n        return C;\n    },\n    \n    /**\n     * Pseudo-inverse using SVD approximation (simplified)\n     */\n    pseudoInverse: function(A) {\n        const n = A.length;\n        const At = this.transpose(A);\n        const AtA = this.matMul(At, A);\n        \n        // Add regularization for numerical stability\n        for (let i = 0; i < n; i++) {\n            AtA[i][i] += 1e-10;\n        }\n        \n        // Gauss-Jordan elimination\n        const aug = AtA.map((row, i) => [...row, ...At[i]]);\n        \n        for (let i = 0; i < n; i++) {\n            // Find pivot\n            let maxRow = i;\n            for (let k = i + 1; k < n; k++) {\n                if (Math.abs(aug[k][i]) > Math.abs(aug[maxRow][i])) maxRow = k;\n            }\n            [aug[i], aug[maxRow]] = [aug[maxRow], aug[i]];\n            \n            if (Math.abs(aug[i][i]) < 1e-12) return null;\n            \n            const pivot = aug[i][i];\n            for (let j = 0; j < 2 * n; j++) aug[i][j] /= pivot;\n            \n            for (let k = 0; k < n; k++) {\n                if (k !== i) {\n                    const factor = aug[k][i];\n                    for (let j = 0; j < 2 * n; j++) {\n                        aug[k][j] -= factor * aug[i][j];\n                    }\n                }\n            }\n        }\n        \n        return aug.map(row => row.slice(n));\n    },\n    \n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // 5-AXIS CNC SPECIFIC KINEMATICS\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    \n    /**\n     * 5-Axis inverse kinematics with multiple solutions\n     * @param {Object} toolPose - {position: {x,y,z}, axis: {i,j,k}}\n     * @param {Object} config - Machine configuration\n     * @returns {Array} Array of possible solutions\n     */\n    fiveAxisIK: function(toolPose, config = {}) {\n        const { position, axis } = toolPose;\n        const machineType = config.type || 'table-table'; // table-table, head-head, mixed\n        \n        // Normalize tool axis\n        const len = Math.sqrt(axis.i**2 + axis.j**2 + axis.k**2);\n        const n = { i: axis.i/len, j: axis.j/len, k: axis.k/len };\n        \n        const solutions = [];\n        \n        if (machineType === 'table-table') {\n            // A-C table configuration (most common)\n            // A rotates about X, C rotates about Z\n            \n            // Solution 1: Primary\n            let A = Math.acos(-n.k) * 180 / Math.PI;\n            let C = Math.atan2(n.j, n.i) * 180 / Math.PI;\n            \n            // Handle singularity at A = 0\n            if (Math.abs(A) < 0.01) {\n                C = config.previousC || 0;\n            }\n            \n            solutions.push(this._computeXYZ(position, A, C, config, 1));\n            \n            // Solution 2: Alternative (A negative, C + 180)\n            if (A > 0.01 && A < 179.99) {\n                const A2 = -A;\n                const C2 = C + 180;\n                solutions.push(this._computeXYZ(position, A2, C2, config, 2));\n            }\n        } else if (machineType === 'head-head') {\n            // A-C head configuration\n            // Both rotary axes in spindle head\n            \n            let A = Math.acos(-n.k) * 180 / Math.PI;\n            let C = Math.atan2(n.j, n.i) * 180 / Math.PI;\n            \n            solutions.push({\n                X: position.x, Y: position.y, Z: position.z,\n                A, C, valid: true, solution: 1\n            });\n        } else {\n            // Mixed configuration (Table A, Head C or similar)\n            let A = Math.acos(-n.k) * 180 / Math.PI;\n            let C = Math.atan2(n.j, n.i) * 180 / Math.PI;\n            \n            solutions.push(this._computeXYZ(position, A, C, config, 1));\n        }\n        \n        // Validate against limits\n        return solutions.map(sol => ({\n            ...sol,\n            valid: this._checkLimits(sol, config.limits)\n        }));\n    },\n    \n    _computeXYZ: function(position, A, C, config, solutionNum) {\n        const Arad = A * Math.PI / 180;\n        const Crad = C * Math.PI / 180;\n        \n        // Pivot point compensation\n        const pivot = config.pivotOffset || { x: 0, y: 0, z: 0 };\n        \n        // For table-table: compensate for table rotation\n        const dx = pivot.x * (1 - Math.cos(Arad) * Math.cos(Crad));\n        const dy = pivot.y * (1 - Math.cos(Arad) * Math.sin(Crad));\n        const dz = pivot.z * (1 - Math.cos(Arad));\n        \n        return {\n            X: position.x - dx,\n            Y: position.y - dy,\n            Z: position.z - dz,\n            A, C,\n            valid: true,\n            solution: solutionNum\n        };\n    },\n    \n    _checkLimits: function(joints, limits) {\n        if (!limits) return true;\n        const axes = ['X', 'Y', 'Z', 'A', 'C'];\n        for (const axis of axes) {\n            if (limits[axis] && joints[axis] !== undefined) {\n                const [min, max] = limits[axis];\n                if (joints[axis] < min || joints[axis] > max) return false;\n            }\n        }\n        return true;\n    },\n    \n    /**\n     * Singularity detection for 5-axis machines\n     */\n    detectSingularity: function(joints, config = {}) {\n        const threshold = config.singularityThreshold || 1.0; // degrees\n        const A = Math.abs(joints.A);\n        \n        const isSingular = A < threshold || Math.abs(A - 180) < threshold;\n        \n        return {\n            isSingular,\n            type: isSingular ? 'gimbal_lock' : 'none',\n            aAngle: joints.A,\n            recommendation: isSingular ? \n                'Modify toolpath to avoid vertical tool orientation' : \n                'No singularity issues'\n        };\n    },\n    \n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // VELOCITY KINEMATICS\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    \n    /**\n     * Compute TCP velocity from joint velocities\n     * @param {Array} jacobian - 6\u00d7n Jacobian matrix\n     * @param {Array} jointVelocities - n\u00d71 joint velocity vector\n     * @returns {Object} TCP linear and angular velocities\n     */\n    tcpVelocity: function(jacobian, jointVelocities) {\n        const v = jacobian.map(row => \n            row.reduce((sum, j, i) => sum + j * jointVelocities[i], 0)\n        );\n        \n        return {\n            linear: { vx: v[0], vy: v[1], vz: v[2] },\n            angular: { wx: v[3], wy: v[4], wz: v[5] },\n            magnitude: {\n                linear: Math.sqrt(v[0]**2 + v[1]**2 + v[2]**2),\n                angular: Math.sqrt(v[3]**2 + v[4]**2 + v[5]**2)\n            }\n        };\n    },\n    \n    /**\n     * Compute required joint velocities for desired TCP velocity\n     * @param {Array} jacobian - Jacobian matrix\n     * @param {Object} tcpVel - Desired TCP velocity\n     * @returns {Array} Joint velocities\n     */\n    inverseVelocity: function(jacobian, tcpVel) {\n        const v = [\n            tcpVel.linear?.vx || 0, tcpVel.linear?.vy || 0, tcpVel.linear?.vz || 0,\n            tcpVel.angular?.wx || 0, tcpVel.angular?.wy || 0, tcpVel.angular?.wz || 0\n        ];\n        \n        // Damped least squares (DLS) for numerical stability\n        const lambda = 0.01; // Damping factor\n        const Jt = this.transpose(jacobian);\n        const JJt = this.matMul(jacobian, Jt);\n        \n        // Add damping: (J*J^T + \u03bb\u00b2I)\n        for (let i = 0; i < JJt.length; i++) {\n            JJt[i][i] += lambda * lambda;\n        }\n        \n        // Solve: q_dot = J^T * (J*J^T + \u03bb\u00b2I)^-1 * v\n        const JJtInv = this.pseudoInverse(JJt);\n        if (!JJtInv) return null;\n        \n        const temp = this.matMul(JJtInv, v.map(x => [x])).map(r => r[0]);\n        const qDot = this.matMul(Jt, temp.map(x => [x])).map(r => r[0]);\n        \n        return qDot;\n    },\n    \n    // Gateway registration\n    register: function() {\n        if (typeof PRISM_GATEWAY !== 'undefined') {\n            PRISM_GATEWAY.register('kinematics.transform.rotX', 'PRISM_ADVANCED_KINEMATICS_ENGINE.rotX');\n            PRISM_GATEWAY.register('kinematics.transform.rotY', 'PRISM_ADVANCED_KINEMATICS_ENGINE.rotY');\n            PRISM_GATEWAY.register('kinematics.transform.rotZ', 'PRISM_ADVANCED_KINEMATICS_ENGINE.rotZ');\n            PRISM_GATEWAY.register('kinematics.transform.translate', 'PRISM_ADVANCED_KINEMATICS_ENGINE.translate');\n            PRISM_GATEWAY.register('kinematics.transform.chain', 'PRISM_ADVANCED_KINEMATICS_ENGINE.chainTransforms');\n            PRISM_GATEWAY.register('kinematics.transform.invert', 'PRISM_ADVANCED_KINEMATICS_ENGINE.invertTransform');\n            PRISM_GATEWAY.register('kinematics.dh.transform', 'PRISM_ADVANCED_KINEMATICS_ENGINE.dhTransform');\n            PRISM_GATEWAY.register('kinematics.fk.dh', 'PRISM_ADVANCED_KINEMATICS_ENGINE.forwardKinematicsDH');\n            PRISM_GATEWAY.register('kinematics.jacobian.compute', 'PRISM_ADVANCED_KINEMATICS_ENGINE.computeJacobian');\n            PRISM_GATEWAY.register('kinematics.5axis.ik', 'PRISM_ADVANCED_KINEMATICS_ENGINE.fiveAxisIK');\n            PRISM_GATEWAY.register('kinematics.5axis.singularity', 'PRISM_ADVANCED_KINEMATICS_ENGINE.detectSingularity');\n            PRISM_GATEWAY.register('kinematics.velocity.tcp', 'PRISM_ADVANCED_KINEMATICS_ENGINE.tcpVelocity');\n            PRISM_GATEWAY.register('kinematics.velocity.inverse', 'PRISM_ADVANCED_KINEMATICS_ENGINE.inverseVelocity');\n            console.log('[PRISM] PRISM_ADVANCED_KINEMATICS_ENGINE registered: 13 routes');\n        }\n    }\n}",
      "methods": [],
      "lines": 601
    },
    {
      "name": "PRISM_RIGID_BODY_DYNAMICS_ENGINE",
      "category": "engines",
      "refs": 311,
      "status": "NOT_FOUND",
      "code": "",
      "methods": [],
      "lines": 0
    },
    {
      "name": "PRISM_VIBRATION_ANALYSIS_ENGINE",
      "category": "engines",
      "refs": 306,
      "status": "FOUND",
      "code": "const PRISM_VIBRATION_ANALYSIS_ENGINE = {\n    name: 'PRISM_VIBRATION_ANALYSIS_ENGINE',\n    version: '1.0.0',\n    source: 'MIT 16.07, Altintas Manufacturing Automation',\n    \n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // SINGLE DOF VIBRATION\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    \n    /**\n     * Calculate natural frequency and related parameters for SDOF system\n     * @param {Object} params - {mass, stiffness, damping}\n     * @returns {Object} System characteristics\n     */\n    sdofNaturalFrequency: function(params) {\n        const { mass: m, stiffness: k, damping: c = 0 } = params;\n        \n        // Undamped natural frequency\n        const omega_n = Math.sqrt(k / m);\n        const f_n = omega_n / (2 * Math.PI);\n        \n        // Damping ratio\n        const c_critical = 2 * Math.sqrt(k * m);\n        const zeta = c / c_critical;\n        \n        // Damped natural frequency\n        const omega_d = omega_n * Math.sqrt(Math.max(0, 1 - zeta * zeta));\n        const f_d = omega_d / (2 * Math.PI);\n        \n        // Logarithmic decrement\n        const delta = zeta < 1 ? 2 * Math.PI * zeta / Math.sqrt(1 - zeta * zeta) : null;\n        \n        // Quality factor\n        const Q = zeta > 0 ? 1 / (2 * zeta) : Infinity;\n        \n        // Period\n        const T_n = 1 / f_n;\n        const T_d = zeta < 1 ? 1 / f_d : null;\n        \n        return {\n            undampedNaturalFreq_rad: omega_n,\n            undampedNaturalFreq_Hz: f_n,\n            dampedNaturalFreq_rad: omega_d,\n            dampedNaturalFreq_Hz: f_d,\n            dampingRatio: zeta,\n            criticalDamping: c_critical,\n            logarithmicDecrement: delta,\n            qualityFactor: Q,\n            period_undamped: T_n,\n            period_damped: T_d,\n            systemType: zeta < 1 ? 'underdamped' : zeta === 1 ? 'critically_damped' : 'overdamped'\n        };\n    },\n    \n    /**\n     * Free vibration response of SDOF system\n     * @param {Object} params - System parameters\n     * @param {Object} initial - {x0, v0} initial conditions\n     * @param {number} t - Time\n     * @returns {Object} Position and velocity\n     */\n    sdofFreeResponse: function(params, initial, t) {\n        const { mass: m, stiffness: k, damping: c = 0 } = params;\n        const { x0 = 0, v0 = 0 } = initial;\n        \n        const omega_n = Math.sqrt(k / m);\n        const zeta = c / (2 * Math.sqrt(k * m));\n        \n        let x, v;\n        \n        if (zeta < 1) {\n            // Underdamped\n            const omega_d = omega_n * Math.sqrt(1 - zeta * zeta);\n            const A = x0;\n            const B = (v0 + zeta * omega_n * x0) / omega_d;\n            \n            const envelope = Math.exp(-zeta * omega_n * t);\n            x = envelope * (A * Math.cos(omega_d * t) + B * Math.sin(omega_d * t));\n            v = envelope * (\n                -zeta * omega_n * (A * Math.cos(omega_d * t) + B * Math.sin(omega_d * t)) +\n                omega_d * (-A * Math.sin(omega_d * t) + B * Math.cos(omega_d * t))\n            );\n        } else if (zeta === 1) {\n            // Critically damped\n            const A = x0;\n            const B = v0 + omega_n * x0;\n            x = (A + B * t) * Math.exp(-omega_n * t);\n            v = (B - omega_n * (A + B * t)) * Math.exp(-omega_n * t);\n        } else {\n            // Overdamped\n            const s1 = -omega_n * (zeta - Math.sqrt(zeta * zeta - 1));\n            const s2 = -omega_n * (zeta + Math.sqrt(zeta * zeta - 1));\n            const A = (v0 - s2 * x0) / (s1 - s2);\n            const B = (s1 * x0 - v0) / (s1 - s2);\n            x = A * Math.exp(s1 * t) + B * Math.exp(s2 * t);\n            v = A * s1 * Math.exp(s1 * t) + B * s2 * Math.exp(s2 * t);\n        }\n        \n        return { position: x, velocity: v };\n    },\n    \n    /**\n     * Forced vibration response (harmonic excitation)\n     * @param {Object} system - {mass, stiffness, damping}\n     * @param {Object} excitation - {amplitude, frequency}\n     * @returns {Object} Steady-state response\n     */\n    sdofForcedResponse: function(system, excitation) {\n        const { mass: m, stiffness: k, damping: c = 0 } = system;\n        const { amplitude: F0, frequency: omega } = excitation;\n        \n        const omega_n = Math.sqrt(k / m);\n        const zeta = c / (2 * Math.sqrt(k * m));\n        const r = omega / omega_n; // Frequency ratio\n        \n        // Steady-state amplitude\n        const X = (F0 / k) / Math.sqrt(Math.pow(1 - r * r, 2) + Math.pow(2 * zeta * r, 2));\n        \n        // Phase angle\n        const phi = Math.atan2(2 * zeta * r, 1 - r * r);\n        \n        // Magnification factor\n        const MF = X / (F0 / k);\n        \n        // Transmissibility (force transmitted to base)\n        const TR = Math.sqrt(1 + Math.pow(2 * zeta * r, 2)) / \n                   Math.sqrt(Math.pow(1 - r * r, 2) + Math.pow(2 * zeta * r, 2));\n        \n        // Power dissipated\n        const P_dissipated = 0.5 * c * X * X * omega * omega;\n        \n        return {\n            amplitude: X,\n            phase_rad: phi,\n            phase_deg: phi * 180 / Math.PI,\n            magnificationFactor: MF,\n            transmissibility: TR,\n            frequencyRatio: r,\n            dampingRatio: zeta,\n            isResonant: Math.abs(r - 1) < 0.1,\n            peakResponseFreq: omega_n * Math.sqrt(1 - 2 * zeta * zeta),\n            powerDissipated: P_dissipated,\n            response: (t) => X * Math.cos(omega * t - phi)\n        };\n    },\n    \n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // FREQUENCY RESPONSE FUNCTION (FRF)\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    \n    /**\n     * Compute FRF (compliance) for SDOF system\n     * G(j\u03c9) = 1 / (k - m\u03c9\u00b2 + jc\u03c9)\n     */\n    computeFRF: function(system, omega) {\n        const { mass: m, stiffness: k, damping: c = 0 } = system;\n        \n        const real = k - m * omega * omega;\n        const imag = c * omega;\n        const denominator = real * real + imag * imag;\n        \n        const G_real = real / denominator;\n        const G_imag = -imag / denominator;\n        const magnitude = 1 / Math.sqrt(denominator);\n        const phase = -Math.atan2(imag, real);\n        \n        return {\n            real: G_real,\n            imaginary: G_imag,\n            magnitude,\n            phase_rad: phase,\n            phase_deg: phase * 180 / Math.PI,\n            frequency_rad: omega,\n            frequency_Hz: omega / (2 * Math.PI)\n        };\n    },\n    \n    /**\n     * Generate FRF data over frequency range\n     */\n    generateFRFData: function(system, freqRange) {\n        const { start, end, points } = freqRange;\n        const data = [];\n        \n        for (let i = 0; i < points; i++) {\n            const freq = start + (end - start) * i / (points - 1);\n            const omega = 2 * Math.PI * freq;\n            const frf = this.computeFRF(system, omega);\n            data.push({\n                frequency_Hz: freq,\n                ...frf\n            });\n        }\n        \n        // Find resonance peak\n        const peak = data.reduce((max, d) => d.magnitude > max.magnitude ? d : max);\n        \n        return {\n            data,\n            resonanceFreq: peak.frequency_Hz,\n            peakMagnitude: peak.magnitude,\n            halfPowerBandwidth: this._calculateHalfPowerBandwidth(data, peak)\n        };\n    },\n    \n    _calculateHalfPowerBandwidth: function(data, peak) {\n        const halfPower = peak.magnitude / Math.sqrt(2);\n        let f1 = null, f2 = null;\n        \n        for (let i = 1; i < data.length; i++) {\n            if (!f1 && data[i].magnitude >= halfPower && data[i-1].magnitude < halfPower) {\n                f1 = data[i].frequency_Hz;\n            }\n            if (f1 && data[i].magnitude < halfPower && data[i-1].magnitude >= halfPower) {\n                f2 = data[i].frequency_Hz;\n                break;\n            }\n        }\n        \n        return f1 && f2 ? f2 - f1 : null;\n    },\n    \n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    // MULTI-DOF MODAL ANALYSIS\n    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    \n    /**\n     * Modal analysis for multi-DOF system\n     * Solve eigenvalue problem: [K - \u03c9\u00b2M]\u03c6 = 0\n     * @param {Array} M - Mass matrix (n\u00d7n)\n     * @param {Array} K - Stiffness matrix (n\u00d7n)\n     * @returns {Object} Natural frequencies and mode shapes\n     */\n    modalAnalysis: function(M, K) {\n        const n = M.length;\n        \n        // Use inverse power iteration with shifting for multiple modes\n        const modes = [];\n        const frequencies = [];\n        \n        // Find all eigenvalues using QR iteration (simplified)\n        const eigenData = this._qrEigenvalues(M, K);\n        \n        // Sort by frequency\n        eigenData.sort((a, b) => a.frequency - b.frequency);\n        \n        // Extract modal mass and stiffness\n        for (let i = 0; i < eigenData.length; i++) {\n            const phi = eigenData[i].modeShape;\n            \n            // Modal mass: m_i = \u03c6_i^T * M * \u03c6_i\n            const modalMass = this._quadraticForm(phi, M, phi);\n            \n            // Modal stiffness: k_i = \u03c6_i^T * K * \u03c6_i\n            const modalStiffness = this._quadraticForm(phi, K, phi);\n            \n            // Normalize mode shape\n            const norm = Math.sqrt(phi.reduce((s, p) => s + p * p, 0));\n            const normalizedPhi = phi.map(p => p / norm);\n            \n            // Mass-normalize: \u03c6 such that \u03c6^T * M * \u03c6 = 1\n            const massNormalizedPhi = phi.map(p => p / Math.sqrt(modalMass));\n            \n            modes.push({\n                modeNumber: i + 1,\n                frequency_rad: eigenData[i].omega,\n                frequency_Hz: eigenData[i].frequency,\n                modeShape: normalizedPhi,\n                massNormalizedModeShape: massNormalizedPhi,\n                modalMass,\n                modalStiffness,\n                participationFactor: this._participationFactor(normalizedPhi, M)\n            });\n        }\n        \n        return {\n            numberOfModes: modes.length,\n            modes,\n            massMatrix: M,\n            stiffnessMatrix: K\n        };\n    },\n    \n    _qrEigenvalues: function(M, K) {\n        const n = M.length;\n        const results = [];\n        \n        // Power iteration for each eigenvalue (simplified)\n        for (let mode = 0; mode < n; mode++) {\n            // Initial guess\n            let v = Array(n).fill(0);\n            v[mode] = 1;\n            \n            // Add some randomness to break symmetry\n            v = v.map(x => x + 0.01 * (Math.random() - 0.5));\n            \n            // Solve K*x = \u03bb*M*x iteratively\n            for (let iter = 0; iter < 50; iter++) {\n                // y = K^-1 * M * v (inverse iteration)\n                const Mv = this._matVecMul(M, v);\n                const y = this._solveSystem(K, Mv);\n                \n                // Rayleigh quotient\n                const vMv = this._dotProduct(v, Mv);\n                const vKv = this._dotProduct(v, this._matVecMul(K, v));\n                const lambda = vKv / vMv;\n                \n                // Normalize\n                const norm = Math.sqrt(y.reduce((s, yi) => s + yi * yi, 0));\n                v = y.map(yi => yi / norm);\n            }\n            \n            // Final eigenvalue\n            const Mv = this._matVecMul(M, v);\n            const Kv = this._matVecMul(K, v);\n            const lambda = this._dotProduct(v, Kv) / this._dotProduct(v, Mv);\n            const omega = Math.sqrt(Math.abs(lambda));\n            \n            results.push({\n                omega,\n                frequency: omega / (2 * Math.PI),\n                modeShape: v\n            });\n        }\n        \n        return results;\n    },\n    \n    _matVecMul: function(A, v) {\n        return A.map(row => row.reduce((sum, a, j) => sum + a * v[j], 0));\n    },\n    \n    _dotProduct: function(a, b) {\n        return a.reduce((sum, ai, i) => sum + ai * b[i], 0);\n    },\n    \n    _quadraticForm: function(v, M, w) {\n        const Mw = this._matVecMul(M, w);\n        return this._dotProduct(v, Mw);\n    },\n    \n    _solveSystem: function(A, b) {\n        const n = b.length;\n        const aug = A.map((row, i) => [...row, b[i]]);\n        \n        for (let i = 0; i < n; i++) {\n            let maxRow = i;\n            for (let k = i + 1; k < n; k++) {\n                if (Math.abs(aug[k][i]) > Math.abs(aug[maxRow][i])) maxRow = k;\n            }\n            [aug[i], aug[maxRow]] = [aug[maxRow], aug[i]];\n            \n            if (Math.abs(aug[i][i]) < 1e-12) aug[i][i] = 1e-12;\n            \n            for (let k = i + 1; k < n; k++) {\n                const factor = aug[k][i] / aug[i][i];\n                for (let j = i; j <= n; j++) aug[k][j] -= factor * aug[i][j];\n            }\n        }\n        \n        const x = Array(n).fill(0);\n        for (let i = n - 1; i >= 0; i--) {\n            x[i] = aug[i][n];\n            for (let j = i + 1; j < n; j++) x[i] -= aug[i][j] * x[j];\n            x[i] /= aug[i][i];\n        }\n        \n        return x;\n    },\n    \n    _participationFactor: function(phi, M) {\n        // Participation factor for seismic/base excitation\n        const ones = Array(phi.length).fill(1);\n        const numerator = this._dotProduct(phi, this._matVecMul(M, ones));\n        const denominator = this._dotProduct(phi, this._matVecMul(M, phi));\n        return numerator / denominator;\n    },\n    \n    // Gateway registration\n    register: function() {\n        if (typeof PRISM_GATEWAY !== 'undefined') {\n            PRISM_GATEWAY.register('vibration.sdof.natural', 'PRISM_VIBRATION_ANALYSIS_ENGINE.sdofNaturalFrequency');\n            PRISM_GATEWAY.register('vibration.sdof.freeResponse', 'PRISM_VIBRATION_ANALYSIS_ENGINE.sdofFreeResponse');\n            PRISM_GATEWAY.register('vibration.sdof.forcedResponse', 'PRISM_VIBRATION_ANALYSIS_ENGINE.sdofForcedResponse');\n            PRISM_GATEWAY.register('vibration.frf.compute', 'PRISM_VIBRATION_ANALYSIS_ENGINE.computeFRF');\n            PRISM_GATEWAY.register('vibration.frf.generate', 'PRISM_VIBRATION_ANALYSIS_ENGINE.generateFRFData');\n            PRISM_GATEWAY.register('vibration.modal.analysis', 'PRISM_VIBRATION_ANALYSIS_ENGINE.modalAnalysis');\n            console.log('[PRISM] PRISM_VIBRATION_ANALYSIS_ENGINE registered: 6 routes');\n        }\n    }\n}",
      "methods": [],
      "lines": 391
    },
    {
      "name": "PRISM_MASTER",
      "category": "core",
      "refs": 366,
      "status": "NOT_FOUND",
      "code": "",
      "methods": [],
      "lines": 0
    },
    {
      "name": "PRISM_MASTER_DB",
      "category": "core",
      "refs": 258,
      "status": "FOUND",
      "code": "const PRISM_MASTER_DB = {\n  version: '8.0.0',\n  buildDate: new Date().toISOString(),\n\n  // Accurate counts after full consolidation\n  stats: {\n    machines: 279,\n    materials: 355,\n    tools: 87561,\n    camStrategies: 517,\n    postProcessors: 247,\n    totalDatabases: 230\n  },\n  // Unified access methods\n  machines: {\n    getAll: () => UNIFIED_MACHINES?.getAll() || [],\n    search: (q) => UNIFIED_MACHINES?.search(q) || [],\n    getByCategory: (c) => UNIFIED_MACHINES?.getByCategory(c) || [],\n    getByBrand: (b) => UNIFIED_MACHINES?.getByBrand(b) || [],\n    getCount: () => UNIFIED_MACHINES?.getCount() || 279\n  },\n  materials: {\n    getAll: () => UNIFIED_MATERIALS?.getAll() || [],\n    search: (q) => UNIFIED_MATERIALS?.search(q) || [],\n    getByCategory: (c) => UNIFIED_MATERIALS?.getByCategory(c) || [],\n    getSpeedsFeedsFor: (m) => UNIFIED_MATERIALS?.getSpeedsFeedsFor(m) || null,\n    getCount: () => UNIFIED_MATERIALS?.getCount() || 355\n  },\n  tools: {\n    search: (c) => PRISM_TOOLS?.search(c) || [],\n    generate: (t, s, o) => PRISM_TOOLS?.generate(t, s, o) || null,\n    getTemplates: () => PRISM_TOOLS?.getTemplates() || [],\n    recommendForFeature: (f, m, d) => PRISM_TOOLS?.recommendForFeature(f, m, d) || [],\n    getTapDrill: (t, ty) => PRISM_TOOLS?.getTapDrill(t, ty) || null,\n    getCount: () => 87561\n  },\n  cam: {\n    getBestStrategy: (f, m, c) => UNIFIED_CAM?.getBestStrategy(f, m, c) || 'adaptive',\n    getStrategyDetails: (s) => UNIFIED_CAM?.getStrategyDetails(s) || null,\n    getSoftwareStrengths: (s) => UNIFIED_CAM?.getSoftwareStrengths(s) || null,\n    getStrategiesForFeature: (f) => UNIFIED_CAM?.getStrategiesForFeature(f) || [],\n    getCount: () => UNIFIED_CAM?.getStrategyCount() || 517\n  },\n  posts: {\n    getController: (n) => UNIFIED_POSTS?.getController(n) || null,\n    getGCodeHelp: (c) => UNIFIED_POSTS?.getGCodeHelp(c) || null,\n    getMCodeHelp: (c) => UNIFIED_POSTS?.getMCodeHelp(c) || null,\n    getPostForMachine: (m) => UNIFIED_POSTS?.getPostForMachine(m) || null,\n    getAllControllers: () => UNIFIED_POSTS?.getAllControllers() || []\n  },\n  // Complete workflow helper\n  getCompleteSetup(partFeatures, material, machine) {\n    const result = {\n      machine: null,\n      material: null,\n      tools: [],\n      strategies: [],\n      post: null\n    };\n    // Get machine\n    if (machine) {\n      const machines = this.machines.search(machine);\n      result.machine = machines[0] || null;\n    }\n    // Get material\n    if (material) {\n      const materials = this.materials.search(material);\n      result.material = materials[0] || null;\n      result.speedsFeedsData = this.materials.getSpeedsFeedsFor(material);\n    }\n    // Get tools and strategies for each feature\n    if (Array.isArray(partFeatures)) {\n      partFeatures.forEach(feature => {\n        const tools = this.tools.recommendForFeature(feature.type, material, feature.diameter);\n        const strategy = this.cam.getBestStrategy(feature.type, material);\n\n        result.tools.push(...tools.slice(0, 2));\n        result.strategies.push({ feature: feature.type, strategy });\n      });\n    }\n    // Get post processor\n    if (result.machine) {\n      result.post = this.posts.getPostForMachine(result.machine.model || result.machine.name);\n    }\n    return result;\n  },\n  // Health check\n  checkHealth() {\n    const systems = {\n      machines: typeof window.UNIFIED_MACHINES !== 'undefined',\n      materials: typeof window.UNIFIED_MATERIALS !== 'undefined',\n      tools: typeof window.PRISM_TOOLS !== 'undefined',\n      cam: typeof window.UNIFIED_CAM !== 'undefined',\n      posts: typeof window.UNIFIED_POSTS !== 'undefined'\n    };\n    const active = Object.values(systems).filter(Boolean).length;\n    console.log(`[PRISM_MASTER_DB] Health: ${active}/5 systems active`);\n\n    return { systems, active, total: 5 };\n  },\n  // Initialize all systems\n  init() {\n    console.log('[PRISM_MASTER_DB] Initializing unified database systems...');\n\n    // Initialize each system\n    if (typeof window.UNIFIED_MACHINES !== 'undefined') UNIFIED_MACHINES.init();\n    if (typeof window.UNIFIED_MATERIALS !== 'undefined') UNIFIED_MATERIALS.init();\n    if (typeof window.UNIFIED_CAM !== 'undefined') UNIFIED_CAM.init();\n    if (typeof window.UNIFIED_POSTS !== 'undefined') UNIFIED_POSTS.init();\n\n    // Health check\n    const health = this.checkHealth();\n\n    (typeof PRISM_CONSTANTS !== 'undefined' && PRISM_CONSTANTS.DEBUG) && console.log('[PRISM_MASTER_DB] Initialization complete');\n    console.log(`  Machines: ${this.stats.machines}+`);\n    console.log(`  Materials: ${this.stats.materials}+`);\n    console.log(`  Tools: ${this.stats.tools.toLocaleString()}`);\n    console.log(`  CAM Strategies: ${this.stats.camStrategies}+`);\n    console.log(`  Post Processors: ${this.stats.postProcessors}+`);\n\n    return this;\n  }\n}",
      "methods": [],
      "lines": 123
    },
    {
      "name": "PRISM_ENHANCEMENTS",
      "category": "core",
      "refs": 100,
      "status": "NOT_FOUND",
      "code": "",
      "methods": [],
      "lines": 0
    },
    {
      "name": "PRISM_AI_AUTO_CAM",
      "category": "engines/ai_ml",
      "refs": 160,
      "status": "NOT_FOUND",
      "code": "",
      "methods": [],
      "lines": 0
    },
    {
      "name": "PRISM_PHASE3_DEEP_LEARNING",
      "category": "engines/ai_ml",
      "refs": 60,
      "status": "FOUND",
      "code": "const PRISM_PHASE3_DEEP_LEARNING = {\n    name: 'Phase 3 Deep Learning Module',\n    version: '1.0.0',\n    sources: ['Stanford CS231N', 'MIT 15.773', 'fast.ai'],\n    algorithmCount: 25,\n    \n    /**\n     * 2D Convolution Layer\n     * Source: Stanford CS231N - Convolutional Neural Networks\n     * Usage: Feature extraction from CAD images, vibration spectrograms\n     */\n    conv2D: function(input, kernels, stride = 1, padding = 0) {\n        const [batchSize, inChannels, height, width] = [\n            input.length, input[0].length, input[0][0].length, input[0][0][0].length\n        ];\n        const [outChannels, kC, kH, kW] = [\n            kernels.length, kernels[0].length, kernels[0][0].length, kernels[0][0][0].length\n        ];\n        \n        const outH = Math.floor((height + 2 * padding - kH) / stride) + 1;\n        const outW = Math.floor((width + 2 * padding - kW) / stride) + 1;\n        \n        // Initialize output\n        const output = Array(batchSize).fill(0).map(() =>\n            Array(outChannels).fill(0).map(() =>\n                Array(outH).fill(0).map(() => Array(outW).fill(0))\n            )\n        );\n        \n        // Convolution\n        for (let b = 0; b < batchSize; b++) {\n            for (let oc = 0; oc < outChannels; oc++) {\n                for (let oh = 0; oh < outH; oh++) {\n                    for (let ow = 0; ow < outW; ow++) {\n                        let sum = 0;\n                        for (let ic = 0; ic < inChannels; ic++) {\n                            for (let kh = 0; kh < kH; kh++) {\n                                for (let kw = 0; kw < kW; kw++) {\n                                    const ih = oh * stride - padding + kh;\n                                    const iw = ow * stride - padding + kw;\n                                    if (ih >= 0 && ih < height && iw >= 0 && iw < width) {\n                                        sum += input[b][ic][ih][iw] * kernels[oc][ic][kh][kw];\n                                    }\n                                }\n                            }\n                        }\n                        output[b][oc][oh][ow] = sum;\n                    }\n                }\n            }\n        }\n        \n        return { output, shape: [batchSize, outChannels, outH, outW] };\n    },\n    \n    /**\n     * Max Pooling 2D\n     * Source: Stanford CS231N\n     */\n    maxPool2D: function(input, poolSize = 2, stride = 2) {\n        const [batchSize, channels, height, width] = [\n            input.length, input[0].length, input[0][0].length, input[0][0][0].length\n        ];\n        \n        const outH = Math.floor((height - poolSize) / stride) + 1;\n        const outW = Math.floor((width - poolSize) / stride) + 1;\n        \n        const output = Array(batchSize).fill(0).map(() =>\n            Array(channels).fill(0).map(() =>\n                Array(outH).fill(0).map(() => Array(outW).fill(0))\n            )\n        );\n        \n        for (let b = 0; b < batchSize; b++) {\n            for (let c = 0; c < channels; c++) {\n                for (let oh = 0; oh < outH; oh++) {\n                    for (let ow = 0; ow < outW; ow++) {\n                        let maxVal = -Infinity;\n                        for (let ph = 0; ph < poolSize; ph++) {\n                            for (let pw = 0; pw < poolSize; pw++) {\n                                const ih = oh * stride + ph;\n                                const iw = ow * stride + pw;\n                                maxVal = Math.max(maxVal, input[b][c][ih][iw]);\n                            }\n                        }\n                        output[b][c][oh][ow] = maxVal;\n                    }\n                }\n            }\n        }\n        \n        return { output, shape: [batchSize, channels, outH, outW] };\n    },\n    \n    /**\n     * Average Pooling 2D\n     */\n    avgPool2D: function(input, poolSize = 2, stride = 2) {\n        const [batchSize, channels, height, width] = [\n            input.length, input[0].length, input[0][0].length, input[0][0][0].length\n        ];\n        \n        const outH = Math.floor((height - poolSize) / stride) + 1;\n        const outW = Math.floor((width - poolSize) / stride) + 1;\n        \n        const output = Array(batchSize).fill(0).map(() =>\n            Array(channels).fill(0).map(() =>\n                Array(outH).fill(0).map(() => Array(outW).fill(0))\n            )\n        );\n        \n        for (let b = 0; b < batchSize; b++) {\n            for (let c = 0; c < channels; c++) {\n                for (let oh = 0; oh < outH; oh++) {\n                    for (let ow = 0; ow < outW; ow++) {\n                        let sum = 0;\n                        for (let ph = 0; ph < poolSize; ph++) {\n                            for (let pw = 0; pw < poolSize; pw++) {\n                                sum += input[b][c][oh * stride + ph][ow * stride + pw];\n                            }\n                        }\n                        output[b][c][oh][ow] = sum / (poolSize * poolSize);\n                    }\n                }\n            }\n        }\n        \n        return { output, shape: [batchSize, channels, outH, outW] };\n    },\n    \n    /**\n     * Batch Normalization\n     * Source: Stanford CS231N - Batch Normalization (Ioffe & Szegedy 2015)\n     * Usage: Stabilize training, reduce internal covariate shift\n     */\n    batchNorm: function(input, gamma = 1, beta = 0, eps = 1e-5) {\n        const batchSize = input.length;\n        const features = input[0].length;\n        \n        // Calculate mean and variance\n        const mean = new Array(features).fill(0);\n        const variance = new Array(features).fill(0);\n        \n        for (let f = 0; f < features; f++) {\n            for (let b = 0; b < batchSize; b++) {\n                mean[f] += input[b][f];\n            }\n            mean[f] /= batchSize;\n            \n            for (let b = 0; b < batchSize; b++) {\n                variance[f] += Math.pow(input[b][f] - mean[f], 2);\n            }\n            variance[f] /= batchSize;\n        }\n        \n        // Normalize\n        const output = input.map(batch =>\n            batch.map((val, f) => gamma * (val - mean[f]) / Math.sqrt(variance[f] + eps) + beta)\n        );\n        \n        return { output, mean, variance, source: 'Stanford CS231N - Batch Normalization' };\n    },\n    \n    /**\n     * Layer Normalization\n     * Source: MIT 15.773 Deep Learning\n     */\n    layerNorm: function(input, gamma = 1, beta = 0, eps = 1e-5) {\n        const output = input.map(sample => {\n            const mean = sample.reduce((a, b) => a + b, 0) / sample.length;\n            const variance = sample.reduce((a, b) => a + Math.pow(b - mean, 2), 0) / sample.length;\n            return sample.map(val => gamma * (val - mean) / Math.sqrt(variance + eps) + beta);\n        });\n        \n        return { output, source: 'MIT 15.773 - Layer Normalization' };\n    },\n    \n    /**\n     * Dropout Layer\n     * Source: Stanford CS231N\n     * Usage: Regularization during training\n     */\n    dropout: function(input, dropRate = 0.5, training = true) {\n        if (!training) {\n            return { output: input, mask: null };\n        }\n        \n        const mask = input.map(row =>\n            row.map(() => Math.random() > dropRate ? 1 / (1 - dropRate) : 0)\n        );\n        \n        const output = input.map((row, i) =>\n            row.map((val, j) => val * mask[i][j])\n        );\n        \n        return { output, mask, source: 'Stanford CS231N - Dropout' };\n    },\n    \n    /**\n     * LSTM (Long Short-Term Memory) Cell\n     * Source: MIT 15.773 Deep Learning for Manufacturing\n     * Usage: Toolpath sequence prediction, time series forecasting\n     */\n    lstm: function(input, hiddenSize, weights = null) {\n        const seqLen = input.length;\n        const inputSize = input[0].length;\n        \n        // Initialize weights if not provided\n        if (!weights) {\n            const initWeight = (rows, cols) =>\n                Array(rows).fill(0).map(() =>\n                    Array(cols).fill(0).map(() => (Math.random() - 0.5) * Math.sqrt(2 / (rows + cols)))\n                );\n            \n            weights = {\n                Wi: initWeight(hiddenSize, inputSize),\n                Wf: initWeight(hiddenSize, inputSize),\n                Wo: initWeight(hiddenSize, inputSize),\n                Wc: initWeight(hiddenSize, inputSize),\n                Ui: initWeight(hiddenSize, hiddenSize),\n                Uf: initWeight(hiddenSize, hiddenSize),\n                Uo: initWeight(hiddenSize, hiddenSize),\n                Uc: initWeight(hiddenSize, hiddenSize),\n                bi: new Array(hiddenSize).fill(0),\n                bf: new Array(hiddenSize).fill(1), // Forget bias = 1\n                bo: new Array(hiddenSize).fill(0),\n                bc: new Array(hiddenSize).fill(0)\n            };\n        }\n        \n        const sigmoid = x => 1 / (1 + Math.exp(-Math.max(-500, Math.min(500, x))));\n        const tanh = x => Math.tanh(x);\n        \n        const matVec = (M, v) => M.map(row => row.reduce((sum, w, i) => sum + w * v[i], 0));\n        const addVec = (a, b) => a.map((v, i) => v + b[i]);\n        const mulVec = (a, b) => a.map((v, i) => v * b[i]);\n        \n        let h = new Array(hiddenSize).fill(0);\n        let c = new Array(hiddenSize).fill(0);\n        const outputs = [];\n        const states = [];\n        \n        for (let t = 0; t < seqLen; t++) {\n            const x = input[t];\n            \n            // Gates\n            const i_gate = addVec(addVec(matVec(weights.Wi, x), matVec(weights.Ui, h)), weights.bi).map(sigmoid);\n            const f_gate = addVec(addVec(matVec(weights.Wf, x), matVec(weights.Uf, h)), weights.bf).map(sigmoid);\n            const o_gate = addVec(addVec(matVec(weights.Wo, x), matVec(weights.Uo, h)), weights.bo).map(sigmoid);\n            const c_tilde = addVec(addVec(matVec(weights.Wc, x), matVec(weights.Uc, h)), weights.bc).map(tanh);\n            \n            // Update cell state and hidden state\n            c = addVec(mulVec(f_gate, c), mulVec(i_gate, c_tilde));\n            h = mulVec(o_gate, c.map(tanh));\n            \n            outputs.push([...h]);\n            states.push({ h: [...h], c: [...c] });\n        }\n        \n        return { outputs, finalState: { h, c }, weights, source: 'MIT 15.773 - LSTM' };\n    },\n    \n    /**\n     * GRU (Gated Recurrent Unit) Cell\n     * Source: MIT 15.773\n     * Usage: Simpler alternative to LSTM for sequence modeling\n     */\n    gru: function(input, hiddenSize, weights = null) {\n        const seqLen = input.length;\n        const inputSize = input[0].length;\n        \n        if (!weights) {\n            const initWeight = (rows, cols) =>\n                Array(rows).fill(0).map(() =>\n                    Array(cols).fill(0).map(() => (Math.random() - 0.5) * Math.sqrt(2 / (rows + cols)))\n                );\n            \n            weights = {\n                Wz: initWeight(hiddenSize, inputSize),\n                Wr: initWeight(hiddenSize, inputSize),\n                Wh: initWeight(hiddenSize, inputSize),\n                Uz: initWeight(hiddenSize, hiddenSize),\n                Ur: initWeight(hiddenSize, hiddenSize),\n                Uh: initWeight(hiddenSize, hiddenSize),\n                bz: new Array(hiddenSize).fill(0),\n                br: new Array(hiddenSize).fill(0),\n                bh: new Array(hiddenSize).fill(0)\n            };\n        }\n        \n        const sigmoid = x => 1 / (1 + Math.exp(-Math.max(-500, Math.min(500, x))));\n        const tanh = x => Math.tanh(x);\n        \n        const matVec = (M, v) => M.map(row => row.reduce((sum, w, i) => sum + w * v[i], 0));\n        const addVec = (a, b) => a.map((v, i) => v + b[i]);\n        const mulVec = (a, b) => a.map((v, i) => v * b[i]);\n        \n        let h = new Array(hiddenSize).fill(0);\n        const outputs = [];\n        \n        for (let t = 0; t < seqLen; t++) {\n            const x = input[t];\n            \n            const z = addVec(addVec(matVec(weights.Wz, x), matVec(weights.Uz, h)), weights.bz).map(sigmoid);\n            const r = addVec(addVec(matVec(weights.Wr, x), matVec(weights.Ur, h)), weights.br).map(sigmoid);\n            const h_tilde = addVec(addVec(matVec(weights.Wh, x), matVec(weights.Uh, mulVec(r, h))), weights.bh).map(tanh);\n            \n            h = addVec(mulVec(z.map(v => 1 - v), h), mulVec(z, h_tilde));\n            outputs.push([...h]);\n        }\n        \n        return { outputs, finalState: h, weights, source: 'MIT 15.773 - GRU' };\n    },\n    \n    /**\n     * Scaled Dot-Product Attention\n     * Source: MIT 15.773 - \"Attention Is All You Need\"\n     * Usage: Feature importance weighting, self-attention in sequences\n     */\n    attention: function(query, key, value, mask = null) {\n        const dK = key[0].length;\n        const scale = Math.sqrt(dK);\n        \n        // QK^T / sqrt(d_k)\n        const scores = query.map(q =>\n            key.map(k =>\n                q.reduce((sum, qv, i) => sum + qv * k[i], 0) / scale\n            )\n        );\n        \n        // Apply mask if provided\n        if (mask) {\n            for (let i = 0; i < scores.length; i++) {\n                for (let j = 0; j < scores[i].length; j++) {\n                    if (mask[i][j] === 0) {\n                        scores[i][j] = -1e9;\n                    }\n                }\n            }\n        }\n        \n        // Softmax\n        const attention = scores.map(row => {\n            const maxVal = Math.max(...row);\n            const exp = row.map(v => Math.exp(v - maxVal));\n            const sum = exp.reduce((a, b) => a + b, 0);\n            return exp.map(v => v / sum);\n        });\n        \n        // Weighted sum of values\n        const output = attention.map(attn =>\n            value[0].map((_, vIdx) =>\n                attn.reduce((sum, a, kIdx) => sum + a * value[kIdx][vIdx], 0)\n            )\n        );\n        \n        return { output, attention, source: 'MIT 15.773 - Scaled Dot-Product Attention' };\n    },\n    \n    /**\n     * Multi-Head Attention\n     * Source: MIT 15.773 - Transformer Architecture\n     */\n    multiHeadAttention: function(query, key, value, numHeads = 8) {\n        const dModel = query[0].length;\n        const dK = Math.floor(dModel / numHeads);\n        \n        const heads = [];\n        \n        for (let h = 0; h < numHeads; h++) {\n            // Project Q, K, V for this head\n            const startIdx = h * dK;\n            const endIdx = startIdx + dK;\n            \n            const qProj = query.map(q => q.slice(startIdx, endIdx));\n            const kProj = key.map(k => k.slice(startIdx, endIdx));\n            const vProj = value.map(v => v.slice(startIdx, endIdx));\n            \n            // Apply attention\n            const { output } = this.attention(qProj, kProj, vProj);\n            heads.push(output);\n        }\n        \n        // Concatenate heads\n        const concat = query.map((_, i) =>\n            heads.flatMap(head => head[i])\n        );\n        \n        return { output: concat, heads, source: 'MIT 15.773 - Multi-Head Attention' };\n    },\n    \n    /**\n     * Transformer Encoder Layer\n     * Source: MIT 15.773\n     */\n    transformerEncoder: function(input, numHeads = 8, ffnDim = 2048) {\n        // Self-attention\n        const { output: attnOutput } = this.multiHeadAttention(input, input, input, numHeads);\n        \n        // Add & Norm 1\n        const addNorm1 = input.map((x, i) => {\n            const sum = x.map((v, j) => v + attnOutput[i][j]);\n            const mean = sum.reduce((a, b) => a + b, 0) / sum.length;\n            const variance = sum.reduce((a, b) => a + Math.pow(b - mean, 2), 0) / sum.length;\n            return sum.map(v => (v - mean) / Math.sqrt(variance + 1e-6));\n        });\n        \n        // Feed-forward network\n        const ffnOutput = addNorm1.map(x => {\n            // First linear + ReLU\n            const hidden = x.map(v => Math.max(0, v * Math.sqrt(2)));\n            // Second linear\n            return hidden;\n        });\n        \n        // Add & Norm 2\n        const output = addNorm1.map((x, i) => {\n            const sum = x.map((v, j) => v + ffnOutput[i][j]);\n            const mean = sum.reduce((a, b) => a + b, 0) / sum.length;\n            const variance = sum.reduce((a, b) => a + Math.pow(b - mean, 2), 0) / sum.length;\n            return sum.map(v => (v - mean) / Math.sqrt(variance + 1e-6));\n        });\n        \n        return { output, source: 'MIT 15.773 - Transformer Encoder' };\n    },\n    \n    /**\n     * Transformer Decoder Layer\n     * Source: MIT 15.773\n     */\n    transformerDecoder: function(input, encoderOutput, numHeads = 8) {\n        // Masked self-attention\n        const seqLen = input.length;\n        const mask = Array(seqLen).fill(0).map((_, i) =>\n            Array(seqLen).fill(0).map((_, j) => j <= i ? 1 : 0)\n        );\n        \n        const { output: selfAttn } = this.multiHeadAttention(input, input, input, numHeads);\n        \n        // Add & Norm 1\n        const addNorm1 = input.map((x, i) => {\n            const sum = x.map((v, j) => v + selfAttn[i][j]);\n            const mean = sum.reduce((a, b) => a + b, 0) / sum.length;\n            const variance = sum.reduce((a, b) => a + Math.pow(b - mean, 2), 0) / sum.length;\n            return sum.map(v => (v - mean) / Math.sqrt(variance + 1e-6));\n        });\n        \n        // Cross-attention\n        const { output: crossAttn } = this.multiHeadAttention(addNorm1, encoderOutput, encoderOutput, numHeads);\n        \n        // Add & Norm 2\n        const addNorm2 = addNorm1.map((x, i) => {\n            const sum = x.map((v, j) => v + crossAttn[i][j]);\n            const mean = sum.reduce((a, b) => a + b, 0) / sum.length;\n            const variance = sum.reduce((a, b) => a + Math.pow(b - mean, 2), 0) / sum.length;\n            return sum.map(v => (v - mean) / Math.sqrt(variance + 1e-6));\n        });\n        \n        return { output: addNorm2, source: 'MIT 15.773 - Transformer Decoder' };\n    },\n    \n    /**\n     * Positional Encoding\n     * Source: MIT 15.773 - \"Attention Is All You Need\"\n     */\n    positionalEncoding: function(seqLen, dModel) {\n        const pe = Array(seqLen).fill(0).map(() => Array(dModel).fill(0));\n        \n        for (let pos = 0; pos < seqLen; pos++) {\n            for (let i = 0; i < dModel; i++) {\n                const angle = pos / Math.pow(10000, (2 * Math.floor(i / 2)) / dModel);\n                pe[pos][i] = i % 2 === 0 ? Math.sin(angle) : Math.cos(angle);\n            }\n        }\n        \n        return { encoding: pe, source: 'MIT 15.773 - Positional Encoding' };\n    },\n    \n    /**\n     * Residual Block\n     * Source: Stanford CS231N - ResNet\n     */\n    residualBlock: function(input, convFn) {\n        const residual = convFn(input);\n        const output = input.map((x, i) =>\n            x.map((v, j) => v + residual[i][j])\n        );\n        return { output, source: 'Stanford CS231N - ResNet Residual Block' };\n    },\n    \n    /**\n     * Dense (DenseNet) Block\n     * Source: Stanford CS231N\n     */\n    denseBlock: function(input, numLayers, growthRate) {\n        let features = [...input];\n        \n        for (let l = 0; l < numLayers; l++) {\n            const newFeatures = features.map(x =>\n                x.map(v => Math.max(0, v * growthRate / numLayers))\n            );\n            features = features.map((x, i) => [...x, ...newFeatures[i]]);\n        }\n        \n        return { output: features, source: 'Stanford CS231N - DenseNet Block' };\n    },\n    \n    /**\n     * GELU Activation\n     * Source: Stanford CS231N\n     */\n    gelu: function(x) {\n        return x * 0.5 * (1 + Math.tanh(Math.sqrt(2 / Math.PI) * (x + 0.044715 * Math.pow(x, 3))));\n    },\n    \n    /**\n     * Swish Activation\n     */\n    swish: function(x, beta = 1) {\n        return x / (1 + Math.exp(-beta * x));\n    },\n    \n    /**\n     * CNN for CAD Feature Recognition\n     * Source: MIT 15.773 + Stanford CS231N combined\n     * Usage: Automatic detection of manufacturing features (holes, pockets, slots)\n     */\n    cnnFeatureRecognition: function(cadImage) {\n        // Simplified CNN pipeline for feature detection\n        const features = {\n            holes: [],\n            pockets: [],\n            slots: [],\n            bosses: [],\n            chamfers: [],\n            fillets: []\n        };\n        \n        // Placeholder for actual CNN inference\n        return {\n            features,\n            confidence: 0.85,\n            source: 'MIT 15.773 + Stanford CS231N - CAD Feature Recognition',\n            note: 'Full implementation requires trained model weights'\n        };\n    },\n    \n    /**\n     * LSTM for Toolpath Prediction\n     * Source: MIT 15.773\n     * Usage: Predict optimal next toolpath point based on sequence history\n     */\n    lstmToolpath: function(pathHistory, hiddenSize = 64) {\n        const { outputs, finalState } = this.lstm(pathHistory, hiddenSize);\n        \n        // Predict next point (x, y, z, feed)\n        const lastOutput = outputs[outputs.length - 1];\n        const prediction = {\n            x: lastOutput[0] || 0,\n            y: lastOutput[1] || 0,\n            z: lastOutput[2] || 0,\n            feed: Math.abs(lastOutput[3]) || 1000\n        };\n        \n        return {\n            prediction,\n            confidence: 0.8,\n            source: 'MIT 15.773 - LSTM Toolpath Prediction'\n        };\n    },\n    \n    /**\n     * Sequence-to-Sequence Model\n     * Source: MIT 15.773\n     */\n    seq2seq: function(encoderInput, decoderInput, hiddenSize = 128) {\n        const { outputs: encOutputs, finalState } = this.lstm(encoderInput, hiddenSize);\n        const { outputs: decOutputs } = this.lstm(decoderInput, hiddenSize, null);\n        \n        return {\n            encoderOutputs: encOutputs,\n            decoderOutputs: decOutputs,\n            source: 'MIT 15.773 - Seq2Seq'\n        };\n    },\n    \n    /**\n     * Embedding Layer\n     * Source: MIT 15.773\n     */\n    embedding: function(indices, vocabSize, embeddingDim) {\n        const embeddingMatrix = Array(vocabSize).fill(0).map(() =>\n            Array(embeddingDim).fill(0).map(() => (Math.random() - 0.5) * 0.1)\n        );\n        \n        const embeddings = indices.map(idx => embeddingMatrix[idx] || embeddingMatrix[0]);\n        \n        return { embeddings, matrix: embeddingMatrix, source: 'MIT 15.773 - Embedding Layer' };\n    },\n    \n    /**\n     * U-Net Encoder (for segmentation)\n     * Source: Stanford CS231N\n     */\n    unetEncoder: function(input, levels = 4) {\n        const features = [input];\n        let current = input;\n        \n        for (let l = 0; l < levels; l++) {\n            // Simplified: double channels, halve spatial dims\n            features.push(current);\n        }\n        \n        return { features, source: 'Stanford CS231N - U-Net Encoder' };\n    },\n    \n    /**\n     * U-Net Decoder\n     */\n    unetDecoder: function(encoderFeatures) {\n        const output = encoderFeatures[0];\n        return { output, source: 'Stanford CS231N - U-Net Decoder' };\n    },\n    \n    /**\n     * VAE Encoder\n     * Source: Stanford CS236\n     */\n    vaeEncoder: function(input, latentDim = 32) {\n        const mean = input.map(x => x.reduce((a, b) => a + b, 0) / x.length);\n        const logVar = input.map(() => 0);\n        \n        // Reparameterization trick\n        const z = mean.map((m, i) =>\n            m + Math.exp(0.5 * logVar[i]) * (Math.random() * 2 - 1)\n        );\n        \n        return { z, mean, logVar, source: 'Stanford CS236 - VAE Encoder' };\n    },\n    \n    /**\n     * VAE Decoder\n     */\n    vaeDecoder: function(z, outputDim) {\n        const output = Array(outputDim).fill(0).map((_, i) =>\n            z.reduce((sum, zv) => sum + zv * (Math.random() - 0.5), 0)\n        );\n        \n        return { output, source: 'Stanford CS236 - VAE Decoder' };\n    }\n}",
      "methods": [],
      "lines": 651
    },
    {
      "name": "PRISM_LEAN_SIX_SIGMA_KAIZEN",
      "category": "engines/ai_ml",
      "refs": 52,
      "status": "FOUND",
      "code": "const PRISM_LEAN_SIX_SIGMA_KAIZEN = {\n    VERSION: '1.0.0',\n    BUILD_DATE: '2026-01-15',\n\n    // SECTION 1: SIX SIGMA - Statistical Process Control\n    sixSigma: {\n\n        // 1.1 Process Capability Indices\n        processCapability: {\n            /**\n             * Calculate Cp (Process Capability)\n             * Measures potential capability if process is centered\n             * @param {number} USL - Upper specification limit\n             * @param {number} LSL - Lower specification limit\n             * @param {number} sigma - Process standard deviation\n             * @returns {number} Cp value\n             */\n            calculateCp: function(USL, LSL, sigma) {\n                if (sigma <= 0) return 0;\n                return (USL - LSL) / (6 * sigma);\n            },\n            /**\n             * Calculate Cpk (Process Capability Index)\n             * Measures actual capability considering centering\n             * @param {number} USL - Upper specification limit\n             * @param {number} LSL - Lower specification limit\n             * @param {number} mean - Process mean\n             * @param {number} sigma - Process standard deviation\n             * @returns {object} Cpk value with interpretation\n             */\n            calculateCpk: function(USL, LSL, mean, sigma) {\n                if (sigma <= 0) return { value: 0, interpretation: 'Invalid sigma' };\n\n                const cpkUpper = (USL - mean) / (3 * sigma);\n                const cpkLower = (mean - LSL) / (3 * sigma);\n                const cpk = Math.min(cpkUpper, cpkLower);\n\n                let interpretation;\n                if (cpk >= 2.0) interpretation = 'World Class (6\u03c3)';\n                else if (cpk >= 1.67) interpretation = 'Excellent (5\u03c3)';\n                else if (cpk >= 1.33) interpretation = 'Good (4\u03c3)';\n                else if (cpk >= 1.0) interpretation = 'Capable (3\u03c3)';\n                else if (cpk >= 0.67) interpretation = 'Marginal';\n                else interpretation = 'Not Capable - Action Required';\n\n                return {\n                    value: cpk,\n                    cpkUpper,\n                    cpkLower,\n                    interpretation,\n                    ppm: this._cpkToPPM(cpk),\n                    sigmaLevel: this._cpkToSigma(cpk)\n                };\n            },\n            /**\n             * Calculate Ppk (Process Performance Index)\n             * Uses overall standard deviation (includes between-group variation)\n             */\n            calculatePpk: function(USL, LSL, mean, overallSigma) {\n                return this.calculateCpk(USL, LSL, mean, overallSigma);\n            },\n            /**\n             * PRISM INNOVATION: Cpk with Gaussian Process Uncertainty\n             * Provides confidence intervals on capability indices\n             */\n            calculateCpkWithUncertainty: function(measurements, USL, LSL) {\n                const n = measurements.length;\n                if (n < 10) return { error: 'Need at least 10 measurements' };\n\n                const mean = measurements.reduce((a, b) => a + b, 0) / n;\n                const sigma = Math.sqrt(measurements.reduce((sum, x) =>\n                    sum + Math.pow(x - mean, 2), 0) / (n - 1));\n\n                // Bootstrap for confidence intervals\n                const bootstrapCpks = [];\n                for (let i = 0; i < 1000; i++) {\n                    const sample = [];\n                    for (let j = 0; j < n; j++) {\n                        sample.push(measurements[Math.floor(Math.random() * n)]);\n                    }\n                    const sampleMean = sample.reduce((a, b) => a + b, 0) / n;\n                    const sampleSigma = Math.sqrt(sample.reduce((sum, x) =>\n                        sum + Math.pow(x - sampleMean, 2), 0) / (n - 1));\n                    if (sampleSigma > 0) {\n                        const cpk = Math.min(\n                            (USL - sampleMean) / (3 * sampleSigma),\n                            (sampleMean - LSL) / (3 * sampleSigma)\n                        );\n                        bootstrapCpks.push(cpk);\n                    }\n                }\n                bootstrapCpks.sort((a, b) => a - b);\n                const ci95Lower = bootstrapCpks[Math.floor(bootstrapCpks.length * 0.025)];\n                const ci95Upper = bootstrapCpks[Math.floor(bootstrapCpks.length * 0.975)];\n\n                const cpk = this.calculateCpk(USL, LSL, mean, sigma);\n\n                return {\n                    ...cpk,\n                    confidence95: { lower: ci95Lower, upper: ci95Upper },\n                    sampleSize: n,\n                    uncertaintyLevel: (ci95Upper - ci95Lower) / cpk.value\n                };\n            },\n            _cpkToPPM: function(cpk) {\n                // Approximate PPM from Cpk using normal distribution\n                if (cpk <= 0) return 1000000;\n                const z = cpk * 3;\n                // One-sided, so multiply by 2 for both tails\n                return Math.round(2 * 1000000 * (1 - this._normalCDF(z)));\n            },\n            _cpkToSigma: function(cpk) {\n                return Math.round(cpk * 3 * 10) / 10;\n            },\n            _normalCDF: function(z) {\n                const a1 = 0.254829592, a2 = -0.284496736, a3 = 1.421413741;\n                const a4 = -1.453152027, a5 = 1.061405429, p = 0.3275911;\n                const sign = z < 0 ? -1 : 1;\n                z = Math.abs(z) / Math.sqrt(2);\n                const t = 1 / (1 + p * z);\n                const y = 1 - (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t * Math.exp(-z * z);\n                return 0.5 * (1 + sign * y);\n            }\n        },\n        // 1.2 Control Charts (X-bar, R, S, p, np, c, u)\n        controlCharts: {\n            /**\n             * X-bar and R Chart (Variables data)\n             * Most common SPC chart for continuous measurements\n             */\n            xBarRChart: function(subgroups) {\n                const n = subgroups[0].length; // Subgroup size\n                const k = subgroups.length; // Number of subgroups\n\n                // Constants for control chart factors\n                const factors = {\n                    2: { A2: 1.880, D3: 0, D4: 3.267, d2: 1.128 },\n                    3: { A2: 1.023, D3: 0, D4: 2.574, d2: 1.693 },\n                    4: { A2: 0.729, D3: 0, D4: 2.282, d2: 2.059 },\n                    5: { A2: 0.577, D3: 0, D4: 2.114, d2: 2.326 },\n                    6: { A2: 0.483, D3: 0, D4: 2.004, d2: 2.534 },\n                    7: { A2: 0.419, D3: 0.076, D4: 1.924, d2: 2.704 },\n                    8: { A2: 0.373, D3: 0.136, D4: 1.864, d2: 2.847 },\n                    9: { A2: 0.337, D3: 0.184, D4: 1.816, d2: 2.970 },\n                    10: { A2: 0.308, D3: 0.223, D4: 1.777, d2: 3.078 }\n                };\n                const f = factors[n] || factors[5];\n\n                // Calculate subgroup statistics\n                const xBars = subgroups.map(sg => sg.reduce((a, b) => a + b, 0) / n);\n                const ranges = subgroups.map(sg => Math.max(...sg) - Math.min(...sg));\n\n                // Calculate centerlines\n                const xBarBar = xBars.reduce((a, b) => a + b, 0) / k;\n                const rBar = ranges.reduce((a, b) => a + b, 0) / k;\n\n                // Calculate control limits\n                const xBarUCL = xBarBar + f.A2 * rBar;\n                const xBarLCL = xBarBar - f.A2 * rBar;\n                const rUCL = f.D4 * rBar;\n                const rLCL = f.D3 * rBar;\n\n                // Detect out-of-control points\n                const outOfControl = [];\n                xBars.forEach((xBar, i) => {\n                    if (xBar > xBarUCL || xBar < xBarLCL) {\n                        outOfControl.push({ index: i, type: 'X-bar', value: xBar });\n                    }\n                });\n                ranges.forEach((r, i) => {\n                    if (r > rUCL || r < rLCL) {\n                        outOfControl.push({ index: i, type: 'Range', value: r });\n                    }\n                });\n\n                return {\n                    chartType: 'X-bar and R',\n                    subgroupSize: n,\n                    numSubgroups: k,\n                    xBar: {\n                        centerline: xBarBar,\n                        UCL: xBarUCL,\n                        LCL: xBarLCL,\n                        values: xBars\n                    },\n                    range: {\n                        centerline: rBar,\n                        UCL: rUCL,\n                        LCL: rLCL,\n                        values: ranges\n                    },\n                    estimatedSigma: rBar / f.d2,\n                    outOfControl,\n                    inControl: outOfControl.length === 0\n                };\n            },\n            /**\n             * Individual and Moving Range Chart (I-MR)\n             * For when subgrouping is not possible\n             */\n            iMRChart: function(individuals) {\n                const n = individuals.length;\n\n                // Calculate moving ranges\n                const movingRanges = [];\n                for (let i = 1; i < n; i++) {\n                    movingRanges.push(Math.abs(individuals[i] - individuals[i - 1]));\n                }\n                // Centerlines\n                const xBar = individuals.reduce((a, b) => a + b, 0) / n;\n                const mRBar = movingRanges.reduce((a, b) => a + b, 0) / movingRanges.length;\n\n                // Control limits (d2 = 1.128 for n=2)\n                const d2 = 1.128;\n                const D4 = 3.267;\n                const estimatedSigma = mRBar / d2;\n\n                const iUCL = xBar + 3 * estimatedSigma;\n                const iLCL = xBar - 3 * estimatedSigma;\n                const mrUCL = D4 * mRBar;\n\n                return {\n                    chartType: 'I-MR',\n                    individuals: {\n                        centerline: xBar,\n                        UCL: iUCL,\n                        LCL: iLCL,\n                        values: individuals\n                    },\n                    movingRange: {\n                        centerline: mRBar,\n                        UCL: mrUCL,\n                        LCL: 0,\n                        values: movingRanges\n                    },\n                    estimatedSigma\n                };\n            },\n            /**\n             * p-Chart (Proportion defective)\n             * For attribute data - fraction nonconforming\n             */\n            pChart: function(inspected, defective) {\n                const n = inspected.length;\n                const pBars = defective.map((d, i) => d / inspected[i]);\n                const totalDefective = defective.reduce((a, b) => a + b, 0);\n                const totalInspected = inspected.reduce((a, b) => a + b, 0);\n                const pBar = totalDefective / totalInspected;\n\n                // Variable control limits based on sample size\n                const ucls = inspected.map(ni => pBar + 3 * Math.sqrt(pBar * (1 - pBar) / ni));\n                const lcls = inspected.map(ni => Math.max(0, pBar - 3 * Math.sqrt(pBar * (1 - pBar) / ni)));\n\n                return {\n                    chartType: 'p-Chart',\n                    centerline: pBar,\n                    UCL: ucls,\n                    LCL: lcls,\n                    values: pBars,\n                    averageSampleSize: totalInspected / n\n                };\n            },\n            /**\n             * c-Chart (Count of defects)\n             * For count data with constant sample size\n             */\n            cChart: function(defectCounts) {\n                const cBar = defectCounts.reduce((a, b) => a + b, 0) / defectCounts.length;\n                const ucl = cBar + 3 * Math.sqrt(cBar);\n                const lcl = Math.max(0, cBar - 3 * Math.sqrt(cBar));\n\n                return {\n                    chartType: 'c-Chart',\n                    centerline: cBar,\n                    UCL: ucl,\n                    LCL: lcl,\n                    values: defectCounts\n                };\n            },\n            /**\n             * PRISM INNOVATION: Self-Adjusting Control Limits with Bayesian Learning\n             * Control limits that adapt based on process history\n             */\n            bayesianControlChart: function(newData, priorHistory = null) {\n                // Prior belief about process parameters\n                let priorMean, priorVariance, priorN;\n\n                if (priorHistory) {\n                    priorMean = priorHistory.mean;\n                    priorVariance = priorHistory.variance;\n                    priorN = priorHistory.n;\n                } else {\n                    // Non-informative prior\n                    priorMean = newData.reduce((a, b) => a + b, 0) / newData.length;\n                    priorVariance = newData.reduce((sum, x) => sum + Math.pow(x - priorMean, 2), 0) / newData.length;\n                    priorN = 1;\n                }\n                // Update with new data\n                const n = newData.length;\n                const dataMean = newData.reduce((a, b) => a + b, 0) / n;\n                const dataVariance = newData.reduce((sum, x) => sum + Math.pow(x - dataMean, 2), 0) / n;\n\n                // Bayesian update (conjugate normal-normal)\n                const posteriorN = priorN + n;\n                const posteriorMean = (priorN * priorMean + n * dataMean) / posteriorN;\n                const posteriorVariance = ((priorN * priorVariance + n * dataVariance) +\n                    (priorN * n * Math.pow(priorMean - dataMean, 2)) / posteriorN) / posteriorN;\n\n                const posteriorSigma = Math.sqrt(posteriorVariance);\n\n                // Adaptive control limits\n                const ucl = posteriorMean + 3 * posteriorSigma;\n                const lcl = posteriorMean - 3 * posteriorSigma;\n\n                // Confidence in limits (higher n = more confident)\n                const confidence = 1 - 1 / Math.sqrt(posteriorN);\n\n                return {\n                    chartType: 'Bayesian Adaptive',\n                    centerline: posteriorMean,\n                    UCL: ucl,\n                    LCL: lcl,\n                    estimatedSigma: posteriorSigma,\n                    confidence,\n                    effectiveSampleSize: posteriorN,\n                    posteriorHistory: {\n                        mean: posteriorMean,\n                        variance: posteriorVariance,\n                        n: posteriorN\n                    },\n                    recommendation: confidence > 0.9 ? 'Limits stable' : 'Continue monitoring'\n                };\n            }\n        },\n        // 1.3 DMAIC Framework\n        dmaic: {\n            /**\n             * Create DMAIC project structure\n             */\n            createProject: function(params) {\n                return {\n                    projectId: 'DMAIC-' + Date.now(),\n                    createdDate: new Date().toISOString(),\n                    name: params.name,\n                    problemStatement: params.problem,\n                    projectScope: params.scope,\n                    teamMembers: params.team || [],\n                    targetMetric: params.metric,\n                    baseline: params.baseline,\n                    target: params.target,\n                    phases: {\n                        define: { status: 'active', startDate: new Date().toISOString(), data: {} },\n                        measure: { status: 'pending', data: {} },\n                        analyze: { status: 'pending', data: {} },\n                        improve: { status: 'pending', data: {} },\n                        control: { status: 'pending', data: {} }\n                    },\n                    currentPhase: 'define'\n                };\n            },\n            /**\n             * Calculate Sigma Level from defect rate\n             */\n            calculateSigmaLevel: function(defects, opportunities, units) {\n                const dpo = defects / (opportunities * units);\n                const dpmo = dpo * 1000000;\n\n                // Convert DPMO to Sigma Level (1.5 shift included)\n                const z = this._dpmoToZ(dpmo);\n                const sigmaLevel = z + 1.5; // Add 1.5 sigma shift\n\n                return {\n                    defects,\n                    opportunities,\n                    units,\n                    dpo,\n                    dpmo: Math.round(dpmo),\n                    yield: (1 - dpo) * 100,\n                    sigmaLevel: Math.round(sigmaLevel * 100) / 100,\n                    interpretation: this._interpretSigma(sigmaLevel)\n                };\n            },\n            _dpmoToZ: function(dpmo) {\n                // Inverse normal approximation\n                const p = dpmo / 1000000;\n                if (p <= 0) return 6;\n                if (p >= 1) return 0;\n\n                // Newton-Raphson approximation\n                let z = 3;\n                for (let i = 0; i < 10; i++) {\n                    const cdf = PRISM_LEAN_SIX_SIGMA_KAIZEN.sixSigma.processCapability._normalCDF(z);\n                    const pdf = Math.exp(-z * z / 2) / Math.sqrt(2 * Math.PI);\n                    z = z - (cdf - (1 - p)) / pdf;\n                }\n                return z;\n            },\n            _interpretSigma: function(sigma) {\n                if (sigma >= 6) return 'World Class (3.4 DPMO)';\n                if (sigma >= 5) return 'Excellent (233 DPMO)';\n                if (sigma >= 4) return 'Good (6,210 DPMO)';\n                if (sigma >= 3) return 'Average (66,807 DPMO)';\n                if (sigma >= 2) return 'Below Average (308,538 DPMO)';\n                return 'Poor (>691,462 DPMO)';\n            }\n        },\n        // 1.4 FMEA with Monte Carlo (PRISM Innovation)\n        fmea: {\n            /**\n             * Standard FMEA RPN calculation\n             */\n            calculateRPN: function(severity, occurrence, detection) {\n                return severity * occurrence * detection;\n            },\n            /**\n             * PRISM INNOVATION: Probabilistic FMEA with Monte Carlo simulation\n             * Models uncertainty in S, O, D ratings\n             */\n            monteCarloFMEA: function(failureModes, simulations = 10000) {\n                const results = failureModes.map(fm => {\n                    const rpnSamples = [];\n\n                    // Simulate with uncertainty in ratings\n                    for (let i = 0; i < simulations; i++) {\n                        // Allow \u00b11 variation in ratings (triangular distribution)\n                        const s = this._triangularSample(\n                            Math.max(1, fm.severity - 1),\n                            fm.severity,\n                            Math.min(10, fm.severity + 1)\n                        );\n                        const o = this._triangularSample(\n                            Math.max(1, fm.occurrence - 1),\n                            fm.occurrence,\n                            Math.min(10, fm.occurrence + 1)\n                        );\n                        const d = this._triangularSample(\n                            Math.max(1, fm.detection - 1),\n                            fm.detection,\n                            Math.min(10, fm.detection + 1)\n                        );\n\n                        rpnSamples.push(s * o * d);\n                    }\n                    rpnSamples.sort((a, b) => a - b);\n\n                    return {\n                        ...fm,\n                        nominalRPN: fm.severity * fm.occurrence * fm.detection,\n                        meanRPN: rpnSamples.reduce((a, b) => a + b, 0) / simulations,\n                        medianRPN: rpnSamples[Math.floor(simulations / 2)],\n                        p95RPN: rpnSamples[Math.floor(simulations * 0.95)],\n                        p99RPN: rpnSamples[Math.floor(simulations * 0.99)],\n                        worstCaseRPN: rpnSamples[simulations - 1],\n                        riskCategory: this._categorizeRisk(rpnSamples[Math.floor(simulations * 0.95)])\n                    };\n                });\n\n                // Sort by P95 RPN (worst likely case)\n                results.sort((a, b) => b.p95RPN - a.p95RPN);\n\n                return {\n                    failureModes: results,\n                    simulations,\n                    topRisks: results.slice(0, 5),\n                    totalP95Risk: results.reduce((sum, fm) => sum + fm.p95RPN, 0)\n                };\n            },\n            _triangularSample: function(min, mode, max) {\n                const u = Math.random();\n                const fc = (mode - min) / (max - min);\n                if (u < fc) {\n                    return min + Math.sqrt(u * (max - min) * (mode - min));\n                } else {\n                    return max - Math.sqrt((1 - u) * (max - min) * (max - mode));\n                }\n            },\n            _categorizeRisk: function(rpn) {\n                if (rpn >= 200) return 'CRITICAL - Immediate action required';\n                if (rpn >= 100) return 'HIGH - Action required';\n                if (rpn >= 50) return 'MEDIUM - Monitor closely';\n                return 'LOW - Acceptable risk';\n            }\n        }\n    },\n    // SECTION 2: LEAN MANUFACTURING\n    lean: {\n\n        // 2.1 Seven Wastes (Muda) Detection\n        sevenWastes: {\n            wasteTypes: {\n                TRANSPORT: { name: 'Transportation', description: 'Unnecessary movement of materials' },\n                INVENTORY: { name: 'Inventory', description: 'Excess raw materials, WIP, or finished goods' },\n                MOTION: { name: 'Motion', description: 'Unnecessary movement of people' },\n                WAITING: { name: 'Waiting', description: 'Idle time waiting for next step' },\n                OVERPRODUCTION: { name: 'Overproduction', description: 'Making more than needed' },\n                OVERPROCESSING: { name: 'Over-processing', description: 'Doing more work than required' },\n                DEFECTS: { name: 'Defects', description: 'Rework, scrap, corrections' }\n            },\n            /**\n             * Analyze shop floor data for waste indicators\n             * PRISM INNOVATION: AI-powered waste detection patterns\n             */\n            analyzeForWaste: function(shopData) {\n                const wasteFound = [];\n\n                // Transport waste - excessive material movement\n                if (shopData.avgMaterialTravelDistance > 50) { // meters\n                    wasteFound.push({\n                        type: 'TRANSPORT',\n                        severity: Math.min(10, shopData.avgMaterialTravelDistance / 10),\n                        indicator: `Average material travel: ${shopData.avgMaterialTravelDistance}m`,\n                        recommendation: 'Consider cellular manufacturing layout'\n                    });\n                }\n                // Inventory waste - high WIP levels\n                if (shopData.wipDays > 5) {\n                    wasteFound.push({\n                        type: 'INVENTORY',\n                        severity: Math.min(10, shopData.wipDays),\n                        indicator: `WIP covers ${shopData.wipDays} days of production`,\n                        recommendation: 'Implement pull system/kanban'\n                    });\n                }\n                // Waiting waste - machine idle time\n                if (shopData.machineUtilization < 70) {\n                    wasteFound.push({\n                        type: 'WAITING',\n                        severity: Math.round((100 - shopData.machineUtilization) / 10),\n                        indicator: `Machine utilization: ${shopData.machineUtilization}%`,\n                        recommendation: 'Analyze bottlenecks, balance workload'\n                    });\n                }\n                // Defects waste - scrap rate\n                if (shopData.scrapRate > 2) {\n                    wasteFound.push({\n                        type: 'DEFECTS',\n                        severity: Math.min(10, shopData.scrapRate * 2),\n                        indicator: `Scrap rate: ${shopData.scrapRate}%`,\n                        recommendation: 'Root cause analysis, implement poka-yoke'\n                    });\n                }\n                // Overproduction - finished goods inventory\n                if (shopData.finishedGoodsDays > 10) {\n                    wasteFound.push({\n                        type: 'OVERPRODUCTION',\n                        severity: Math.min(10, shopData.finishedGoodsDays / 3),\n                        indicator: `${shopData.finishedGoodsDays} days of FG inventory`,\n                        recommendation: 'Produce to customer demand, not forecast'\n                    });\n                }\n                // Motion waste - setup time\n                if (shopData.avgSetupTime > 60) { // minutes\n                    wasteFound.push({\n                        type: 'MOTION',\n                        severity: Math.min(10, shopData.avgSetupTime / 15),\n                        indicator: `Average setup time: ${shopData.avgSetupTime} minutes`,\n                        recommendation: 'Implement SMED methodology'\n                    });\n                }\n                // Over-processing - excessive tolerances\n                if (shopData.avgToleranceRatio < 0.5) {\n                    wasteFound.push({\n                        type: 'OVERPROCESSING',\n                        severity: Math.round((1 - shopData.avgToleranceRatio) * 10),\n                        indicator: `Tolerances tighter than needed by ${Math.round((1 - shopData.avgToleranceRatio) * 100)}%`,\n                        recommendation: 'Review customer requirements'\n                    });\n                }\n                return {\n                    wastesIdentified: wasteFound.length,\n                    totalSeverity: wasteFound.reduce((sum, w) => sum + w.severity, 0),\n                    wastes: wasteFound.sort((a, b) => b.severity - a.severity),\n                    topPriority: wasteFound[0] || null,\n                    leanScore: Math.max(0, 100 - wasteFound.reduce((sum, w) => sum + w.severity * 2, 0))\n                };\n            }\n        },\n        // 2.2 OEE (Overall Equipment Effectiveness)\n        oee: {\n            /**\n             * Calculate OEE\n             * OEE = Availability \u00d7 Performance \u00d7 Quality\n             */\n            calculate: function(params) {\n                const {\n                    plannedProductionTime,  // minutes\n                    downtime,               // minutes (unplanned + planned stoppages)\n                    idealCycleTime,         // minutes per part\n                    totalParts,             // parts produced\n                    goodParts               // parts meeting quality specs\n                } = params;\n\n                const operatingTime = plannedProductionTime - downtime;\n\n                // Availability = Operating Time / Planned Production Time\n                const availability = operatingTime / plannedProductionTime;\n\n                // Performance = (Ideal Cycle Time \u00d7 Total Parts) / Operating Time\n                const performance = (idealCycleTime * totalParts) / operatingTime;\n\n                // Quality = Good Parts / Total Parts\n                const quality = goodParts / totalParts;\n\n                // OEE\n                const oee = availability * performance * quality;\n\n                return {\n                    availability: Math.round(availability * 1000) / 10,\n                    performance: Math.round(performance * 1000) / 10,\n                    quality: Math.round(quality * 1000) / 10,\n                    oee: Math.round(oee * 1000) / 10,\n                    interpretation: this._interpretOEE(oee),\n                    losses: {\n                        availabilityLoss: (1 - availability) * plannedProductionTime,\n                        performanceLoss: (1 - performance) * operatingTime,\n                        qualityLoss: (totalParts - goodParts) * idealCycleTime\n                    },\n                    benchmark: {\n                        worldClass: 85,\n                        typical: 60,\n                        gap: Math.round((0.85 - oee) * 1000) / 10\n                    }\n                };\n            },\n            /**\n             * PRISM INNOVATION: OEE with Kalman Filter prediction\n             * Predicts future OEE based on trend\n             */\n            predictWithKalman: function(oeeHistory) {\n                if (oeeHistory.length < 5) {\n                    return { error: 'Need at least 5 historical OEE values' };\n                }\n                // Simple Kalman filter implementation\n                const dt = 1; // time step (e.g., 1 day)\n                let x = oeeHistory[0]; // state estimate\n                let P = 1; // estimate uncertainty\n                const Q = 0.1; // process noise\n                const R = 1; // measurement noise\n\n                const estimates = [];\n\n                for (const measurement of oeeHistory) {\n                    // Predict\n                    const xPred = x;\n                    const pPred = P + Q;\n\n                    // Update\n                    const K = pPred / (pPred + R);\n                    x = xPred + K * (measurement - xPred);\n                    P = (1 - K) * pPred;\n\n                    estimates.push(x);\n                }\n                // Predict next 5 periods\n                const predictions = [];\n                let trend = (estimates[estimates.length - 1] - estimates[0]) / estimates.length;\n\n                for (let i = 1; i <= 5; i++) {\n                    predictions.push({\n                        period: i,\n                        predictedOEE: Math.min(100, Math.max(0, x + trend * i)),\n                        confidence: Math.max(0, 1 - 0.1 * i)\n                    });\n                }\n                return {\n                    currentEstimate: x,\n                    trend: trend > 0 ? 'Improving' : trend < 0 ? 'Declining' : 'Stable',\n                    trendValue: Math.round(trend * 100) / 100,\n                    predictions,\n                    smoothedHistory: estimates\n                };\n            },\n            _interpretOEE: function(oee) {\n                if (oee >= 0.85) return 'World Class';\n                if (oee >= 0.75) return 'Good';\n                if (oee >= 0.65) return 'Average';\n                if (oee >= 0.55) return 'Below Average';\n                return 'Poor - Major improvement needed';\n            }\n        },\n        // 2.3 Value Stream Mapping with ACO Optimization\n        valueStreamMapping: {\n            /**\n             * Create Value Stream Map\n             */\n            createVSM: function(processSteps) {\n                const vsm = {\n                    processSteps: processSteps.map((step, i) => ({\n                        ...step,\n                        index: i,\n                        valueAdded: step.cycleTime || 0,\n                        nonValueAdded: (step.waitTime || 0) + (step.transportTime || 0),\n                        leadTime: (step.cycleTime || 0) + (step.waitTime || 0) + (step.transportTime || 0)\n                    })),\n                    metrics: {}\n                };\n                // Calculate overall metrics\n                vsm.metrics.totalLeadTime = vsm.processSteps.reduce((sum, s) => sum + s.leadTime, 0);\n                vsm.metrics.totalValueAdded = vsm.processSteps.reduce((sum, s) => sum + s.valueAdded, 0);\n                vsm.metrics.totalNonValueAdded = vsm.processSteps.reduce((sum, s) => sum + s.nonValueAdded, 0);\n                vsm.metrics.valueAddedRatio = vsm.metrics.totalValueAdded / vsm.metrics.totalLeadTime;\n                vsm.metrics.processEfficiency = Math.round(vsm.metrics.valueAddedRatio * 100);\n\n                // Identify bottleneck\n                const maxCycleTime = Math.max(...vsm.processSteps.map(s => s.cycleTime || 0));\n                vsm.bottleneck = vsm.processSteps.find(s => s.cycleTime === maxCycleTime);\n\n                return vsm;\n            },\n            /**\n             * PRISM INNOVATION: VSM Optimization with Ant Colony Optimization\n             * Finds optimal process sequence to minimize lead time\n             */\n            optimizeWithACO: function(processSteps, constraints = {}) {\n                const n = processSteps.length;\n                const numAnts = 20;\n                const iterations = 50;\n                const alpha = 1; // pheromone importance\n                const beta = 2; // heuristic importance\n                const evaporationRate = 0.5;\n                const Q = 100;\n\n                // Initialize pheromone matrix\n                const pheromone = Array(n).fill(null).map(() => Array(n).fill(1));\n\n                // Calculate heuristic (inverse of transition time)\n                const heuristic = Array(n).fill(null).map(() => Array(n).fill(1));\n                for (let i = 0; i < n; i++) {\n                    for (let j = 0; j < n; j++) {\n                        if (i !== j) {\n                            // Lower transition time = higher desirability\n                            const transitionTime = processSteps[j].setupTime || 10;\n                            heuristic[i][j] = 1 / transitionTime;\n                        }\n                    }\n                }\n                let bestSequence = null;\n                let bestLeadTime = Infinity;\n\n                for (let iter = 0; iter < iterations; iter++) {\n                    const antSequences = [];\n                    const antLeadTimes = [];\n\n                    for (let ant = 0; ant < numAnts; ant++) {\n                        // Build sequence\n                        const visited = new Set();\n                        const sequence = [];\n                        let current = 0; // Start from first process\n                        sequence.push(current);\n                        visited.add(current);\n\n                        while (sequence.length < n) {\n                            // Calculate probabilities for unvisited nodes\n                            const probs = [];\n                            let probSum = 0;\n\n                            for (let j = 0; j < n; j++) {\n                                if (!visited.has(j)) {\n                                    const prob = Math.pow(pheromone[current][j], alpha) *\n                                                 Math.pow(heuristic[current][j], beta);\n                                    probs.push({ node: j, prob });\n                                    probSum += prob;\n                                }\n                            }\n                            // Roulette wheel selection\n                            let r = Math.random() * probSum;\n                            let selected = probs[0].node;\n                            for (const p of probs) {\n                                r -= p.prob;\n                                if (r <= 0) {\n                                    selected = p.node;\n                                    break;\n                                }\n                            }\n                            sequence.push(selected);\n                            visited.add(selected);\n                            current = selected;\n                        }\n                        // Calculate lead time for this sequence\n                        let leadTime = 0;\n                        for (let i = 0; i < sequence.length; i++) {\n                            const step = processSteps[sequence[i]];\n                            leadTime += (step.cycleTime || 0) + (step.waitTime || 0);\n                            if (i > 0) {\n                                leadTime += step.setupTime || 0;\n                            }\n                        }\n                        antSequences.push(sequence);\n                        antLeadTimes.push(leadTime);\n\n                        if (leadTime < bestLeadTime) {\n                            bestLeadTime = leadTime;\n                            bestSequence = [...sequence];\n                        }\n                    }\n                    // Evaporate pheromone\n                    for (let i = 0; i < n; i++) {\n                        for (let j = 0; j < n; j++) {\n                            pheromone[i][j] *= (1 - evaporationRate);\n                        }\n                    }\n                    // Deposit pheromone\n                    for (let ant = 0; ant < numAnts; ant++) {\n                        const deposit = Q / antLeadTimes[ant];\n                        const seq = antSequences[ant];\n                        for (let i = 0; i < seq.length - 1; i++) {\n                            pheromone[seq[i]][seq[i + 1]] += deposit;\n                        }\n                    }\n                }\n                return {\n                    optimizedSequence: bestSequence.map(i => processSteps[i]),\n                    originalLeadTime: processSteps.reduce((sum, s) =>\n                        sum + (s.cycleTime || 0) + (s.waitTime || 0) + (s.setupTime || 0), 0),\n                    optimizedLeadTime: bestLeadTime,\n                    improvement: Math.round((1 - bestLeadTime /\n                        processSteps.reduce((sum, s) =>\n                            sum + (s.cycleTime || 0) + (s.waitTime || 0) + (s.setupTime || 0), 0)) * 100),\n                    acoIterations: iterations,\n                    sequenceIndices: bestSequence\n                };\n            }\n        },\n        // 2.4 SMED (Single Minute Exchange of Die)\n        smed: {\n            /**\n             * Analyze setup activities and categorize\n             */\n            analyzeSetup: function(activities) {\n                const internal = []; // Machine must be stopped\n                const external = []; // Can be done while machine runs\n\n                activities.forEach(activity => {\n                    if (activity.requiresMachineStop) {\n                        internal.push(activity);\n                    } else {\n                        external.push(activity);\n                    }\n                });\n\n                const totalInternal = internal.reduce((sum, a) => sum + a.duration, 0);\n                const totalExternal = external.reduce((sum, a) => sum + a.duration, 0);\n\n                return {\n                    internalActivities: internal,\n                    externalActivities: external,\n                    internalTime: totalInternal,\n                    externalTime: totalExternal,\n                    totalSetupTime: totalInternal + totalExternal,\n                    downtimeReduction: totalExternal,\n                    recommendations: this._generateSMEDRecommendations(internal)\n                };\n            },\n            _generateSMEDRecommendations: function(internalActivities) {\n                const recs = [];\n\n                // Look for activities that could be converted\n                internalActivities.forEach(activity => {\n                    if (activity.duration > 5) { // > 5 minutes\n                        recs.push({\n                            activity: activity.name,\n                            suggestion: 'Consider pre-staging or parallel processing',\n                            potentialSaving: Math.round(activity.duration * 0.5)\n                        });\n                    }\n                });\n\n                return recs;\n            }\n        },\n        // 2.5 TPM (Total Productive Maintenance)\n        tpm: {\n            /**\n             * Calculate maintenance metrics\n             */\n            calculateMetrics: function(maintenanceData) {\n                const {\n                    totalDowntime,      // hours\n                    numFailures,\n                    operatingHours,\n                    maintenanceCost\n                } = maintenanceData;\n\n                // MTBF = Operating Hours / Number of Failures\n                const mtbf = numFailures > 0 ? operatingHours / numFailures : operatingHours;\n\n                // MTTR = Total Downtime / Number of Failures\n                const mttr = numFailures > 0 ? totalDowntime / numFailures : 0;\n\n                // Availability = MTBF / (MTBF + MTTR)\n                const availability = mtbf / (mtbf + mttr);\n\n                return {\n                    mtbf: Math.round(mtbf * 10) / 10,\n                    mttr: Math.round(mttr * 10) / 10,\n                    availability: Math.round(availability * 1000) / 10,\n                    failureRate: numFailures > 0 ? (numFailures / operatingHours) : 0,\n                    costPerFailure: numFailures > 0 ? maintenanceCost / numFailures : 0,\n                    recommendation: this._getTPMRecommendation(mtbf, mttr)\n                };\n            },\n            _getTPMRecommendation: function(mtbf, mttr) {\n                if (mtbf < 100) return 'Critical: Implement preventive maintenance program';\n                if (mtbf < 500) return 'Warning: Increase PM frequency';\n                if (mttr > 4) return 'Focus on reducing repair time - train technicians';\n                return 'Good performance - maintain current program';\n            }\n        },\n        // 2.6 5S Implementation\n        fiveS: {\n            categories: {\n                SORT: { name: 'Sort (Seiri)', description: 'Remove unnecessary items' },\n                SETINORDER: { name: 'Set in Order (Seiton)', description: 'Organize remaining items' },\n                SHINE: { name: 'Shine (Seiso)', description: 'Clean the workplace' },\n                STANDARDIZE: { name: 'Standardize (Seiketsu)', description: 'Create consistent procedures' },\n                SUSTAIN: { name: 'Sustain (Shitsuke)', description: 'Maintain and improve' }\n            },\n            /**\n             * 5S Audit scorecard\n             */\n            audit: function(scores) {\n                // scores = { sort: 1-5, setInOrder: 1-5, shine: 1-5, standardize: 1-5, sustain: 1-5 }\n                const total = scores.sort + scores.setInOrder + scores.shine +\n                              scores.standardize + scores.sustain;\n                const maxScore = 25;\n\n                return {\n                    scores: {\n                        sort: { score: scores.sort, max: 5 },\n                        setInOrder: { score: scores.setInOrder, max: 5 },\n                        shine: { score: scores.shine, max: 5 },\n                        standardize: { score: scores.standardize, max: 5 },\n                        sustain: { score: scores.sustain, max: 5 }\n                    },\n                    totalScore: total,\n                    maxScore,\n                    percentage: Math.round((total / maxScore) * 100),\n                    level: this._get5SLevel(total / maxScore),\n                    weakestArea: this._findWeakest(scores),\n                    nextSteps: this._getNextSteps(scores)\n                };\n            },\n            _get5SLevel: function(ratio) {\n                if (ratio >= 0.9) return 'Excellent - World Class';\n                if (ratio >= 0.8) return 'Good - Minor improvements needed';\n                if (ratio >= 0.6) return 'Average - Focus on weak areas';\n                return 'Needs Improvement - Comprehensive 5S program required';\n            },\n            _findWeakest: function(scores) {\n                const areas = Object.entries(scores);\n                areas.sort((a, b) => a[1] - b[1]);\n                return areas[0][0];\n            },\n            _getNextSteps: function(scores) {\n                const steps = [];\n                if (scores.sort < 3) steps.push('Conduct red tag event');\n                if (scores.setInOrder < 3) steps.push('Create visual management system');\n                if (scores.shine < 3) steps.push('Establish cleaning schedules');\n                if (scores.standardize < 3) steps.push('Document best practices');\n                if (scores.sustain < 3) steps.push('Implement audit schedule');\n                return steps;\n            }\n        },\n        // 2.7 Kanban System\n        kanban: {\n            /**\n             * Calculate kanban quantity\n             */\n            calculateKanbanSize: function(params) {\n                const {\n                    dailyDemand,      // units per day\n                    leadTime,         // days\n                    safetyFactor,     // typically 1.0-1.5\n                    containerSize     // units per container\n                } = params;\n\n                // Number of kanbans = (Daily Demand \u00d7 Lead Time \u00d7 Safety Factor) / Container Size\n                const numKanbans = Math.ceil(\n                    (dailyDemand * leadTime * safetyFactor) / containerSize\n                );\n\n                return {\n                    numberOfKanbans: numKanbans,\n                    totalInventory: numKanbans * containerSize,\n                    daysOfStock: (numKanbans * containerSize) / dailyDemand,\n                    recommendation: numKanbans > 10 ? 'Consider reducing lead time or container size' : 'Kanban size appropriate'\n                };\n            }\n        }\n    },\n    // SECTION 3: KAIZEN - Continuous Improvement\n    kaizen: {\n\n        // 3.1 PDCA with Reinforcement Learning\n        pdca: {\n            /**\n             * Create PDCA cycle\n             */\n            createCycle: function(params) {\n                return {\n                    cycleId: 'PDCA-' + Date.now(),\n                    createdDate: new Date().toISOString(),\n                    problem: params.problem,\n                    targetMetric: params.metric,\n                    baseline: params.baseline,\n                    target: params.target,\n                    phases: {\n                        plan: {\n                            status: 'active',\n                            hypothesis: params.hypothesis || '',\n                            actions: params.plannedActions || [],\n                            expectedOutcome: params.target\n                        },\n                        do: {\n                            status: 'pending',\n                            implementationDate: null,\n                            actualActions: []\n                        },\n                        check: {\n                            status: 'pending',\n                            measuredResult: null,\n                            varianceFromTarget: null\n                        },\n                        act: {\n                            status: 'pending',\n                            decision: null, // 'standardize', 'iterate', 'abandon'\n                            nextActions: []\n                        }\n                    },\n                    currentPhase: 'plan'\n                };\n            },\n            /**\n             * PRISM INNOVATION: PDCA with Reinforcement Learning\n             * Learns from past PDCA cycles to suggest better improvements\n             */\n            suggestImprovement: function(problemType, historicalCycles) {\n                // Build success rate for different action types\n                const actionSuccess = {};\n\n                historicalCycles.forEach(cycle => {\n                    if (cycle.phases.check.measuredResult !== null) {\n                        const success = cycle.phases.check.measuredResult >= cycle.target ? 1 : 0;\n\n                        cycle.phases.plan.actions.forEach(action => {\n                            const actionType = action.type || 'general';\n                            if (!actionSuccess[actionType]) {\n                                actionSuccess[actionType] = { successes: 0, total: 0 };\n                            }\n                            actionSuccess[actionType].successes += success;\n                            actionSuccess[actionType].total += 1;\n                        });\n                    }\n                });\n\n                // Calculate success rates and rank actions\n                const rankedActions = Object.entries(actionSuccess)\n                    .map(([type, data]) => ({\n                        actionType: type,\n                        successRate: data.total > 0 ? data.successes / data.total : 0.5,\n                        sampleSize: data.total,\n                        confidence: 1 - 1 / (1 + Math.sqrt(data.total))\n                    }))\n                    .sort((a, b) => b.successRate * b.confidence - a.successRate * a.confidence);\n\n                return {\n                    recommendedActions: rankedActions.slice(0, 3),\n                    explorationSuggestion: rankedActions.length < 5 ?\n                        'Consider trying new improvement approaches' : null,\n                    historicalCyclesAnalyzed: historicalCycles.length\n                };\n            }\n        },\n        // 3.2 Improvement Event Tracking\n        improvementTracker: {\n            improvements: [],\n\n            /**\n             * Log an improvement event\n             */\n            logImprovement: function(params) {\n                const improvement = {\n                    id: 'KZ-' + Date.now(),\n                    date: new Date().toISOString(),\n                    category: params.category, // 'quality', 'productivity', 'safety', 'cost', 'delivery'\n                    description: params.description,\n                    area: params.area,\n                    submittedBy: params.submittedBy,\n                    beforeState: params.beforeState,\n                    afterState: params.afterState,\n                    measuredImpact: params.impact,\n                    costSavings: params.costSavings || 0,\n                    timeSavings: params.timeSavings || 0,\n                    status: 'implemented'\n                };\n                this.improvements.push(improvement);\n                return improvement;\n            },\n            /**\n             * Get improvement statistics\n             */\n            getStatistics: function(timeRange = null) {\n                let filtered = this.improvements;\n                if (timeRange) {\n                    const cutoff = new Date(Date.now() - timeRange * 24 * 60 * 60 * 1000);\n                    filtered = filtered.filter(i => new Date(i.date) >= cutoff);\n                }\n                const byCategory = {};\n                let totalCostSavings = 0;\n                let totalTimeSavings = 0;\n\n                filtered.forEach(imp => {\n                    byCategory[imp.category] = (byCategory[imp.category] || 0) + 1;\n                    totalCostSavings += imp.costSavings;\n                    totalTimeSavings += imp.timeSavings;\n                });\n\n                return {\n                    totalImprovements: filtered.length,\n                    byCategory,\n                    totalCostSavings,\n                    totalTimeSavings,\n                    avgCostSavingsPer: filtered.length > 0 ? totalCostSavings / filtered.length : 0\n                };\n            }\n        },\n        // 3.3 Gemba Data Collection\n        gemba: {\n            observations: [],\n\n            /**\n             * Record a Gemba observation\n             */\n            recordObservation: function(params) {\n                const obs = {\n                    id: 'GEMBA-' + Date.now(),\n                    date: new Date().toISOString(),\n                    location: params.location,\n                    observer: params.observer,\n                    category: params.category, // 'waste', 'safety', 'quality', 'flow', 'environment'\n                    observation: params.observation,\n                    severity: params.severity || 'medium', // 'low', 'medium', 'high', 'critical'\n                    actionRequired: params.actionRequired || false,\n                    status: 'open'\n                };\n                this.observations.push(obs);\n                return obs;\n            },\n            /**\n             * Get open observations by priority\n             */\n            getOpenObservations: function() {\n                return this.observations\n                    .filter(o => o.status === 'open')\n                    .sort((a, b) => {\n                        const priority = { critical: 4, high: 3, medium: 2, low: 1 };\n                        return priority[b.severity] - priority[a.severity];\n                    });\n            }\n        },\n        // 3.4 A3 Problem Solving\n        a3: {\n            /**\n             * Create A3 problem solving document\n             */\n            createA3: function(params) {\n                return {\n                    id: 'A3-' + Date.now(),\n                    title: params.title,\n                    author: params.author,\n                    date: new Date().toISOString(),\n                    sections: {\n                        background: params.background || '',\n                        currentCondition: params.currentCondition || '',\n                        targetCondition: params.targetCondition || '',\n                        rootCauseAnalysis: params.rootCause || '',\n                        countermeasures: params.countermeasures || [],\n                        implementationPlan: params.plan || [],\n                        followUp: params.followUp || ''\n                    },\n                    status: 'draft'\n                };\n            },\n            /**\n             * 5 Why Analysis\n             */\n            fiveWhyAnalysis: function(problem) {\n                return {\n                    problem,\n                    whys: [\n                        { level: 1, why: '', answer: '' },\n                        { level: 2, why: '', answer: '' },\n                        { level: 3, why: '', answer: '' },\n                        { level: 4, why: '', answer: '' },\n                        { level: 5, why: '', answer: '' }\n                    ],\n                    rootCause: '',\n                    countermeasure: ''\n                };\n            }\n        }\n    },\n    // SECTION 4: AI INTEGRATION & TRAINING DATA GENERATION\n    aiIntegration: {\n        /**\n         * Generate training data for AI systems\n         */\n        generateTrainingData: function(numSamples = 100) {\n            const samples = [];\n\n            for (let i = 0; i < numSamples; i++) {\n                // Generate random process data\n                const measurements = Array(30).fill(0).map(() =>\n                    10 + Math.random() * 2 - 1 + (Math.random() > 0.95 ? 5 : 0)); // Some outliers\n\n                const USL = 12;\n                const LSL = 8;\n                const mean = measurements.reduce((a, b) => a + b, 0) / measurements.length;\n                const sigma = Math.sqrt(measurements.reduce((sum, x) =>\n                    sum + Math.pow(x - mean, 2), 0) / measurements.length);\n\n                const cpkResult = PRISM_LEAN_SIX_SIGMA_KAIZEN.sixSigma.processCapability\n                    .calculateCpk(USL, LSL, mean, sigma);\n\n                samples.push({\n                    input: {\n                        mean,\n                        sigma,\n                        sampleSize: measurements.length,\n                        range: Math.max(...measurements) - Math.min(...measurements)\n                    },\n                    output: {\n                        cpk: cpkResult.value,\n                        inControl: cpkResult.value >= 1.0,\n                        sigmaLevel: cpkResult.sigmaLevel\n                    }\n                });\n            }\n            return {\n                type: 'process_capability',\n                samples,\n                generatedAt: new Date().toISOString()\n            };\n        },\n        /**\n         * Get all available AI routes for this module\n         */\n        getRoutes: function() {\n            return {\n                'sixsigma.cpk': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.sixSigma.processCapability.calculateCpk',\n                'sixsigma.cpk.uncertainty': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.sixSigma.processCapability.calculateCpkWithUncertainty',\n                'sixsigma.chart.xbar': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.sixSigma.controlCharts.xBarRChart',\n                'sixsigma.chart.imr': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.sixSigma.controlCharts.iMRChart',\n                'sixsigma.chart.bayesian': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.sixSigma.controlCharts.bayesianControlChart',\n                'sixsigma.dmaic.sigma': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.sixSigma.dmaic.calculateSigmaLevel',\n                'sixsigma.fmea.montecarlo': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.sixSigma.fmea.monteCarloFMEA',\n                'lean.wastes.analyze': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.lean.sevenWastes.analyzeForWaste',\n                'lean.oee.calculate': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.lean.oee.calculate',\n                'lean.oee.predict': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.lean.oee.predictWithKalman',\n                'lean.vsm.create': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.lean.valueStreamMapping.createVSM',\n                'lean.vsm.optimize': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.lean.valueStreamMapping.optimizeWithACO',\n                'lean.smed.analyze': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.lean.smed.analyzeSetup',\n                'lean.tpm.metrics': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.lean.tpm.calculateMetrics',\n                'lean.5s.audit': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.lean.fiveS.audit',\n                'lean.kanban.size': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.lean.kanban.calculateKanbanSize',\n                'kaizen.pdca.create': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.kaizen.pdca.createCycle',\n                'kaizen.pdca.suggest': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.kaizen.pdca.suggestImprovement',\n                'kaizen.improvement.log': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.kaizen.improvementTracker.logImprovement',\n                'kaizen.improvement.stats': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.kaizen.improvementTracker.getStatistics',\n                'kaizen.gemba.record': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.kaizen.gemba.recordObservation',\n                'kaizen.a3.create': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.kaizen.a3.createA3',\n                'kaizen.a3.5why': 'PRISM_LEAN_SIX_SIGMA_KAIZEN.kaizen.a3.fiveWhyAnalysis'\n            };\n        }\n    },\n    // SECTION 5: SELF-TESTS\n    selfTests: {\n        runAll: function() {\n            console.log('\\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550');\n            console.log('PRISM_LEAN_SIX_SIGMA_KAIZEN - Self Tests');\n            console.log('\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\\n');\n\n            let passed = 0;\n            let failed = 0;\n\n            // Test 1: Process Capability\n            try {\n                const cpk = PRISM_LEAN_SIX_SIGMA_KAIZEN.sixSigma.processCapability\n                    .calculateCpk(12, 8, 10, 0.5);\n                if (cpk.value > 1.3 && cpk.interpretation.includes('Good')) {\n                    console.log('\u2705 Test 1: Process Capability (Cpk) - PASSED');\n                    passed++;\n                } else {\n                    console.log('\u274c Test 1: Process Capability - FAILED');\n                    failed++;\n                }\n            } catch (e) {\n                console.log('\u274c Test 1: Process Capability - ERROR:', e.message);\n                failed++;\n            }\n            // Test 2: X-bar R Chart\n            try {\n                const subgroups = [[10.1, 10.2, 10.0], [9.9, 10.1, 10.0], [10.0, 10.1, 9.9]];\n                const chart = PRISM_LEAN_SIX_SIGMA_KAIZEN.sixSigma.controlCharts.xBarRChart(subgroups);\n                if (chart.chartType === 'X-bar and R' && chart.xBar.centerline > 0) {\n                    console.log('\u2705 Test 2: X-bar R Chart - PASSED');\n                    passed++;\n                } else {\n                    console.log('\u274c Test 2: X-bar R Chart - FAILED');\n                    failed++;\n                }\n            } catch (e) {\n                console.log('\u274c Test 2: X-bar R Chart - ERROR:', e.message);\n                failed++;\n            }\n            // Test 3: OEE Calculation\n            try {\n                const oee = PRISM_LEAN_SIX_SIGMA_KAIZEN.lean.oee.calculate({\n                    plannedProductionTime: 480,\n                    downtime: 48,\n                    idealCycleTime: 2,\n                    totalParts: 200,\n                    goodParts: 195\n                });\n                if (oee.oee > 70 && oee.oee < 90) {\n                    console.log('\u2705 Test 3: OEE Calculation - PASSED');\n                    passed++;\n                } else {\n                    console.log('\u274c Test 3: OEE Calculation - FAILED');\n                    failed++;\n                }\n            } catch (e) {\n                console.log('\u274c Test 3: OEE Calculation - ERROR:', e.message);\n                failed++;\n            }\n            // Test 4: Seven Wastes Analysis\n            try {\n                const wastes = PRISM_LEAN_SIX_SIGMA_KAIZEN.lean.sevenWastes.analyzeForWaste({\n                    avgMaterialTravelDistance: 75,\n                    wipDays: 8,\n                    machineUtilization: 60,\n                    scrapRate: 3.5,\n                    finishedGoodsDays: 15,\n                    avgSetupTime: 90,\n                    avgToleranceRatio: 0.3\n                });\n                if (wastes.wastesIdentified >= 5) {\n                    console.log('\u2705 Test 4: Seven Wastes Analysis - PASSED');\n                    passed++;\n                } else {\n                    console.log('\u274c Test 4: Seven Wastes Analysis - FAILED');\n                    failed++;\n                }\n            } catch (e) {\n                console.log('\u274c Test 4: Seven Wastes Analysis - ERROR:', e.message);\n                failed++;\n            }\n            // Test 5: Monte Carlo FMEA\n            try {\n                const fmea = PRISM_LEAN_SIX_SIGMA_KAIZEN.sixSigma.fmea.monteCarloFMEA([\n                    { name: 'Tool Breakage', severity: 8, occurrence: 4, detection: 3 },\n                    { name: 'Dimensional Error', severity: 6, occurrence: 5, detection: 2 }\n                ], 1000);\n                if (fmea.failureModes.length === 2 && fmea.simulations === 1000) {\n                    console.log('\u2705 Test 5: Monte Carlo FMEA - PASSED');\n                    passed++;\n                } else {\n                    console.log('\u274c Test 5: Monte Carlo FMEA - FAILED');\n                    failed++;\n                }\n            } catch (e) {\n                console.log('\u274c Test 5: Monte Carlo FMEA - ERROR:', e.message);\n                failed++;\n            }\n            // Test 6: VSM with ACO Optimization\n            try {\n                const vsm = PRISM_LEAN_SIX_SIGMA_KAIZEN.lean.valueStreamMapping.optimizeWithACO([\n                    { name: 'Cut', cycleTime: 10, waitTime: 5, setupTime: 15 },\n                    { name: 'Mill', cycleTime: 20, waitTime: 10, setupTime: 20 },\n                    { name: 'Drill', cycleTime: 5, waitTime: 3, setupTime: 8 },\n                    { name: 'Inspect', cycleTime: 5, waitTime: 2, setupTime: 0 }\n                ]);\n                if (vsm.optimizedSequence && vsm.improvement >= 0) {\n                    console.log('\u2705 Test 6: VSM ACO Optimization - PASSED');\n                    passed++;\n                } else {\n                    console.log('\u274c Test 6: VSM ACO Optimization - FAILED');\n                    failed++;\n                }\n            } catch (e) {\n                console.log('\u274c Test 6: VSM ACO Optimization - ERROR:', e.message);\n                failed++;\n            }\n            // Test 7: 5S Audit\n            try {\n                const audit = PRISM_LEAN_SIX_SIGMA_KAIZEN.lean.fiveS.audit({\n                    sort: 4, setInOrder: 3, shine: 4, standardize: 3, sustain: 2\n                });\n                if (audit.totalScore === 16 && audit.percentage === 64) {\n                    console.log('\u2705 Test 7: 5S Audit - PASSED');\n                    passed++;\n                } else {\n                    console.log('\u274c Test 7: 5S Audit - FAILED');\n                    failed++;\n                }\n            } catch (e) {\n                console.log('\u274c Test 7: 5S Audit - ERROR:', e.message);\n                failed++;\n            }\n            // Test 8: PDCA Cycle\n            try {\n                const pdca = PRISM_LEAN_SIX_SIGMA_KAIZEN.kaizen.pdca.createCycle({\n                    problem: 'High scrap rate',\n                    metric: 'scrap_percentage',\n                    baseline: 5,\n                    target: 2\n                });\n                if (pdca.cycleId.startsWith('PDCA-') && pdca.currentPhase === 'plan') {\n                    console.log('\u2705 Test 8: PDCA Cycle - PASSED');\n                    passed++;\n                } else {\n                    console.log('\u274c Test 8: PDCA Cycle - FAILED');\n                    failed++;\n                }\n            } catch (e) {\n                console.log('\u274c Test 8: PDCA Cycle - ERROR:', e.message);\n                failed++;\n            }\n            // Test 9: Sigma Level Calculation\n            try {\n                const sigma = PRISM_LEAN_SIX_SIGMA_KAIZEN.sixSigma.dmaic.calculateSigmaLevel(\n                    34, 10, 1000 // 34 defects, 10 opportunities, 1000 units\n                );\n                if (sigma.dpmo === 3400 && sigma.sigmaLevel > 4) {\n                    console.log('\u2705 Test 9: Sigma Level Calculation - PASSED');\n                    passed++;\n                } else {\n                    console.log('\u274c Test 9: Sigma Level Calculation - FAILED');\n                    failed++;\n                }\n            } catch (e) {\n                console.log('\u274c Test 9: Sigma Level Calculation - ERROR:', e.message);\n                failed++;\n            }\n            // Test 10: Training Data Generation\n            try {\n                const training = PRISM_LEAN_SIX_SIGMA_KAIZEN.aiIntegration.generateTrainingData(50);\n                if (training.samples.length === 50 && training.type === 'process_capability') {\n                    console.log('\u2705 Test 10: Training Data Generation - PASSED');\n                    passed++;\n                } else {\n                    console.log('\u274c Test 10: Training Data Generation - FAILED');\n                    failed++;\n                }\n            } catch (e) {\n                console.log('\u274c Test 10: Training Data Generation - ERROR:', e.message);\n                failed++;\n            }\n            console.log(`\\n=== RESULTS: ${passed}/${passed + failed} tests passed ===\\n`);\n            return { passed, failed, total: passed + failed };\n        }\n    }\n}",
      "methods": [],
      "lines": 1463
    },
    {
      "name": "PRISM_PHASE6_DEEPLEARNING",
      "category": "engines/ai_ml",
      "refs": 39,
      "status": "NOT_FOUND",
      "code": "",
      "methods": [],
      "lines": 0
    },
    {
      "name": "PRISM_TRUE_AI_SYSTEM",
      "category": "engines/ai_ml",
      "refs": 21,
      "status": "FOUND",
      "code": "const PRISM_TRUE_AI_SYSTEM = {\n\n    version: '1.1.0',\n    name: 'PRISM True AI System',\n    initialized: false,\n\n    // Component references\n    tensor: PRISM_TENSOR,\n    layers: PRISM_NN_LAYERS,\n    network: PRISM_NEURAL_NETWORK,\n    pretrained: PRISM_PRETRAINED_MODELS,\n    claude: PRISM_CLAUDE_API,\n    orchestrator: PRISM_AI_BACKGROUND_ORCHESTRATOR,\n    chat: PRISM_AI_CHAT_INTERFACE,\n    learning: PRISM_LEARNING_ENGINE,\n\n    /**\n     * Initialize the complete AI system\n     */\n    initialize: async function(options = {}) {\n        console.log('[PRISM TRUE AI] Initializing v1.1...');\n\n        // Configure Claude API\n        if (options.claudeApiKey) {\n            PRISM_CLAUDE_API.setApiKey(options.claudeApiKey);\n        }\n        // Initialize pretrained models\n        PRISM_PRETRAINED_MODELS.initializeAll();\n\n        // Start background orchestrator\n        PRISM_AI_BACKGROUND_ORCHESTRATOR.start();\n\n        // Set help level\n        if (options.helpLevel) {\n            PRISM_AI_BACKGROUND_ORCHESTRATOR.setHelpLevel(options.helpLevel);\n        }\n        this.initialized = true;\n        (typeof PRISM_CONSTANTS !== 'undefined' && PRISM_CONSTANTS.DEBUG) && console.log('[PRISM TRUE AI] Initialization complete');\n\n        return {\n            success: true,\n            claudeAvailable: PRISM_CLAUDE_API.isAvailable(),\n            models: ['toolWearPredictor', 'surfaceFinishPredictor', 'cycleTimePredictor', 'chatterPredictor']\n        };\n    },\n    /**\n     * Ask AI a question (unified interface)\n     */\n    ask: async function(question, context = {}) {\n        PRISM_AI_CHAT_INTERFACE.setContext(context);\n        return await PRISM_AI_CHAT_INTERFACE.sendMessage(question);\n    },\n    /**\n     * Get prediction from pretrained neural network\n     */\n    predict: function(model, input) {\n        const wearStates = ['minimal', 'moderate', 'severe', 'critical'];\n\n        switch (model) {\n            case 'toolWear':\n                if (!PRISM_PRETRAINED_MODELS.toolWearPredictor) {\n                    PRISM_PRETRAINED_MODELS.createToolWearModel();\n                }\n                const wearOut = PRISM_PRETRAINED_MODELS.toolWearPredictor.predict(input);\n                const wearMaxIdx = wearOut.indexOf(Math.max(...wearOut));\n                return {\n                    state: wearStates[wearMaxIdx],\n                    confidence: wearOut[wearMaxIdx],\n                    probabilities: Object.fromEntries(wearStates.map((s, i) => [s, wearOut[i]]))\n                };\n            case 'surfaceFinish':\n                if (!PRISM_PRETRAINED_MODELS.surfaceFinishPredictor) {\n                    PRISM_PRETRAINED_MODELS.createSurfaceFinishModel();\n                }\n                const raOut = PRISM_PRETRAINED_MODELS.surfaceFinishPredictor.predict(input);\n                return { Ra: raOut[0] * 5, unit: '\u00b5m' };\n\n            case 'cycleTime':\n                if (!PRISM_PRETRAINED_MODELS.cycleTimePredictor) {\n                    PRISM_PRETRAINED_MODELS.createCycleTimeModel();\n                }\n                const timeOut = PRISM_PRETRAINED_MODELS.cycleTimePredictor.predict(input);\n                return { time: timeOut[0] * 20, unit: 'minutes' };\n\n            case 'chatter':\n                if (!PRISM_PRETRAINED_MODELS.chatterPredictor) {\n                    PRISM_PRETRAINED_MODELS.createChatterModel();\n                }\n                const chatterOut = PRISM_PRETRAINED_MODELS.chatterPredictor.predict(input);\n                return {\n                    stable: chatterOut[0] > chatterOut[1],\n                    stability: chatterOut[0],\n                    instability: chatterOut[1],\n                    recommendation: chatterOut[0] > chatterOut[1] ?\n                        'Parameters are in stable cutting zone' :\n                        'Risk of chatter - consider reducing DOC or adjusting RPM'\n                };\n            default:\n                return { error: `Unknown model: ${model}` };\n        }\n    },\n    /**\n     * Record user action for learning\n     */\n    recordAction: function(action) {\n        PRISM_AI_BACKGROUND_ORCHESTRATOR.recordAction(action);\n    },\n    /**\n     * Record machining outcome for learning\n     */\n    recordOutcome: function(params, outcome) {\n        PRISM_LEARNING_ENGINE.recordOutcome(params, outcome);\n    },\n    /**\n     * Get pending AI suggestions\n     */\n    getSuggestions: function() {\n        return PRISM_AI_BACKGROUND_ORCHESTRATOR.getPendingSuggestions();\n    },\n    /**\n     * Get system status\n     */\n    getStatus: function() {\n        return {\n            version: this.version,\n            initialized: this.initialized,\n            claudeAvailable: PRISM_CLAUDE_API.isAvailable(),\n            orchestratorRunning: PRISM_AI_BACKGROUND_ORCHESTRATOR.isRunning,\n            learningStats: PRISM_LEARNING_ENGINE.getStats(),\n            pendingSuggestions: PRISM_AI_BACKGROUND_ORCHESTRATOR.getPendingSuggestions().length\n        };\n    },\n    /**\n     * Configure Claude API key\n     */\n    setClaudeApiKey: function(key) {\n        PRISM_CLAUDE_API.setApiKey(key);\n    },\n    /**\n     * Run comprehensive self-tests\n     */\n    runTests: function() {\n        console.log('\\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550');\n        console.log('PRISM TRUE AI SYSTEM v1.1 - SELF-TESTS');\n        console.log('\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550');\n\n        let passed = 0, failed = 0;\n\n        // Test 1: Tensor operations\n        try {\n            const a = PRISM_TENSOR.random([3, 3], 0.5);\n            const b = PRISM_TENSOR.random([3, 3], 0.5);\n            const c = PRISM_TENSOR.matmul(a, b);\n            if (c.length === 3 && c[0].length === 3 && !isNaN(c[0][0])) {\n                console.log('  \u2705 Tensor Operations: PASS');\n                passed++;\n            } else throw new Error();\n        } catch (e) {\n            console.log('  \u274c Tensor Operations: FAIL');\n            failed++;\n        }\n        // Test 2: Dense layer\n        try {\n            const dense = new PRISM_NN_LAYERS.Dense(4, 2, 'relu');\n            const out = dense.forward([1, 2, 3, 4]);\n            if (out.length === 2 && !isNaN(out[0])) {\n                console.log('  \u2705 Dense Layer Forward: PASS');\n                passed++;\n            } else throw new Error();\n        } catch (e) {\n            console.log('  \u274c Dense Layer Forward: FAIL');\n            failed++;\n        }\n        // Test 3: Neural network training\n        try {\n            const model = new PRISM_NEURAL_NETWORK.Sequential('XOR-test');\n            model.add(new PRISM_NN_LAYERS.Dense(2, 8, 'relu'));\n            model.add(new PRISM_NN_LAYERS.Dense(8, 2, 'softmax'));\n            model.compile({ loss: 'crossentropy', learningRate: 0.1 });\n\n            const X = [[0, 0], [0, 1], [1, 0], [1, 1]];\n            const y = [[1, 0], [0, 1], [0, 1], [1, 0]];\n            model.fit(X, y, { epochs: 50, verbose: false });\n\n            const pred = model.predict([1, 0]);\n            if (pred.length === 2 && !isNaN(pred[0]) && pred[1] > pred[0]) {\n                console.log('  \u2705 Neural Network Training: PASS');\n                passed++;\n            } else throw new Error();\n        } catch (e) {\n            console.log('  \u274c Neural Network Training: FAIL');\n            failed++;\n        }\n        // Test 4: Tool wear predictor\n        try {\n            const result = this.predict('toolWear', [0.5, 0.3, 0.4, 0.6, 0.2, 0.4]);\n            if (result.state && result.confidence && !isNaN(result.confidence)) {\n                console.log('  \u2705 Tool Wear Predictor: PASS');\n                passed++;\n            } else throw new Error();\n        } catch (e) {\n            console.log('  \u274c Tool Wear Predictor: FAIL');\n            failed++;\n        }\n        // Test 5: Surface finish predictor\n        try {\n            const result = this.predict('surfaceFinish', [0.2, 0.5, 0.6, 0.4, 0.8]);\n            if (result.Ra && !isNaN(result.Ra)) {\n                console.log('  \u2705 Surface Finish Predictor: PASS');\n                passed++;\n            } else throw new Error();\n        } catch (e) {\n            console.log('  \u274c Surface Finish Predictor: FAIL');\n            failed++;\n        }\n        // Test 6: Chatter predictor\n        try {\n            const result = this.predict('chatter', [0.5, 0.3, 0.4, 0.5]);\n            if (typeof result.stable === 'boolean' && result.recommendation) {\n                console.log('  \u2705 Chatter Predictor: PASS');\n                passed++;\n            } else throw new Error();\n        } catch (e) {\n            console.log('  \u274c Chatter Predictor: FAIL');\n            failed++;\n        }\n        // Test 7: Orchestrator\n        try {\n            PRISM_AI_BACKGROUND_ORCHESTRATOR.recordAction({ type: 'test', data: {} });\n            if (PRISM_AI_BACKGROUND_ORCHESTRATOR.userActions.length > 0) {\n                console.log('  \u2705 AI Orchestrator: PASS');\n                passed++;\n            } else throw new Error();\n        } catch (e) {\n            console.log('  \u274c AI Orchestrator: FAIL');\n            failed++;\n        }\n        // Test 8: Chat interface\n        try {\n            const convId = PRISM_AI_CHAT_INTERFACE.createConversation();\n            if (convId && PRISM_AI_CHAT_INTERFACE.conversations.has(convId)) {\n                console.log('  \u2705 Chat Interface: PASS');\n                passed++;\n            } else throw new Error();\n        } catch (e) {\n            console.log('  \u274c Chat Interface: FAIL');\n            failed++;\n        }\n        // Test 9: Learning engine\n        try {\n            PRISM_LEARNING_ENGINE.recordOutcome({ speed: 200 }, { quality: 'good' });\n            if (PRISM_LEARNING_ENGINE.data.outcomes.length > 0) {\n                console.log('  \u2705 Learning Engine: PASS');\n                passed++;\n            } else throw new Error();\n        } catch (e) {\n            console.log('  \u274c Learning Engine: FAIL');\n            failed++;\n        }\n        // Test 10: Claude local fallback\n        try {\n            const response = PRISM_CLAUDE_API._generateLocalResponse('What speed for aluminum?', {\n                material: { name: '6061 Aluminum' },\n                tool: { diameter: 10, teeth: 4 }\n            });\n            if (response && response.includes('RPM')) {\n                console.log('  \u2705 Claude Local Fallback: PASS');\n                passed++;\n            } else throw new Error();\n        } catch (e) {\n            console.log('  \u274c Claude Local Fallback: FAIL');\n            failed++;\n        }\n        console.log('\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550');\n        console.log(`RESULTS: ${passed} passed, ${failed} failed`);\n        console.log('\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\\n');\n\n        return { passed, failed, total: passed + failed };\n    }\n}",
      "methods": [],
      "lines": 280
    },
    {
      "name": "PRISM_BREP_CAD_GENERATOR_V2",
      "category": "engines/cad_cam",
      "refs": 86,
      "status": "FOUND",
      "code": "const PRISM_BREP_CAD_GENERATOR_V2 = {\n  version: '3.0.0',\n\n  // CORE B-REP DATA STRUCTURES\n\n  topology: {\n    _entityId: 0,\n    _entities: new Map(),\n    _assembly: null,\n\n    // Create unique entity ID\n    nextId() {\n      return ++this._entityId;\n    },\n    // Reset for new model\n    reset() {\n      this._entityId = 0;\n      this._entities.clear();\n      this._assembly = null;\n    },\n    // Store entity\n    store(entity) {\n      this._entities.set(entity.id, entity);\n      return entity;\n    },\n    // Get entity by ID\n    get(id) {\n      return this._entities.get(id);\n    },\n    // Export all entities\n    exportAll() {\n      return Array.from(this._entities.values());\n    }\n  },\n  // GEOMETRY CREATION\n\n  geometry: {\n\n    // Create 3D point\n    createPoint(x, y, z) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'CARTESIAN_POINT',\n        coordinates: [x, y, z],\n        x, y, z\n      });\n    },\n    // Create direction vector (normalized)\n    createDirection(x, y, z) {\n      const len = Math.sqrt(x*x + y*y + z*z);\n      if (len < 1e-10) {\n        console.warn('[BREP] Zero-length direction, using default');\n        return this.createDirection(0, 0, 1);\n      }\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'DIRECTION',\n        ratios: [x/len, y/len, z/len],\n        x: x/len, y: y/len, z: z/len\n      });\n    },\n    // Create vector\n    createVector(direction, magnitude) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'VECTOR',\n        direction: direction.id,\n        magnitude\n      });\n    },\n    // Create axis placement (position + orientation)\n    createAxis2Placement3D(origin, axis, refDirection) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'AXIS2_PLACEMENT_3D',\n        location: origin.id,\n        axis: axis.id,\n        refDirection: refDirection.id,\n        origin, axisDir: axis, refDir: refDirection\n      });\n    },\n    // Create line\n    createLine(point, direction) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'LINE',\n        pnt: point.id,\n        dir: direction.id,\n        point, direction\n      });\n    },\n    // Create circle\n    createCircle(placement, radius) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'CIRCLE',\n        position: placement.id,\n        radius,\n        placement\n      });\n    },\n    // Create ellipse\n    createEllipse(placement, semiAxis1, semiAxis2) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'ELLIPSE',\n        position: placement.id,\n        semiAxis1,\n        semiAxis2,\n        placement\n      });\n    },\n    // Create B-spline curve\n    createBSplineCurve(degree, controlPoints, knots, multiplicities, weights = null) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      const isRational = weights !== null && weights.length > 0;\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: isRational ? 'RATIONAL_B_SPLINE_CURVE' : 'B_SPLINE_CURVE_WITH_KNOTS',\n        degree,\n        controlPointList: controlPoints.map(p => p.id),\n        controlPoints,\n        knotMultiplicities: multiplicities,\n        knots,\n        weights: weights || controlPoints.map(() => 1),\n        curveForm: 'UNSPECIFIED',\n        closedCurve: false,\n        selfIntersect: false\n      });\n    },\n    // Create plane surface\n    createPlane(placement) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'PLANE',\n        position: placement.id,\n        placement\n      });\n    },\n    // Create cylindrical surface\n    createCylindricalSurface(placement, radius) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'CYLINDRICAL_SURFACE',\n        position: placement.id,\n        radius,\n        placement\n      });\n    },\n    // Create conical surface\n    createConicalSurface(placement, radius, semiAngle) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'CONICAL_SURFACE',\n        position: placement.id,\n        radius,\n        semiAngle,\n        placement\n      });\n    },\n    // Create spherical surface\n    createSphericalSurface(placement, radius) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'SPHERICAL_SURFACE',\n        position: placement.id,\n        radius,\n        placement\n      });\n    },\n    // Create toroidal surface\n    createToroidalSurface(placement, majorRadius, minorRadius) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'TOROIDAL_SURFACE',\n        position: placement.id,\n        majorRadius,\n        minorRadius,\n        placement\n      });\n    },\n    // Create B-spline surface\n    createBSplineSurface(uDegree, vDegree, controlPointGrid, uKnots, vKnots,\n                          uMults, vMults, weights = null) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      const isRational = weights !== null;\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: isRational ? 'RATIONAL_B_SPLINE_SURFACE' : 'B_SPLINE_SURFACE_WITH_KNOTS',\n        uDegree,\n        vDegree,\n        controlPointsListList: controlPointGrid.map(row => row.map(p => p.id)),\n        controlPointGrid,\n        uKnots,\n        vKnots,\n        uMultiplicities: uMults,\n        vMultiplicities: vMults,\n        weights: weights || controlPointGrid.map(row => row.map(() => 1)),\n        surfaceForm: 'UNSPECIFIED',\n        uClosed: false,\n        vClosed: false,\n        selfIntersect: false\n      });\n    }\n  },\n  // TOPOLOGY CREATION\n\n  topologyOps: {\n\n    // Create vertex at point\n    createVertex(point) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'VERTEX_POINT',\n        vertexGeometry: point.id,\n        point\n      });\n    },\n    // Create edge curve\n    createEdgeCurve(vertex1, vertex2, curve, sameSense = true) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'EDGE_CURVE',\n        edgeStart: vertex1.id,\n        edgeEnd: vertex2.id,\n        edgeGeometry: curve.id,\n        sameSense,\n        vertex1, vertex2, curve\n      });\n    },\n    // Create oriented edge (edge with direction)\n    createOrientedEdge(edge, orientation = true) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'ORIENTED_EDGE',\n        edgeElement: edge.id,\n        orientation,\n        edge\n      });\n    },\n    // Create edge loop (closed loop of edges)\n    createEdgeLoop(orientedEdges) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'EDGE_LOOP',\n        edgeList: orientedEdges.map(e => e.id),\n        edges: orientedEdges\n      });\n    },\n    // Create face bound\n    createFaceBound(loop, orientation = true) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'FACE_BOUND',\n        bound: loop.id,\n        orientation,\n        loop\n      });\n    },\n    // Create face outer bound (the main boundary of a face)\n    createFaceOuterBound(loop, orientation = true) {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'FACE_OUTER_BOUND',\n        bound: loop.id,\n        orientation,\n        loop\n      });\n    },\n    // Create advanced face\n    createAdvancedFace(bounds, surface, sameSense = true, name = '') {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'ADVANCED_FACE',\n        name,\n        bounds: bounds.map(b => b.id),\n        faceGeometry: surface.id,\n        sameSense,\n        boundList: bounds,\n        surface\n      });\n    },\n    // Create closed shell\n    createClosedShell(faces, name = '') {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'CLOSED_SHELL',\n        name,\n        cfsFaces: faces.map(f => f.id),\n        faces\n      });\n    },\n    // Create open shell\n    createOpenShell(faces, name = '') {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'OPEN_SHELL',\n        name,\n        cfsFaces: faces.map(f => f.id),\n        faces\n      });\n    },\n    // Create manifold solid B-rep\n    createManifoldSolidBrep(shell, name = '') {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'MANIFOLD_SOLID_BREP',\n        name,\n        outer: shell.id,\n        shell\n      });\n    },\n    // Create brep with voids (solid with internal cavities)\n    createBrepWithVoids(outerShell, voidShells, name = '') {\n      const id = PRISM_BREP_CAD_GENERATOR_V2.topology.nextId();\n      return PRISM_BREP_CAD_GENERATOR_V2.topology.store({\n        id,\n        type: 'BREP_WITH_VOIDS',\n        name,\n        outer: outerShell.id,\n        voids: voidShells.map(s => s.id),\n        outerShell,\n        voidShells\n      });\n    }\n  },\n  // PRIMITIVE SOLID CREATION (with full B-Rep topology)\n\n  primitives: {\n\n    /**\n     * Create a box solid with full B-Rep topology\n     * Generates all vertices, edges, faces, shell, and solid\n     */\n    createBox(x, y, z, dx, dy, dz) {\n      const geo = PRISM_BREP_CAD_GENERATOR_V2.geometry;\n      const topo = PRISM_BREP_CAD_GENERATOR_V2.topologyOps;\n\n      // Create 8 corner points\n      const points = [\n        geo.createPoint(x, y, z),\n        geo.createPoint(x + dx, y, z),\n        geo.createPoint(x + dx, y + dy, z),\n        geo.createPoint(x, y + dy, z),\n        geo.createPoint(x, y, z + dz),\n        geo.createPoint(x + dx, y, z + dz),\n        geo.createPoint(x + dx, y + dy, z + dz),\n        geo.createPoint(x, y + dy, z + dz)\n      ];\n\n      // Create 8 vertices\n      const vertices = points.map(p => topo.createVertex(p));\n\n      // Create direction vectors\n      const dirX = geo.createDirection(1, 0, 0);\n      const dirY = geo.createDirection(0, 1, 0);\n      const dirZ = geo.createDirection(0, 0, 1);\n      const dirNX = geo.createDirection(-1, 0, 0);\n      const dirNY = geo.createDirection(0, -1, 0);\n      const dirNZ = geo.createDirection(0, 0, -1);\n\n      // Create 12 edge curves (lines)\n      const edgeCurves = [\n        // Bottom face edges\n        geo.createLine(points[0], dirX),   // 0: v0-v1\n        geo.createLine(points[1], dirY),   // 1: v1-v2\n        geo.createLine(points[2], dirNX),  // 2: v2-v3\n        geo.createLine(points[3], dirNY),  // 3: v3-v0\n        // Top face edges\n        geo.createLine(points[4], dirX),   // 4: v4-v5\n        geo.createLine(points[5], dirY),   // 5: v5-v6\n        geo.createLine(points[6], dirNX),  // 6: v6-v7\n        geo.createLine(points[7], dirNY),  // 7: v7-v4\n        // Vertical edges\n        geo.createLine(points[0], dirZ),   // 8: v0-v4\n        geo.createLine(points[1], dirZ),   // 9: v1-v5\n        geo.createLine(points[2], dirZ),   // 10: v2-v6\n        geo.createLine(points[3], dirZ)    // 11: v3-v7\n      ];\n\n      // Create 12 edges\n      const edges = [\n        topo.createEdgeCurve(vertices[0], vertices[1], edgeCurves[0]),\n        topo.createEdgeCurve(vertices[1], vertices[2], edgeCurves[1]),\n        topo.createEdgeCurve(vertices[2], vertices[3], edgeCurves[2]),\n        topo.createEdgeCurve(vertices[3], vertices[0], edgeCurves[3]),\n        topo.createEdgeCurve(vertices[4], vertices[5], edgeCurves[4]),\n        topo.createEdgeCurve(vertices[5], vertices[6], edgeCurves[5]),\n        topo.createEdgeCurve(vertices[6], vertices[7], edgeCurves[6]),\n        topo.createEdgeCurve(vertices[7], vertices[4], edgeCurves[7]),\n        topo.createEdgeCurve(vertices[0], vertices[4], edgeCurves[8]),\n        topo.createEdgeCurve(vertices[1], vertices[5], edgeCurves[9]),\n        topo.createEdgeCurve(vertices[2], vertices[6], edgeCurves[10]),\n        topo.createEdgeCurve(vertices[3], vertices[7], edgeCurves[11])\n      ];\n\n      // Create faces with proper topology\n      const faces = [];\n\n      // Bottom face (Z-) - normal pointing down\n      const bottomPlacement = geo.createAxis2Placement3D(points[0], dirNZ, dirX);\n      const bottomPlane = geo.createPlane(bottomPlacement);\n      const bottomLoop = topo.createEdgeLoop([\n        topo.createOrientedEdge(edges[0], false),\n        topo.createOrientedEdge(edges[3], false),\n        topo.createOrientedEdge(edges[2], false),\n        topo.createOrientedEdge(edges[1], false)\n      ]);\n      faces.push(topo.createAdvancedFace(\n        [topo.createFaceOuterBound(bottomLoop)],\n        bottomPlane, true, 'Bottom'\n      ));\n\n      // Top face (Z+) - normal pointing up\n      const topPlacement = geo.createAxis2Placement3D(points[4], dirZ, dirX);\n      const topPlane = geo.createPlane(topPlacement);\n      const topLoop = topo.createEdgeLoop([\n        topo.createOrientedEdge(edges[4], true),\n        topo.createOrientedEdge(edges[5], true),\n        topo.createOrientedEdge(edges[6], true),\n        topo.createOrientedEdge(edges[7], true)\n      ]);\n      faces.push(topo.createAdvancedFace(\n        [topo.createFaceOuterBound(topLoop)],\n        topPlane, true, 'Top'\n      ));\n\n      // Front face (Y-)\n      const frontPlacement = geo.createAxis2Placement3D(points[0], dirNY, dirX);\n      const frontPlane = geo.createPlane(frontPlacement);\n      const frontLoop = topo.createEdgeLoop([\n        topo.createOrientedEdge(edges[0], true),\n        topo.createOrientedEdge(edges[9], true),\n        topo.createOrientedEdge(edges[4], false),\n        topo.createOrientedEdge(edges[8], false)\n      ]);\n      faces.push(topo.createAdvancedFace(\n        [topo.createFaceOuterBound(frontLoop)],\n        frontPlane, true, 'Front'\n      ));\n\n      // Back face (Y+)\n      const backPlacement = geo.createAxis2Placement3D(points[3], dirY, dirNX);\n      const backPlane = geo.createPlane(backPlacement);\n      const backLoop = topo.createEdgeLoop([\n        topo.createOrientedEdge(edges[2], true),\n        topo.createOrientedEdge(edges[11], false),\n        topo.createOrientedEdge(edges[6], false),\n        topo.createOrientedEdge(edges[10], true)\n      ]);\n      faces.push(topo.createAdvancedFace(\n        [topo.createFaceOuterBound(backLoop)],\n        backPlane, true, 'Back'\n      ));\n\n      // Left face (X-)\n      const leftPlacement = geo.createAxis2Placement3D(points[0], dirNX, dirY);\n      const leftPlane = geo.createPlane(leftPlacement);\n      const leftLoop = topo.createEdgeLoop([\n        topo.createOrientedEdge(edges[3], true),\n        topo.createOrientedEdge(edges[8], true),\n        topo.createOrientedEdge(edges[7], false),\n        topo.createOrientedEdge(edges[11], true)\n      ]);\n      faces.push(topo.createAdvancedFace(\n        [topo.createFaceOuterBound(leftLoop)],\n        leftPlane, true, 'Left'\n      ));\n\n      // Right face (X+)\n      const rightPlacement = geo.createAxis2Placement3D(points[1], dirX, dirNY);\n      const rightPlane = geo.createPlane(rightPlacement);\n      const rightLoop = topo.createEdgeLoop([\n        topo.createOrientedEdge(edges[1], true),\n        topo.createOrientedEdge(edges[10], true),\n        topo.createOrientedEdge(edges[5], false),\n        topo.createOrientedEdge(edges[9], false)\n      ]);\n      faces.push(topo.createAdvancedFace(\n        [topo.createFaceOuterBound(rightLoop)],\n        rightPlane, true, 'Right'\n      ));\n\n      // Create shell and solid\n      const shell = topo.createClosedShell(faces, 'BoxShell');\n      const solid = topo.createManifoldSolidBrep(shell, 'Box');\n\n      return {\n        solid,\n        shell,\n        faces,\n        edges,\n        vertices,\n        points,\n        boundingBox: { x, y, z, dx, dy, dz },\n        entityCount: {\n          points: 8,\n          vertices: 8,\n          edges: 12,\n          faces: 6\n        }\n      };\n    },\n    /**\n     * Create a cylinder solid with full B-Rep topology\n     */\n    createCylinder(cx, cy, cz, radius, height, segments = 36) {\n      const geo = PRISM_BREP_CAD_GENERATOR_V2.geometry;\n      const topo = PRISM_BREP_CAD_GENERATOR_V2.topologyOps;\n\n      // Direction vectors\n      const dirZ = geo.createDirection(0, 0, 1);\n      const dirNZ = geo.createDirection(0, 0, -1);\n      const dirX = geo.createDirection(1, 0, 0);\n\n      // Create center points\n      const bottomCenter = geo.createPoint(cx, cy, cz);\n      const topCenter = geo.createPoint(cx, cy, cz + height);\n\n      // Create placements\n      const bottomPlacement = geo.createAxis2Placement3D(bottomCenter, dirNZ, dirX);\n      const topPlacement = geo.createAxis2Placement3D(topCenter, dirZ, dirX);\n      const cylPlacement = geo.createAxis2Placement3D(bottomCenter, dirZ, dirX);\n\n      // Create surfaces\n      const bottomPlane = geo.createPlane(bottomPlacement);\n      const topPlane = geo.createPlane(topPlacement);\n      const cylSurface = geo.createCylindricalSurface(cylPlacement, radius);\n\n      // Create circles\n      const bottomCircle = geo.createCircle(bottomPlacement, radius);\n      const topCircle = geo.createCircle(topPlacement, radius);\n\n      // Create vertices on circles\n      const bottomVertices = [];\n      const topVertices = [];\n      const bottomPoints = [];\n      const topPoints = [];\n\n      for (let i = 0; i < segments; i++) {\n        const angle = (i / segments) * Math.PI * 2;\n        const px = cx + radius * Math.cos(angle);\n        const py = cy + radius * Math.sin(angle);\n\n        const bp = geo.createPoint(px, py, cz);\n        const tp = geo.createPoint(px, py, cz + height);\n\n        bottomPoints.push(bp);\n        topPoints.push(tp);\n        bottomVertices.push(topo.createVertex(bp));\n        topVertices.push(topo.createVertex(tp));\n      }\n      // Create edges\n      const bottomEdges = [];\n      const topEdges = [];\n      const sideEdges = [];\n\n      for (let i = 0; i < segments; i++) {\n        const next = (i + 1) % segments;\n\n        // Bottom circle edges (using arc segments of the circle)\n        const bEdgeCurve = geo.createLine(bottomPoints[i],\n          geo.createDirection(\n            bottomPoints[next].x - bottomPoints[i].x,\n            bottomPoints[next].y - bottomPoints[i].y,\n            0\n          ));\n        bottomEdges.push(topo.createEdgeCurve(\n          bottomVertices[i], bottomVertices[next], bEdgeCurve\n        ));\n\n        // Top circle edges\n        const tEdgeCurve = geo.createLine(topPoints[i],\n          geo.createDirection(\n            topPoints[next].x - topPoints[i].x,\n            topPoints[next].y - topPoints[i].y,\n            0\n          ));\n        topEdges.push(topo.createEdgeCurve(\n          topVertices[i], topVertices[next], tEdgeCurve\n        ));\n\n        // Vertical edges\n        const vEdgeCurve = geo.createLine(bottomPoints[i], dirZ);\n        sideEdges.push(topo.createEdgeCurve(\n          bottomVertices[i], topVertices[i], vEdgeCurve\n        ));\n      }\n      // Create bottom face\n      const bottomOrientedEdges = bottomEdges.map((e, i) =>\n        topo.createOrientedEdge(e, false)\n      ).reverse();\n      const bottomLoop = topo.createEdgeLoop(bottomOrientedEdges);\n      const bottomFace = topo.createAdvancedFace(\n        [topo.createFaceOuterBound(bottomLoop)],\n        bottomPlane, true, 'CylinderBottom'\n      );\n\n      // Create top face\n      const topOrientedEdges = topEdges.map(e =>\n        topo.createOrientedEdge(e, true)\n      );\n      const topLoop = topo.createEdgeLoop(topOrientedEdges);\n      const topFace = topo.createAdvancedFace(\n        [topo.createFaceOuterBound(topLoop)],\n        topPlane, true, 'CylinderTop'\n      );\n\n      // Create cylindrical side faces\n      const sideFaces = [];\n      for (let i = 0; i < segments; i++) {\n        const next = (i + 1) % segments;\n        const sideLoop = topo.createEdgeLoop([\n          topo.createOrientedEdge(bottomEdges[i], true),\n          topo.createOrientedEdge(sideEdges[next], true),\n          topo.createOrientedEdge(topEdges[i], false),\n          topo.createOrientedEdge(sideEdges[i], false)\n        ]);\n        sideFaces.push(topo.createAdvancedFace(\n          [topo.createFaceOuterBound(sideLoop)],\n          cylSurface, true, 'CylinderSide_' + i\n        ));\n      }\n      // Assemble faces\n      const allFaces = [bottomFace, topFace, ...sideFaces];\n      const shell = topo.createClosedShell(allFaces, 'CylinderShell');\n      const solid = topo.createManifoldSolidBrep(shell, 'Cylinder');\n\n      return {\n        solid,\n        shell,\n        faces: allFaces,\n        bottomFace,\n        topFace,\n        sideFaces,\n        edges: [...bottomEdges, ...topEdges, ...sideEdges],\n        vertices: [...bottomVertices, ...topVertices],\n        boundingBox: {\n          x: cx - radius, y: cy - radius, z: cz,\n          dx: radius * 2, dy: radius * 2, dz: height\n        },\n        entityCount: {\n          points: segments * 2 + 2,\n          vertices: segments * 2,\n          edges: segments * 3,\n          faces: segments + 2\n        }\n      };\n    },\n    /**\n     * Create a cone solid with full B-Rep topology\n     */\n    createCone(cx, cy, cz, bottomRadius, topRadius, height, segments = 36) {\n      const geo = PRISM_BREP_CAD_GENERATOR_V2.geometry;\n      const topo = PRISM_BREP_CAD_GENERATOR_V2.topologyOps;\n\n      // Direction vectors\n      const dirZ = geo.createDirection(0, 0, 1);\n      const dirNZ = geo.createDirection(0, 0, -1);\n      const dirX = geo.createDirection(1, 0, 0);\n\n      // Calculate cone angle\n      const semiAngle = Math.atan2(bottomRadius - topRadius, height);\n\n      // Create center points\n      const bottomCenter = geo.createPoint(cx, cy, cz);\n      const topCenter = geo.createPoint(cx, cy, cz + height);\n\n      // Create placements\n      const bottomPlacement = geo.createAxis2Placement3D(bottomCenter, dirNZ, dirX);\n      const topPlacement = geo.createAxis2Placement3D(topCenter, dirZ, dirX);\n      const conePlacement = geo.createAxis2Placement3D(bottomCenter, dirZ, dirX);\n\n      // Create surfaces\n      const bottomPlane = geo.createPlane(bottomPlacement);\n      const topPlane = geo.createPlane(topPlacement);\n      const coneSurface = geo.createConicalSurface(conePlacement, bottomRadius, semiAngle);\n\n      // Create vertices\n      const bottomVertices = [];\n      const topVertices = [];\n      const bottomPoints = [];\n      const topPoints = [];\n\n      for (let i = 0; i < segments; i++) {\n        const angle = (i / segments) * Math.PI * 2;\n\n        const bx = cx + bottomRadius * Math.cos(angle);\n        const by = cy + bottomRadius * Math.sin(angle);\n        const tx = cx + topRadius * Math.cos(angle);\n        const ty = cy + topRadius * Math.sin(angle);\n\n        const bp = geo.createPoint(bx, by, cz);\n        const tp = geo.createPoint(tx, ty, cz + height);\n\n        bottomPoints.push(bp);\n        topPoints.push(tp);\n        bottomVertices.push(topo.createVertex(bp));\n        topVertices.push(topo.createVertex(tp));\n      }\n      // Create edges (similar to cylinder but with different radii)\n      const bottomEdges = [];\n      const topEdges = [];\n      const sideEdges = [];\n\n      for (let i = 0; i < segments; i++) {\n        const next = (i + 1) % segments;\n\n        // Bottom circle edges\n        const bDir = geo.createDirection(\n          bottomPoints[next].x - bottomPoints[i].x,\n          bottomPoints[next].y - bottomPoints[i].y,\n          0\n        );\n        bottomEdges.push(topo.createEdgeCurve(\n          bottomVertices[i], bottomVertices[next],\n          geo.createLine(bottomPoints[i], bDir)\n        ));\n\n        // Top circle edges\n        const tDir = geo.createDirection(\n          topPoints[next].x - topPoints[i].x,\n          topPoints[next].y - topPoints[i].y,\n          0\n        );\n        topEdges.push(topo.createEdgeCurve(\n          topVertices[i], topVertices[next],\n          geo.createLine(topPoints[i], tDir)\n        ));\n\n        // Side edges (slanted)\n        const sDir = geo.createDirection(\n          topPoints[i].x - bottomPoints[i].x,\n          topPoints[i].y - bottomPoints[i].y,\n          height\n        );\n        sideEdges.push(topo.createEdgeCurve(\n          bottomVertices[i], topVertices[i],\n          geo.createLine(bottomPoints[i], sDir)\n        ));\n      }\n      // Create faces\n      const bottomLoop = topo.createEdgeLoop(\n        bottomEdges.map(e => topo.createOrientedEdge(e, false)).reverse()\n      );\n      const bottomFace = topo.createAdvancedFace(\n        [topo.createFaceOuterBound(bottomLoop)],\n        bottomPlane, true, 'ConeBottom'\n      );\n\n      const topLoop = topo.createEdgeLoop(\n        topEdges.map(e => topo.createOrientedEdge(e, true))\n      );\n      const topFace = topo.createAdvancedFace(\n        [topo.createFaceOuterBound(topLoop)],\n        topPlane, true, 'ConeTop'\n      );\n\n      // Side faces\n      const sideFaces = [];\n      for (let i = 0; i < segments; i++) {\n        const next = (i + 1) % segments;\n        const sideLoop = topo.createEdgeLoop([\n          topo.createOrientedEdge(bottomEdges[i], true),\n          topo.createOrientedEdge(sideEdges[next], true),\n          topo.createOrientedEdge(topEdges[i], false),\n          topo.createOrientedEdge(sideEdges[i], false)\n        ]);\n        sideFaces.push(topo.createAdvancedFace(\n          [topo.createFaceOuterBound(sideLoop)],\n          coneSurface, true, 'ConeSide_' + i\n        ));\n      }\n      const allFaces = [bottomFace, topFace, ...sideFaces];\n      const shell = topo.createClosedShell(allFaces, 'ConeShell');\n      const solid = topo.createManifoldSolidBrep(shell, 'Cone');\n\n      return {\n        solid,\n        shell,\n        faces: allFaces,\n        edges: [...bottomEdges, ...topEdges, ...sideEdges],\n        vertices: [...bottomVertices, ...topVertices],\n        boundingBox: {\n          x: cx - bottomRadius, y: cy - bottomRadius, z: cz,\n          dx: bottomRadius * 2, dy: bottomRadius * 2, dz: height\n        }\n      };\n    },\n    /**\n     * Create a sphere solid\n     */\n    createSphere(cx, cy, cz, radius, uSegments = 24, vSegments = 12) {\n      const geo = PRISM_BREP_CAD_GENERATOR_V2.geometry;\n      const topo = PRISM_BREP_CAD_GENERATOR_V2.topologyOps;\n\n      const center = geo.createPoint(cx, cy, cz);\n      const dirZ = geo.createDirection(0, 0, 1);\n      const dirX = geo.createDirection(1, 0, 0);\n      const placement = geo.createAxis2Placement3D(center, dirZ, dirX);\n      const sphereSurface = geo.createSphericalSurface(placement, radius);\n\n      // Create points grid\n      const pointGrid = [];\n      const vertexGrid = [];\n\n      for (let v = 0; v <= vSegments; v++) {\n        const phi = (v / vSegments) * Math.PI; // 0 to PI\n        const row = [];\n        const vRow = [];\n\n        for (let u = 0; u < uSegments; u++) {\n          const theta = (u / uSegments) * Math.PI * 2;\n          const px = cx + radius * Math.sin(phi) * Math.cos(theta);\n          const py = cy + radius * Math.sin(phi) * Math.sin(theta);\n          const pz = cz + radius * Math.cos(phi);\n\n          const pt = geo.createPoint(px, py, pz);\n          row.push(pt);\n          vRow.push(topo.createVertex(pt));\n        }\n        pointGrid.push(row);\n        vertexGrid.push(vRow);\n      }\n      // Create faces\n      const faces = [];\n      const edges = [];\n\n      for (let v = 0; v < vSegments; v++) {\n        for (let u = 0; u < uSegments; u++) {\n          const nextU = (u + 1) % uSegments;\n\n          // Skip degenerate faces at poles\n          if (v === 0) {\n            // Top cap - triangle faces\n            const e1 = topo.createEdgeCurve(vertexGrid[0][u], vertexGrid[1][u],\n              geo.createLine(pointGrid[0][u], geo.createDirection(\n                pointGrid[1][u].x - pointGrid[0][u].x,\n                pointGrid[1][u].y - pointGrid[0][u].y,\n                pointGrid[1][u].z - pointGrid[0][u].z\n              )));\n            const e2 = topo.createEdgeCurve(vertexGrid[1][u], vertexGrid[1][nextU],\n              geo.createLine(pointGrid[1][u], geo.createDirection(\n                pointGrid[1][nextU].x - pointGrid[1][u].x,\n                pointGrid[1][nextU].y - pointGrid[1][u].y,\n                pointGrid[1][nextU].z - pointGrid[1][u].z\n              )));\n            const e3 = topo.createEdgeCurve(vertexGrid[1][nextU], vertexGrid[0][u],\n              geo.createLine(pointGrid[1][nextU], geo.createDirection(\n                pointGrid[0][u].x - pointGrid[1][nextU].x,\n                pointGrid[0][u].y - pointGrid[1][nextU].y,\n                pointGrid[0][u].z - pointGrid[1][nextU].z\n              )));\n\n            edges.push(e1, e2, e3);\n\n            const loop = topo.createEdgeLoop([\n              topo.createOrientedEdge(e1, true),\n              topo.createOrientedEdge(e2, true),\n              topo.createOrientedEdge(e3, true)\n            ]);\n            faces.push(topo.createAdvancedFace(\n              [topo.createFaceOuterBound(loop)],\n              sphereSurface, true, `SphereFace_${v}_${u}`\n            ));\n          } else if (v === vSegments - 1) {\n            // Bottom cap - triangle faces (similar)\n            continue; // Skip for brevity\n          } else {\n            // Regular quad faces\n            const v0 = vertexGrid[v][u];\n            const v1 = vertexGrid[v][nextU];\n            const v2 = vertexGrid[v+1][nextU];\n            const v3 = vertexGrid[v+1][u];\n\n            const p0 = pointGrid[v][u];\n            const p1 = pointGrid[v][nextU];\n            const p2 = pointGrid[v+1][nextU];\n            const p3 = pointGrid[v+1][u];\n\n            const e0 = topo.createEdgeCurve(v0, v1, geo.createLine(p0,\n              geo.createDirection(p1.x-p0.x, p1.y-p0.y, p1.z-p0.z)));\n            const e1 = topo.createEdgeCurve(v1, v2, geo.createLine(p1,\n              geo.createDirection(p2.x-p1.x, p2.y-p1.y, p2.z-p1.z)));\n            const e2 = topo.createEdgeCurve(v2, v3, geo.createLine(p2,\n              geo.createDirection(p3.x-p2.x, p3.y-p2.y, p3.z-p2.z)));\n            const e3 = topo.createEdgeCurve(v3, v0, geo.createLine(p3,\n              geo.createDirection(p0.x-p3.x, p0.y-p3.y, p0.z-p3.z)));\n\n            edges.push(e0, e1, e2, e3);\n\n            const loop = topo.createEdgeLoop([\n              topo.createOrientedEdge(e0, true),\n              topo.createOrientedEdge(e1, true),\n              topo.createOrientedEdge(e2, true),\n              topo.createOrientedEdge(e3, true)\n            ]);\n            faces.push(topo.createAdvancedFace(\n              [topo.createFaceOuterBound(loop)],\n              sphereSurface, true, `SphereFace_${v}_${u}`\n            ));\n          }\n        }\n      }\n      const shell = topo.createClosedShell(faces, 'SphereShell');\n      const solid = topo.createManifoldSolidBrep(shell, 'Sphere');\n\n      return {\n        solid,\n        shell,\n        faces,\n        edges,\n        boundingBox: {\n          x: cx - radius, y: cy - radius, z: cz - radius,\n          dx: radius * 2, dy: radius * 2, dz: radius * 2\n        }\n      };\n    },\n    /**\n     * Create a torus solid\n     */\n    createTorus(cx, cy, cz, majorRadius, minorRadius, uSegments = 36, vSegments = 24) {\n      const geo = PRISM_BREP_CAD_GENERATOR_V2.geometry;\n      const topo = PRISM_BREP_CAD_GENERATOR_V2.topologyOps;\n\n      const center = geo.createPoint(cx, cy, cz);\n      const dirZ = geo.createDirection(0, 0, 1);\n      const dirX = geo.createDirection(1, 0, 0);\n      const placement = geo.createAxis2Placement3D(center, dirZ, dirX);\n      const torusSurface = geo.createToroidalSurface(placement, majorRadius, minorRadius);\n\n      // Create point grid\n      const pointGrid = [];\n      const vertexGrid = [];\n\n      for (let u = 0; u < uSegments; u++) {\n        const theta = (u / uSegments) * Math.PI * 2;\n        const row = [];\n        const vRow = [];\n\n        for (let v = 0; v < vSegments; v++) {\n          const phi = (v / vSegments) * Math.PI * 2;\n          const r = majorRadius + minorRadius * Math.cos(phi);\n\n          const px = cx + r * Math.cos(theta);\n          const py = cy + r * Math.sin(theta);\n          const pz = cz + minorRadius * Math.sin(phi);\n\n          const pt = geo.createPoint(px, py, pz);\n          row.push(pt);\n          vRow.push(topo.createVertex(pt));\n        }\n        pointGrid.push(row);\n        vertexGrid.push(vRow);\n      }\n      // Create quad faces\n      const faces = [];\n      const edges = [];\n\n      for (let u = 0; u < uSegments; u++) {\n        const nextU = (u + 1) % uSegments;\n        for (let v = 0; v < vSegments; v++) {\n          const nextV = (v + 1) % vSegments;\n\n          const v0 = vertexGrid[u][v];\n          const v1 = vertexGrid[nextU][v];\n          const v2 = vertexGrid[nextU][nextV];\n          const v3 = vertexGrid[u][nextV];\n\n          const p0 = pointGrid[u][v];\n          const p1 = pointGrid[nextU][v];\n          const p2 = pointGrid[nextU][nextV];\n          const p3 = pointGrid[u][nextV];\n\n          const e0 = topo.createEdgeCurve(v0, v1, geo.createLine(p0,\n            geo.createDirection(p1.x-p0.x, p1.y-p0.y, p1.z-p0.z)));\n          const e1 = topo.createEdgeCurve(v1, v2, geo.createLine(p1,\n            geo.createDirection(p2.x-p1.x, p2.y-p1.y, p2.z-p1.z)));\n          const e2 = topo.createEdgeCurve(v2, v3, geo.createLine(p2,\n            geo.createDirection(p3.x-p2.x, p3.y-p2.y, p3.z-p2.z)));\n          const e3 = topo.createEdgeCurve(v3, v0, geo.createLine(p3,\n            geo.createDirection(p0.x-p3.x, p0.y-p3.y, p0.z-p3.z)));\n\n          edges.push(e0, e1, e2, e3);\n\n          const loop = topo.createEdgeLoop([\n            topo.createOrientedEdge(e0, true),\n            topo.createOrientedEdge(e1, true),\n            topo.createOrientedEdge(e2, true),\n            topo.createOrientedEdge(e3, true)\n          ]);\n          faces.push(topo.createAdvancedFace(\n            [topo.createFaceOuterBound(loop)],\n            torusSurface, true, `TorusFace_${u}_${v}`\n          ));\n        }\n      }\n      const shell = topo.createClosedShell(faces, 'TorusShell');\n      const solid = topo.createManifoldSolidBrep(shell, 'Torus');\n\n      return {\n        solid,\n        shell,\n        faces,\n        edges,\n        boundingBox: {\n          x: cx - majorRadius - minorRadius,\n          y: cy - majorRadius - minorRadius,\n          z: cz - minorRadius,\n          dx: (majorRadius + minorRadius) * 2,\n          dy: (majorRadius + minorRadius) * 2,\n          dz: minorRadius * 2\n        }\n      };\n    }\n  },\n  // HIGH-FIDELITY MESH GENERATION\n\n  tessellation: {\n\n    /**\n     * Tessellate a B-Rep solid to triangular mesh\n     * Uses curvature-adaptive subdivision for high quality\n     */\n    tessellate(brep, options = {}) {\n      const {\n        minSegments = 8,\n        maxSegments = 72,\n        chordTolerance = 0.01,\n        angleTolerance = 15,  // degrees\n        targetTriangles = null\n      } = options;\n\n      const vertices = [];\n      const indices = [];\n      const normals = [];\n      const uvs = [];\n\n      let vertexIndex = 0;\n\n      // Process each face\n      for (const face of (brep.faces || [])) {\n        const faceResult = this._tessellateFace(face, {\n          minSegments,\n          maxSegments,\n          chordTolerance,\n          angleTolerance\n        });\n\n        // Add vertices\n        for (let i = 0; i < faceResult.vertices.length; i += 3) {\n          vertices.push(\n            faceResult.vertices[i],\n            faceResult.vertices[i + 1],\n            faceResult.vertices[i + 2]\n          );\n        }\n        // Add normals\n        for (let i = 0; i < faceResult.normals.length; i += 3) {\n          normals.push(\n            faceResult.normals[i],\n            faceResult.normals[i + 1],\n            faceResult.normals[i + 2]\n          );\n        }\n        // Add indices (offset by current vertex count)\n        for (const idx of faceResult.indices) {\n          indices.push(idx + vertexIndex);\n        }\n        vertexIndex += faceResult.vertices.length / 3;\n      }\n      return {\n        vertices: new Float32Array(vertices),\n        normals: new Float32Array(normals),\n        indices: indices,\n        uvs: new Float32Array(uvs),\n        statistics: {\n          vertexCount: vertices.length / 3,\n          triangleCount: indices.length / 3,\n          faceCount: brep.faces?.length || 0\n        }\n      };\n    },\n    /**\n     * Tessellate a single face\n     */\n    _tessellateFace(face, options) {\n      const surface = face.surface;\n      if (!surface) {\n        return { vertices: [], normals: [], indices: [] };\n      }\n      switch (surface.type) {\n        case 'PLANE':\n          return this._tessellatePlanarFace(face, options);\n        case 'CYLINDRICAL_SURFACE':\n          return this._tessellateCylindricalFace(face, options);\n        case 'CONICAL_SURFACE':\n          return this._tessellateConicalFace(face, options);\n        case 'SPHERICAL_SURFACE':\n          return this._tessellateSphericalFace(face, options);\n        case 'TOROIDAL_SURFACE':\n          return this._tessellateToroidalFace(face, options);\n        case 'B_SPLINE_SURFACE_WITH_KNOTS':\n        case 'RATIONAL_B_SPLINE_SURFACE':\n          return this._tessellateBSplineFace(face, options);\n        default:\n          return this._tessellateGenericFace(face, options);\n      }\n    },\n    /**\n     * Tessellate a planar face\n     */\n    _tessellatePlanarFace(face, options) {\n      const vertices = [];\n      const normals = [];\n      const indices = [];\n\n      // Get face boundary vertices from edge loop\n      const boundary = this._extractBoundaryPoints(face);\n      if (boundary.length < 3) {\n        return { vertices: [], normals: [], indices: [] };\n      }\n      // Calculate face normal\n      const normal = this._calculateFaceNormal(face);\n\n      // Triangulate the polygon (ear clipping algorithm)\n      const triangulated = this._triangulatePolygon(boundary, normal);\n\n      // Build vertex and index arrays\n      for (const pt of triangulated.vertices) {\n        vertices.push(pt.x, pt.y, pt.z);\n        normals.push(normal.x, normal.y, normal.z);\n      }\n      for (const idx of triangulated.indices) {\n        indices.push(idx);\n      }\n      return { vertices, normals, indices };\n    },\n    /**\n     * Tessellate a cylindrical face with proper curvature\n     */\n    _tessellateCylindricalFace(face, options) {\n      const surface = face.surface;\n      const placement = surface.placement;\n      const radius = surface.radius;\n\n      // Calculate segments based on curvature\n      const circumference = 2 * Math.PI * radius;\n      const chordError = options.chordTolerance;\n      const segmentsFromChord = Math.ceil(Math.PI / Math.acos(1 - chordError / radius));\n      const segments = Math.max(options.minSegments,\n                                Math.min(options.maxSegments, segmentsFromChord));\n\n      const vertices = [];\n      const normals = [];\n      const indices = [];\n\n      // Get height from boundary\n      const boundary = this._extractBoundaryPoints(face);\n      let minZ = Infinity, maxZ = -Infinity;\n      for (const pt of boundary) {\n        minZ = Math.min(minZ, pt.z);\n        maxZ = Math.max(maxZ, pt.z);\n      }\n      const height = maxZ - minZ;\n\n      // Generate vertices\n      const origin = placement.origin;\n      const heightSegs = Math.max(1, Math.ceil(height / (radius * 0.5)));\n\n      for (let h = 0; h <= heightSegs; h++) {\n        const z = minZ + (h / heightSegs) * height;\n        for (let s = 0; s < segments; s++) {\n          const angle = (s / segments) * Math.PI * 2;\n          const x = origin.x + radius * Math.cos(angle);\n          const y = origin.y + radius * Math.sin(angle);\n\n          vertices.push(x, y, z);\n          normals.push(Math.cos(angle), Math.sin(angle), 0);\n        }\n      }\n      // Generate indices\n      for (let h = 0; h < heightSegs; h++) {\n        for (let s = 0; s < segments; s++) {\n          const nextS = (s + 1) % segments;\n          const i0 = h * segments + s;\n          const i1 = h * segments + nextS;\n          const i2 = (h + 1) * segments + nextS;\n          const i3 = (h + 1) * segments + s;\n\n          indices.push(i0, i1, i2);\n          indices.push(i0, i2, i3);\n        }\n      }\n      return { vertices, normals, indices };\n    },\n    // Helper methods\n    _extractBoundaryPoints(face) {\n      const points = [];\n      if (face.boundList) {\n        for (const bound of face.boundList) {\n          if (bound.loop && bound.loop.edges) {\n            for (const orientedEdge of bound.loop.edges) {\n              const edge = orientedEdge.edge;\n              if (edge && edge.vertex1 && edge.vertex1.point) {\n                points.push(edge.vertex1.point);\n              }\n            }\n          }\n        }\n      }\n      return points;\n    },\n    _calculateFaceNormal(face) {\n      if (face.surface && face.surface.placement) {\n        const axis = face.surface.placement.axisDir;\n        if (axis) return { x: axis.x, y: axis.y, z: axis.z };\n      }\n      return { x: 0, y: 0, z: 1 };\n    },\n    _triangulatePolygon(vertices, normal) {\n      // Simple fan triangulation for convex polygons\n      // For complex polygons, use ear clipping\n      const result = {\n        vertices: vertices,\n        indices: []\n      };\n      if (vertices.length < 3) return result;\n\n      // Fan triangulation\n      for (let i = 1; i < vertices.length - 1; i++) {\n        result.indices.push(0, i, i + 1);\n      }\n      return result;\n    },\n    // Stub implementations for other face types\n    _tessellateConicalFace(face, options) {\n      return this._tessellateCylindricalFace(face, options);\n    },\n    _tessellateSphericalFace(face, options) {\n      return { vertices: [], normals: [], indices: [] };\n    },\n    _tessellateToroidalFace(face, options) {\n      return { vertices: [], normals: [], indices: [] };\n    },\n    _tessellateBSplineFace(face, options) {\n      return { vertices: [], normals: [], indices: [] };\n    },\n    _tessellateGenericFace(face, options) {\n      return { vertices: [], normals: [], indices: [] };\n    }\n  },\n  // INITIALIZATION\n\n  init() {\n    console.log('[PRISM_BREP_CAD_GENERATOR_V2] Initialized v' + this.version);\n    console.log('  \u2713 Full B-Rep topology support');\n    console.log('  \u2713 Primitives: box, cylinder, cone, sphere, torus');\n    console.log('  \u2713 Curvature-adaptive tessellation');\n    window.PRISM_BREP_CAD_GENERATOR_V2 = this;\n    return this;\n  }\n}",
      "methods": [],
      "lines": 1285
    },
    {
      "name": "PRISM_NURBS_LIBRARY",
      "category": "engines/cad_cam",
      "refs": 36,
      "status": "FOUND",
      "code": "const PRISM_NURBS_LIBRARY = {\n  name: 'PRISM_NURBS_LIBRARY',\n  version: '1.0.0',\n  description: 'Complete NURBS and B-Spline evaluation for CAM operations',\n\n  basis: {\n    N(i, p, u, knots) {\n      if (p === 0) return (u >= knots[i] && u < knots[i + 1]) ? 1.0 : 0.0;\n      const left = knots[i + p] - knots[i];\n      const right = knots[i + p + 1] - knots[i + 1];\n      let result = 0.0;\n      if (left !== 0) result += ((u - knots[i]) / left) * this.N(i, p - 1, u, knots);\n      if (right !== 0) result += ((knots[i + p + 1] - u) / right) * this.N(i + 1, p - 1, u, knots);\n      return result;\n    },\n    basisFunctions(u, p, knots) {\n      const n = knots.length - p - 2;\n      let span = p;\n      for (let i = p; i < n + 1; i++) {\n        if (u >= knots[i] && u < knots[i + 1]) { span = i; break; }\n      }\n      if (u >= knots[n + 1]) span = n;\n\n      const N = new Array(p + 1).fill(0);\n      N[0] = 1.0;\n      const left = new Array(p + 1).fill(0);\n      const right = new Array(p + 1).fill(0);\n\n      for (let j = 1; j <= p; j++) {\n        left[j] = u - knots[span + 1 - j];\n        right[j] = knots[span + j] - u;\n        let saved = 0.0;\n        for (let r = 0; r < j; r++) {\n          const temp = N[r] / (right[r + 1] + left[j - r]);\n          N[r] = saved + right[r + 1] * temp;\n          saved = left[j - r] * temp;\n        }\n        N[j] = saved;\n      }\n      return { span, values: N };\n    }\n  },\n  curve: {\n    evaluate(curve, u) {\n      const { degree, controlPoints, knots, weights } = curve;\n      const n = controlPoints.length - 1;\n      const uMin = knots[degree], uMax = knots[n + 1];\n      const uActual = uMin + u * (uMax - uMin);\n      const { span, values } = PRISM_NURBS_LIBRARY.basis.basisFunctions(uActual, degree, knots);\n\n      let point = { x: 0, y: 0, z: 0 }, sumW = 0;\n      for (let i = 0; i <= degree; i++) {\n        const idx = span - degree + i;\n        const cp = controlPoints[idx];\n        const w = weights ? weights[idx] : 1.0;\n        const basis = values[i] * w;\n        point.x += basis * cp.x;\n        point.y += basis * cp.y;\n        point.z += (cp.z || 0) * basis;\n        sumW += basis;\n      }\n      if (weights && sumW > 0) { point.x /= sumW; point.y /= sumW; point.z /= sumW; }\n      return point;\n    },\n    tangent(curve, u) {\n      const eps = 0.001;\n      const p1 = this.evaluate(curve, Math.max(0, u - eps));\n      const p2 = this.evaluate(curve, Math.min(1, u + eps));\n      const d = { x: p2.x - p1.x, y: p2.y - p1.y, z: p2.z - p1.z };\n      const len = Math.sqrt(d.x*d.x + d.y*d.y + d.z*d.z);\n      return len > 1e-10 ? { x: d.x/len, y: d.y/len, z: d.z/len } : { x: 1, y: 0, z: 0 };\n    },\n    curvature(curve, u) {\n      const eps = 0.001;\n      const p0 = this.evaluate(curve, Math.max(0, u - eps));\n      const p1 = this.evaluate(curve, u);\n      const p2 = this.evaluate(curve, Math.min(1, u + eps));\n      const d1 = { x: p1.x - p0.x, y: p1.y - p0.y, z: p1.z - p0.z };\n      const d2 = { x: p2.x - p1.x, y: p2.y - p1.y, z: p2.z - p1.z };\n      const cross = {\n        x: d1.y * d2.z - d1.z * d2.y,\n        y: d1.z * d2.x - d1.x * d2.z,\n        z: d1.x * d2.y - d1.y * d2.x\n      };\n      const crossMag = Math.sqrt(cross.x*cross.x + cross.y*cross.y + cross.z*cross.z);\n      const d1Mag = Math.sqrt(d1.x*d1.x + d1.y*d1.y + d1.z*d1.z);\n      return d1Mag > 1e-10 ? crossMag / Math.pow(d1Mag, 3) : 0;\n    },\n    tessellate(curve, tolerance = 0.01) {\n      const points = [];\n      for (let u = 0; u <= 1; u += 0.02) {\n        points.push({ ...this.evaluate(curve, u), u });\n      }\n      return points;\n    }\n  },\n  surface: {\n    evaluate(surface, u, v) {\n      const { degreeU, degreeV, controlPoints, knotsU, knotsV, weights } = surface;\n      const uCount = controlPoints.length, vCount = controlPoints[0].length;\n      const uMin = knotsU[degreeU], uMax = knotsU[uCount];\n      const vMin = knotsV[degreeV], vMax = knotsV[vCount];\n      const uActual = uMin + u * (uMax - uMin);\n      const vActual = vMin + v * (vMax - vMin);\n\n      const basisU = PRISM_NURBS_LIBRARY.basis.basisFunctions(uActual, degreeU, knotsU);\n      const basisV = PRISM_NURBS_LIBRARY.basis.basisFunctions(vActual, degreeV, knotsV);\n\n      let point = { x: 0, y: 0, z: 0 }, sumW = 0;\n      for (let i = 0; i <= degreeU; i++) {\n        const ui = basisU.span - degreeU + i;\n        for (let j = 0; j <= degreeV; j++) {\n          const vj = basisV.span - degreeV + j;\n          if (ui >= 0 && ui < uCount && vj >= 0 && vj < vCount) {\n            const cp = controlPoints[ui][vj];\n            const w = weights ? weights[ui][vj] : 1.0;\n            const basis = basisU.values[i] * basisV.values[j] * w;\n            point.x += basis * cp.x;\n            point.y += basis * cp.y;\n            point.z += basis * cp.z;\n            sumW += basis;\n          }\n        }\n      }\n      if (weights && sumW > 0) { point.x /= sumW; point.y /= sumW; point.z /= sumW; }\n      return point;\n    },\n    normal(surface, u, v) {\n      const eps = 0.001;\n      const p = this.evaluate(surface, u, v);\n      const pu = this.evaluate(surface, Math.min(u + eps, 1), v);\n      const pv = this.evaluate(surface, u, Math.min(v + eps, 1));\n      const du = { x: (pu.x - p.x) / eps, y: (pu.y - p.y) / eps, z: (pu.z - p.z) / eps };\n      const dv = { x: (pv.x - p.x) / eps, y: (pv.y - p.y) / eps, z: (pv.z - p.z) / eps };\n      const normal = {\n        x: du.y * dv.z - du.z * dv.y,\n        y: du.z * dv.x - du.x * dv.z,\n        z: du.x * dv.y - du.y * dv.x\n      };\n      const len = Math.sqrt(normal.x*normal.x + normal.y*normal.y + normal.z*normal.z);\n      if (len > 1e-10) { normal.x /= len; normal.y /= len; normal.z /= len; }\n      else { normal.z = 1; }\n      return normal;\n    },\n    curvatures(surface, u, v) {\n      const eps = 0.001;\n      const p = this.evaluate(surface, u, v);\n      const n = this.normal(surface, u, v);\n      const pu = this.evaluate(surface, Math.min(u + eps, 1), v);\n      const pv = this.evaluate(surface, u, Math.min(v + eps, 1));\n      const Su = { x: (pu.x - p.x) / eps, y: (pu.y - p.y) / eps, z: (pu.z - p.z) / eps };\n      const Sv = { x: (pv.x - p.x) / eps, y: (pv.y - p.y) / eps, z: (pv.z - p.z) / eps };\n      const E = Su.x*Su.x + Su.y*Su.y + Su.z*Su.z;\n      const F = Su.x*Sv.x + Su.y*Sv.y + Su.z*Sv.z;\n      const G = Sv.x*Sv.x + Sv.y*Sv.y + Sv.z*Sv.z;\n      const denom = E*G - F*F;\n      const K = 0, H = 0;\n      const disc = Math.sqrt(Math.max(H*H - K, 0));\n      return { k1: H + disc, k2: H - disc, gaussian: K, mean: H };\n    },\n    tessellate(surface, uDivs = 20, vDivs = 20) {\n      const vertices = [], normals = [], uvs = [], indices = [];\n      for (let i = 0; i <= uDivs; i++) {\n        const u = i / uDivs;\n        for (let j = 0; j <= vDivs; j++) {\n          const v = j / vDivs;\n          vertices.push(this.evaluate(surface, u, v));\n          normals.push(this.normal(surface, u, v));\n          uvs.push({ u, v });\n        }\n      }\n      for (let i = 0; i < uDivs; i++) {\n        for (let j = 0; j < vDivs; j++) {\n          const idx = i * (vDivs + 1) + j;\n          indices.push(idx, idx + 1, idx + vDivs + 1);\n          indices.push(idx + 1, idx + vDivs + 2, idx + vDivs + 1);\n        }\n      }\n      return { vertices, normals, uvs, indices };\n    },\n    closestPoint(surface, point, tolerance = 0.0001, maxIter = 100) {\n      let u = 0.5, v = 0.5;\n      for (let iter = 0; iter < maxIter; iter++) {\n        const p = this.evaluate(surface, u, v);\n        const eps = 0.001;\n        const pu = this.evaluate(surface, Math.min(u + eps, 1), v);\n        const pv = this.evaluate(surface, u, Math.min(v + eps, 1));\n        const Su = { x: (pu.x - p.x) / eps, y: (pu.y - p.y) / eps, z: (pu.z - p.z) / eps };\n        const Sv = { x: (pv.x - p.x) / eps, y: (pv.y - p.y) / eps, z: (pv.z - p.z) / eps };\n        const r = { x: point.x - p.x, y: point.y - p.y, z: point.z - p.z };\n        const a11 = Su.x*Su.x + Su.y*Su.y + Su.z*Su.z;\n        const a12 = Su.x*Sv.x + Su.y*Sv.y + Su.z*Sv.z;\n        const a22 = Sv.x*Sv.x + Sv.y*Sv.y + Sv.z*Sv.z;\n        const b1 = r.x*Su.x + r.y*Su.y + r.z*Su.z;\n        const b2 = r.x*Sv.x + r.y*Sv.y + r.z*Sv.z;\n        const det = a11*a22 - a12*a12;\n        if (Math.abs(det) < 1e-12) break;\n        const du = (a22*b1 - a12*b2) / det;\n        const dv = (a11*b2 - a12*b1) / det;\n        u = Math.max(0, Math.min(1, u + du));\n        v = Math.max(0, Math.min(1, v + dv));\n        if (Math.abs(du) < tolerance && Math.abs(dv) < tolerance) break;\n      }\n      return { u, v, point: this.evaluate(surface, u, v) };\n    }\n  },\n  utils: {\n    uniformKnots(n, degree) {\n      const knots = [];\n      for (let i = 0; i <= degree; i++) knots.push(0);\n      for (let i = 1; i < n - degree; i++) knots.push(i / (n - degree));\n      for (let i = 0; i <= degree; i++) knots.push(1);\n      return knots;\n    },\n    createCircle(center, radius) {\n      const sqrt2 = Math.sqrt(2) / 2;\n      const controlPoints = [\n        { x: radius, y: 0, z: 0 }, { x: radius, y: radius, z: 0 },\n        { x: 0, y: radius, z: 0 }, { x: -radius, y: radius, z: 0 },\n        { x: -radius, y: 0, z: 0 }, { x: -radius, y: -radius, z: 0 },\n        { x: 0, y: -radius, z: 0 }, { x: radius, y: -radius, z: 0 },\n        { x: radius, y: 0, z: 0 }\n      ].map(p => ({ x: p.x + center.x, y: p.y + center.y, z: (p.z || 0) + (center.z || 0) }));\n      const weights = [1, sqrt2, 1, sqrt2, 1, sqrt2, 1, sqrt2, 1];\n      const knots = [0, 0, 0, 0.25, 0.25, 0.5, 0.5, 0.75, 0.75, 1, 1, 1];\n      return { degree: 2, controlPoints, weights, knots };\n    }\n  }\n}",
      "methods": [],
      "lines": 229
    },
    {
      "name": "PRISM_BREP_TESSELLATOR",
      "category": "engines/cad_cam",
      "refs": 35,
      "status": "FOUND",
      "code": "const PRISM_BREP_TESSELLATOR = {\n  version: '1.0.0',\n  courseBasis: 'MIT 18.433 - Computational Geometry',\n\n  /**\n   * Tessellate a complete B-Rep solid into triangle mesh\n   */\n  tessellateBrep(stepData, entityMap, options = {}) {\n    console.log('[B-Rep Tessellator] Starting tessellation...');\n    const startTime = performance.now();\n\n    const result = {\n      vertices: [],\n      normals: [],\n      triangles: [],\n      faceInfo: [],  // Per-triangle face mapping\n      statistics: {\n        faces: 0,\n        triangles: 0,\n        vertices: 0\n      }\n    };\n    // Find all ADVANCED_FACE entities\n    const faces = stepData.byType.get('ADVANCED_FACE') || [];\n\n    faces.forEach((face, faceIdx) => {\n      try {\n        const faceMesh = this.tessellateFace(face, entityMap, options);\n\n        // Add vertices and normals\n        const vertexOffset = result.vertices.length;\n        result.vertices.push(...faceMesh.vertices);\n        result.normals.push(...faceMesh.normals);\n\n        // Add triangles with offset\n        faceMesh.triangles.forEach(tri => {\n          result.triangles.push([\n            tri[0] + vertexOffset,\n            tri[1] + vertexOffset,\n            tri[2] + vertexOffset\n          ]);\n          result.faceInfo.push(faceIdx);\n        });\n\n        result.statistics.faces++;\n      } catch (err) {\n        console.warn(`[Tessellator] Failed to tessellate face #${face.id}:`, err.message);\n      }\n    });\n\n    result.statistics.triangles = result.triangles.length;\n    result.statistics.vertices = result.vertices.length;\n\n    const time = performance.now() - startTime;\n    console.log(`[B-Rep Tessellator] Generated ${result.statistics.triangles} triangles from ${result.statistics.faces} faces in ${time.toFixed(1)}ms`);\n\n    return result;\n  },\n  /**\n   * Tessellate a single ADVANCED_FACE\n   */\n  tessellateFace(face, entityMap, options = {}) {\n    const { resolution = 20 } = options;\n\n    // Get the surface geometry\n    const surfaceRef = face.args[2]?.ref;\n    const surface = entityMap.get(surfaceRef);\n\n    if (!surface) {\n      throw new Error(`Surface #${surfaceRef} not found`);\n    }\n    // Get the bounds (loops)\n    const boundsRefs = face.args[1];\n    const sameSense = face.args[3];\n\n    // Tessellate based on surface type\n    switch (surface.type) {\n      case 'PLANE':\n        return this.tessellatePlanarFace(face, surface, entityMap, options);\n\n      case 'CYLINDRICAL_SURFACE':\n        return this.tessellateCylindricalFace(face, surface, entityMap, options);\n\n      case 'CONICAL_SURFACE':\n        return this.tessellateConicalFace(face, surface, entityMap, options);\n\n      case 'SPHERICAL_SURFACE':\n        return this.tessellateSphericalFace(face, surface, entityMap, options);\n\n      case 'TOROIDAL_SURFACE':\n        return this.tessellateToroidalFace(face, surface, entityMap, options);\n\n      case 'B_SPLINE_SURFACE_WITH_KNOTS':\n      case 'B_SPLINE_SURFACE':\n      case 'RATIONAL_B_SPLINE_SURFACE':\n        return this.tessellateBSplineFace(face, surface, entityMap, options);\n\n      default:\n        console.warn(`[Tessellator] Unsupported surface type: ${surface.type}`);\n        return { vertices: [], normals: [], triangles: [] };\n    }\n  },\n  /**\n   * Tessellate a planar face\n   */\n  tessellatePlanarFace(face, surface, entityMap, options) {\n    const vertices = [];\n    const normals = [];\n    const triangles = [];\n\n    // Get plane placement\n    const placementRef = surface.args[1]?.ref;\n    const placement = this.getPlacement(placementRef, entityMap);\n\n    // Get the outer bound loop\n    const boundsRefs = face.args[1] || [];\n    const loopVertices = [];\n\n    boundsRefs.forEach(boundRef => {\n      const bound = entityMap.get(boundRef.ref);\n      if (!bound) return;\n\n      const loopRef = bound.args[1]?.ref;\n      const loop = entityMap.get(loopRef);\n      if (!loop || loop.type !== 'EDGE_LOOP') return;\n\n      const loopPoints = this.extractLoopVertices(loop, entityMap);\n      loopVertices.push(...loopPoints);\n    });\n\n    if (loopVertices.length < 3) {\n      return { vertices: [], normals: [], triangles: [] };\n    }\n    // Project to 2D for triangulation\n    const projected = this.projectTo2D(loopVertices, placement);\n\n    // Triangulate the polygon (ear clipping - MIT 18.433)\n    const triIndices = this.earClipTriangulate(projected);\n\n    // Build output\n    loopVertices.forEach(v => {\n      vertices.push(v);\n      normals.push({ ...placement.normal });\n    });\n\n    triIndices.forEach(tri => {\n      triangles.push(tri);\n    });\n\n    return { vertices, normals, triangles };\n  },\n  /**\n   * Tessellate a cylindrical surface face\n   */\n  tessellateCylindricalFace(face, surface, entityMap, options) {\n    const { resolution = 24 } = options;\n    const vertices = [];\n    const normals = [];\n    const triangles = [];\n\n    // Get cylinder parameters\n    const placementRef = surface.args[1]?.ref;\n    const placement = this.getPlacement(placementRef, entityMap);\n    const radius = surface.args[2];\n\n    // Get bounds to determine angular extent and height\n    const bounds = this.extractFaceBounds(face, entityMap);\n\n    // Default to full cylinder if bounds not determinable\n    const startAngle = bounds.startAngle ?? 0;\n    const endAngle = bounds.endAngle ?? (2 * Math.PI);\n    const minZ = bounds.minZ ?? 0;\n    const maxZ = bounds.maxZ ?? 10;\n\n    const angleRange = endAngle - startAngle;\n    const heightRange = maxZ - minZ;\n\n    const numCirc = Math.max(4, Math.ceil(resolution * angleRange / (2 * Math.PI)));\n    const numHeight = Math.max(2, Math.ceil(resolution * heightRange / 50));\n\n    // Generate vertices\n    for (let i = 0; i <= numCirc; i++) {\n      const angle = startAngle + (i / numCirc) * angleRange;\n      const cos = Math.cos(angle);\n      const sin = Math.sin(angle);\n\n      for (let j = 0; j <= numHeight; j++) {\n        const z = minZ + (j / numHeight) * heightRange;\n\n        // Local coordinates\n        const localX = radius * cos;\n        const localY = radius * sin;\n        const localZ = z;\n\n        // Transform to world coordinates\n        const world = this.transformPoint({ x: localX, y: localY, z: localZ }, placement);\n        vertices.push(world);\n\n        // Normal points radially outward\n        const normalLocal = { x: cos, y: sin, z: 0 };\n        const normal = this.transformVector(normalLocal, placement);\n        normals.push(normal);\n      }\n    }\n    // Generate triangles\n    for (let i = 0; i < numCirc; i++) {\n      for (let j = 0; j < numHeight; j++) {\n        const idx = i * (numHeight + 1) + j;\n        const next = (i + 1) * (numHeight + 1) + j;\n\n        triangles.push([idx, next, idx + 1]);\n        triangles.push([next, next + 1, idx + 1]);\n      }\n    }\n    return { vertices, normals, triangles };\n  },\n  /**\n   * Tessellate a conical surface face\n   */\n  tessellateConicalFace(face, surface, entityMap, options) {\n    const { resolution = 24 } = options;\n    const vertices = [];\n    const normals = [];\n    const triangles = [];\n\n    const placementRef = surface.args[1]?.ref;\n    const placement = this.getPlacement(placementRef, entityMap);\n    const baseRadius = surface.args[2];\n    const semiAngle = surface.args[3]; // Radians\n\n    // Cone expands/contracts as Z changes\n    const tanAngle = Math.tan(semiAngle);\n\n    const bounds = this.extractFaceBounds(face, entityMap);\n    const minZ = bounds.minZ ?? 0;\n    const maxZ = bounds.maxZ ?? 10;\n\n    const numCirc = Math.max(4, resolution);\n    const numHeight = Math.max(2, Math.ceil(resolution / 2));\n\n    for (let i = 0; i <= numCirc; i++) {\n      const angle = (i / numCirc) * 2 * Math.PI;\n      const cos = Math.cos(angle);\n      const sin = Math.sin(angle);\n\n      for (let j = 0; j <= numHeight; j++) {\n        const z = minZ + (j / numHeight) * (maxZ - minZ);\n        const r = baseRadius + z * tanAngle;\n\n        const localX = r * cos;\n        const localY = r * sin;\n\n        const world = this.transformPoint({ x: localX, y: localY, z }, placement);\n        vertices.push(world);\n\n        // Normal for cone\n        const normalLen = Math.sqrt(1 + tanAngle * tanAngle);\n        const normalLocal = {\n          x: cos / normalLen,\n          y: sin / normalLen,\n          z: -tanAngle / normalLen\n        };\n        const normal = this.transformVector(normalLocal, placement);\n        normals.push(normal);\n      }\n    }\n    // Triangles\n    for (let i = 0; i < numCirc; i++) {\n      for (let j = 0; j < numHeight; j++) {\n        const idx = i * (numHeight + 1) + j;\n        const next = (i + 1) * (numHeight + 1) + j;\n\n        triangles.push([idx, next, idx + 1]);\n        triangles.push([next, next + 1, idx + 1]);\n      }\n    }\n    return { vertices, normals, triangles };\n  },\n  /**\n   * Tessellate a spherical surface face\n   */\n  tessellateSphericalFace(face, surface, entityMap, options) {\n    const { resolution = 20 } = options;\n    const vertices = [];\n    const normals = [];\n    const triangles = [];\n\n    const placementRef = surface.args[1]?.ref;\n    const placement = this.getPlacement(placementRef, entityMap);\n    const radius = surface.args[2];\n\n    const numLat = Math.max(4, resolution);\n    const numLon = Math.max(8, resolution * 2);\n\n    for (let i = 0; i <= numLat; i++) {\n      const phi = (i / numLat) * Math.PI; // 0 to PI\n      const sinPhi = Math.sin(phi);\n      const cosPhi = Math.cos(phi);\n\n      for (let j = 0; j <= numLon; j++) {\n        const theta = (j / numLon) * 2 * Math.PI;\n        const sinTheta = Math.sin(theta);\n        const cosTheta = Math.cos(theta);\n\n        const localX = radius * sinPhi * cosTheta;\n        const localY = radius * sinPhi * sinTheta;\n        const localZ = radius * cosPhi;\n\n        const world = this.transformPoint({ x: localX, y: localY, z: localZ }, placement);\n        vertices.push(world);\n\n        const normalLocal = { x: sinPhi * cosTheta, y: sinPhi * sinTheta, z: cosPhi };\n        const normal = this.transformVector(normalLocal, placement);\n        normals.push(normal);\n      }\n    }\n    // Triangles\n    for (let i = 0; i < numLat; i++) {\n      for (let j = 0; j < numLon; j++) {\n        const idx = i * (numLon + 1) + j;\n        const next = (i + 1) * (numLon + 1) + j;\n\n        if (i > 0) {\n          triangles.push([idx, next, idx + 1]);\n        }\n        if (i < numLat - 1) {\n          triangles.push([next, next + 1, idx + 1]);\n        }\n      }\n    }\n    return { vertices, normals, triangles };\n  },\n  /**\n   * Tessellate a toroidal surface face (fillets/rounds)\n   */\n  tessellateToroidalFace(face, surface, entityMap, options) {\n    const { resolution = 16 } = options;\n    const vertices = [];\n    const normals = [];\n    const triangles = [];\n\n    const placementRef = surface.args[1]?.ref;\n    const placement = this.getPlacement(placementRef, entityMap);\n    const majorRadius = surface.args[2];\n    const minorRadius = surface.args[3];\n\n    const numMajor = Math.max(8, resolution);\n    const numMinor = Math.max(8, resolution);\n\n    for (let i = 0; i <= numMajor; i++) {\n      const theta = (i / numMajor) * 2 * Math.PI; // Around the tube\n      const cosTheta = Math.cos(theta);\n      const sinTheta = Math.sin(theta);\n\n      for (let j = 0; j <= numMinor; j++) {\n        const phi = (j / numMinor) * 2 * Math.PI; // Around the cross-section\n        const cosPhi = Math.cos(phi);\n        const sinPhi = Math.sin(phi);\n\n        // Point on torus\n        const x = (majorRadius + minorRadius * cosPhi) * cosTheta;\n        const y = (majorRadius + minorRadius * cosPhi) * sinTheta;\n        const z = minorRadius * sinPhi;\n\n        const world = this.transformPoint({ x, y, z }, placement);\n        vertices.push(world);\n\n        // Normal\n        const nx = cosPhi * cosTheta;\n        const ny = cosPhi * sinTheta;\n        const nz = sinPhi;\n        const normal = this.transformVector({ x: nx, y: ny, z: nz }, placement);\n        normals.push(normal);\n      }\n    }\n    // Triangles\n    for (let i = 0; i < numMajor; i++) {\n      for (let j = 0; j < numMinor; j++) {\n        const idx = i * (numMinor + 1) + j;\n        const next = (i + 1) * (numMinor + 1) + j;\n\n        triangles.push([idx, next, idx + 1]);\n        triangles.push([next, next + 1, idx + 1]);\n      }\n    }\n    return { vertices, normals, triangles };\n  },\n  /**\n   * Tessellate a B-spline surface face\n   */\n  tessellateBSplineFace(face, surface, entityMap, options) {\n    // Extract B-spline parameters from entity\n    const degreeU = surface.args[1];\n    const degreeV = surface.args[2];\n    const controlPointRefs = surface.args[3]; // 2D array of refs\n\n    // Build control point grid\n    const controlGrid = [];\n    if (Array.isArray(controlPointRefs)) {\n      controlPointRefs.forEach(row => {\n        const gridRow = [];\n        if (Array.isArray(row)) {\n          row.forEach(ref => {\n            const pt = entityMap.get(ref.ref);\n            if (pt && pt.args && pt.args[1]) {\n              const coords = pt.args[1];\n              gridRow.push({\n                x: coords[0] || 0,\n                y: coords[1] || 0,\n                z: coords[2] || 0\n              });\n            }\n          });\n        }\n        if (gridRow.length > 0) {\n          controlGrid.push(gridRow);\n        }\n      });\n    }\n    if (controlGrid.length < 2 || controlGrid[0].length < 2) {\n      return { vertices: [], normals: [], triangles: [] };\n    }\n    // Get knots\n    const knotsU = surface.args[6] || this.generateUniformKnots(controlGrid.length, degreeU);\n    const knotsV = surface.args[7] || this.generateUniformKnots(controlGrid[0].length, degreeV);\n\n    // Get weights for NURBS\n    const weights = null; // Would extract from RATIONAL_B_SPLINE_SURFACE\n\n    // Use NURBS evaluator for tessellation\n    return PRISM_NURBS_EVALUATOR.tessellateSurface(\n      controlGrid, weights, knotsU, knotsV, degreeU, degreeV, options\n    );\n  },\n  /**\n   * Generate uniform knot vector\n   */\n  generateUniformKnots(n, degree) {\n    const knots = [];\n    const numKnots = n + degree + 1;\n\n    for (let i = 0; i < numKnots; i++) {\n      if (i < degree + 1) {\n        knots.push(0);\n      } else if (i >= numKnots - degree - 1) {\n        knots.push(1);\n      } else {\n        knots.push((i - degree) / (numKnots - 2 * degree - 1));\n      }\n    }\n    return knots;\n  },\n  /**\n   * Get placement transformation from AXIS2_PLACEMENT_3D\n   */\n  getPlacement(placementRef, entityMap) {\n    const defaultPlacement = {\n      origin: { x: 0, y: 0, z: 0 },\n      axis: { x: 0, y: 0, z: 1 },\n      refDir: { x: 1, y: 0, z: 0 },\n      normal: { x: 0, y: 0, z: 1 }\n    };\n    if (!placementRef) return defaultPlacement;\n\n    const placement = entityMap.get(placementRef);\n    if (!placement || placement.type !== 'AXIS2_PLACEMENT_3D') {\n      return defaultPlacement;\n    }\n    // Get origin\n    const originRef = placement.args[1]?.ref;\n    const originEnt = entityMap.get(originRef);\n    const origin = originEnt?.args?.[1] || [0, 0, 0];\n\n    // Get axis (Z direction)\n    const axisRef = placement.args[2]?.ref;\n    const axisEnt = entityMap.get(axisRef);\n    const axis = axisEnt?.args?.[1] || [0, 0, 1];\n\n    // Get reference direction (X direction)\n    const refDirRef = placement.args[3]?.ref;\n    const refDirEnt = entityMap.get(refDirRef);\n    const refDir = refDirEnt?.args?.[1] || [1, 0, 0];\n\n    return {\n      origin: { x: origin[0], y: origin[1], z: origin[2] },\n      axis: { x: axis[0], y: axis[1], z: axis[2] },\n      refDir: { x: refDir[0], y: refDir[1], z: refDir[2] },\n      normal: { x: axis[0], y: axis[1], z: axis[2] }\n    };\n  },\n  /**\n   * Transform point from local to world coordinates\n   * MIT 18.06: Linear transformations, rotation matrices\n   */\n  transformPoint(local, placement) {\n    // Build rotation matrix from axis and refDir\n    const zAxis = this.normalize(placement.axis);\n    const xAxis = this.normalize(placement.refDir);\n    const yAxis = this.cross(zAxis, xAxis);\n\n    // Apply rotation then translation\n    return {\n      x: placement.origin.x + local.x * xAxis.x + local.y * yAxis.x + local.z * zAxis.x,\n      y: placement.origin.y + local.x * xAxis.y + local.y * yAxis.y + local.z * zAxis.y,\n      z: placement.origin.z + local.x * xAxis.z + local.y * yAxis.z + local.z * zAxis.z\n    };\n  },\n  /**\n   * Transform vector (no translation, just rotation)\n   */\n  transformVector(local, placement) {\n    const zAxis = this.normalize(placement.axis);\n    const xAxis = this.normalize(placement.refDir);\n    const yAxis = this.cross(zAxis, xAxis);\n\n    const result = {\n      x: local.x * xAxis.x + local.y * yAxis.x + local.z * zAxis.x,\n      y: local.x * xAxis.y + local.y * yAxis.y + local.z * zAxis.y,\n      z: local.x * xAxis.z + local.y * yAxis.z + local.z * zAxis.z\n    };\n    return this.normalize(result);\n  },\n  /**\n   * Extract face bounds from edge loops\n   */\n  extractFaceBounds(face, entityMap) {\n    const bounds = {\n      startAngle: 0,\n      endAngle: 2 * Math.PI,\n      minZ: 0,\n      maxZ: 10\n    };\n    // Would parse FACE_BOUND/EDGE_LOOP to get precise bounds\n    // For now, return defaults\n\n    return bounds;\n  },\n  /**\n   * Extract vertices from edge loop\n   */\n  extractLoopVertices(loop, entityMap) {\n    const vertices = [];\n\n    const edgeRefs = loop.args[1] || [];\n    edgeRefs.forEach(ref => {\n      const orientedEdge = entityMap.get(ref.ref);\n      if (!orientedEdge) return;\n\n      const edgeRef = orientedEdge.args[3]?.ref;\n      const edge = entityMap.get(edgeRef);\n      if (!edge) return;\n\n      // Get start vertex\n      const startVertRef = edge.args[1]?.ref;\n      const startVert = entityMap.get(startVertRef);\n      if (startVert) {\n        const pointRef = startVert.args[1]?.ref;\n        const point = entityMap.get(pointRef);\n        if (point && point.args && point.args[1]) {\n          const coords = point.args[1];\n          vertices.push({\n            x: coords[0],\n            y: coords[1],\n            z: coords[2] || 0\n          });\n        }\n      }\n    });\n\n    return vertices;\n  },\n  /**\n   * Project 3D points to 2D using placement as projection plane\n   */\n  projectTo2D(points3d, placement) {\n    const zAxis = this.normalize(placement.axis);\n    const xAxis = this.normalize(placement.refDir);\n    const yAxis = this.cross(zAxis, xAxis);\n\n    return points3d.map(p => {\n      const rel = {\n        x: p.x - placement.origin.x,\n        y: p.y - placement.origin.y,\n        z: p.z - placement.origin.z\n      };\n      return {\n        x: rel.x * xAxis.x + rel.y * xAxis.y + rel.z * xAxis.z,\n        y: rel.x * yAxis.x + rel.y * yAxis.y + rel.z * yAxis.z\n      };\n    });\n  },\n  /**\n   * Ear clipping polygon triangulation\n   * MIT 18.433: Computational Geometry - O(n\u00b2) simple polygon triangulation\n   */\n  earClipTriangulate(polygon2d) {\n    const triangles = [];\n    const n = polygon2d.length;\n\n    if (n < 3) return triangles;\n    if (n === 3) return [[0, 1, 2]];\n\n    // Create index array\n    const indices = [];\n    for (let i = 0; i < n; i++) indices.push(i);\n\n    // Determine winding order\n    const area = this.signedArea(polygon2d);\n    const ccw = area > 0;\n\n    let remaining = n;\n    let i = 0;\n    let failCount = 0;\n\n    while (remaining > 3 && failCount < remaining) {\n      const prev = indices[(i - 1 + remaining) % remaining];\n      const curr = indices[i % remaining];\n      const next = indices[(i + 1) % remaining];\n\n      const p0 = polygon2d[prev];\n      const p1 = polygon2d[curr];\n      const p2 = polygon2d[next];\n\n      // Check if this is an ear\n      if (this.isEar(polygon2d, indices, prev, curr, next, ccw)) {\n        triangles.push([prev, curr, next]);\n\n        // Remove curr from indices\n        indices.splice(i % remaining, 1);\n        remaining--;\n        failCount = 0;\n\n        if (i >= remaining) i = 0;\n      } else {\n        i++;\n        failCount++;\n      }\n    }\n    // Last triangle\n    if (remaining === 3) {\n      triangles.push([indices[0], indices[1], indices[2]]);\n    }\n    return triangles;\n  },\n  /**\n   * Check if vertex is an ear (can be clipped)\n   */\n  isEar(polygon, indices, prev, curr, next, ccw) {\n    const p0 = polygon[prev];\n    const p1 = polygon[curr];\n    const p2 = polygon[next];\n\n    // Check convexity\n    const cross = (p1.x - p0.x) * (p2.y - p0.y) - (p1.y - p0.y) * (p2.x - p0.x);\n    if ((ccw && cross <= 0) || (!ccw && cross >= 0)) {\n      return false;\n    }\n    // Check that no other vertices are inside the triangle\n    for (let i = 0; i < indices.length; i++) {\n      const idx = indices[i];\n      if (idx === prev || idx === curr || idx === next) continue;\n\n      if (this.pointInTriangle(polygon[idx], p0, p1, p2)) {\n        return false;\n      }\n    }\n    return true;\n  },\n  /**\n   * Point in triangle test using barycentric coordinates\n   */\n  pointInTriangle(p, a, b, c) {\n    const v0 = { x: c.x - a.x, y: c.y - a.y };\n    const v1 = { x: b.x - a.x, y: b.y - a.y };\n    const v2 = { x: p.x - a.x, y: p.y - a.y };\n\n    const dot00 = v0.x * v0.x + v0.y * v0.y;\n    const dot01 = v0.x * v1.x + v0.y * v1.y;\n    const dot02 = v0.x * v2.x + v0.y * v2.y;\n    const dot11 = v1.x * v1.x + v1.y * v1.y;\n    const dot12 = v1.x * v2.x + v1.y * v2.y;\n\n    const invDenom = 1 / (dot00 * dot11 - dot01 * dot01);\n    const u = (dot11 * dot02 - dot01 * dot12) * invDenom;\n    const v = (dot00 * dot12 - dot01 * dot02) * invDenom;\n\n    return (u >= 0) && (v >= 0) && (u + v < 1);\n  },\n  /**\n   * Calculate signed area of polygon\n   */\n  signedArea(polygon) {\n    let area = 0;\n    const n = polygon.length;\n\n    for (let i = 0; i < n; i++) {\n      const j = (i + 1) % n;\n      area += polygon[i].x * polygon[j].y;\n      area -= polygon[j].x * polygon[i].y;\n    }\n    return area / 2;\n  },\n  // Vector utilities\n  normalize(v) {\n    const len = Math.sqrt(v.x * v.x + v.y * v.y + v.z * v.z);\n    if (len < 1e-10) return { x: 0, y: 0, z: 1 };\n    return { x: v.x / len, y: v.y / len, z: v.z / len };\n  },\n  cross(a, b) {\n    return {\n      x: a.y * b.z - a.z * b.y,\n      y: a.z * b.x - a.x * b.z,\n      z: a.x * b.y - a.y * b.x\n    };\n  }\n}",
      "methods": [],
      "lines": 716
    },
    {
      "name": "PRISM_MULTIAXIS_TOOLPATH_ENGINE",
      "category": "engines/cad_cam",
      "refs": 58,
      "status": "FOUND",
      "code": "const PRISM_MULTIAXIS_TOOLPATH_ENGINE = {\n    version: '1.0.0',\n    authority: 'PRISM_MULTIAXIS_TOOLPATH_ENGINE',\n\n    // 1.1 Tool Axis Control Strategies\n\n    toolAxisControl: {\n        /**\n         * Calculate tool axis from surface normal with lead/lag/tilt\n         * @param {Object} normal - Surface normal {x, y, z}\n         * @param {Object} feedDir - Feed direction {x, y, z}\n         * @param {Object} params - {leadAngle, lagAngle, tiltAngle} in radians\n         * @returns {Object} Tool axis {i, j, k}\n         */\n        fromNormalWithAngles: function(normal, feedDir, params) {\n            const { leadAngle = 0, lagAngle = 0, tiltAngle = 0 } = params || {};\n\n            // Normalize inputs\n            const n = PRISM_MULTIAXIS_TOOLPATH_ENGINE._normalize(normal);\n            const f = PRISM_MULTIAXIS_TOOLPATH_ENGINE._normalize(feedDir);\n\n            // Calculate side direction (perpendicular to feed and normal)\n            const side = PRISM_MULTIAXIS_TOOLPATH_ENGINE._cross(f, n);\n            const sideNorm = PRISM_MULTIAXIS_TOOLPATH_ENGINE._normalize(side);\n\n            // Start with tool axis = surface normal\n            let axis = { ...n };\n\n            // Apply lead angle (rotation around side vector)\n            if (Math.abs(leadAngle) > PRISM_CONSTANTS.TOLERANCE.ANGLE) {\n                axis = this._rotateAroundAxis(axis, sideNorm, leadAngle);\n            }\n            // Apply lag angle (negative lead)\n            if (Math.abs(lagAngle) > PRISM_CONSTANTS.TOLERANCE.ANGLE) {\n                axis = this._rotateAroundAxis(axis, sideNorm, -lagAngle);\n            }\n            // Apply tilt angle (rotation around feed direction)\n            if (Math.abs(tiltAngle) > PRISM_CONSTANTS.TOLERANCE.ANGLE) {\n                axis = this._rotateAroundAxis(axis, f, tiltAngle);\n            }\n            return PRISM_MULTIAXIS_TOOLPATH_ENGINE._normalize(axis);\n        },\n        /**\n         * Rotate vector around axis using Rodrigues formula\n         */\n        _rotateAroundAxis: function(vec, axis, angle) {\n            const c = Math.cos(angle);\n            const s = Math.sin(angle);\n            const k = axis;\n\n            // v_rot = v*cos(\u03b8) + (k\u00d7v)*sin(\u03b8) + k*(k\u00b7v)*(1-cos(\u03b8))\n            const cross = PRISM_MULTIAXIS_TOOLPATH_ENGINE._cross(k, vec);\n            const dot = k.x * vec.x + k.y * vec.y + k.z * vec.z;\n\n            return {\n                x: vec.x * c + cross.x * s + k.x * dot * (1 - c),\n                y: vec.y * c + cross.y * s + k.y * dot * (1 - c),\n                z: vec.z * c + cross.z * s + k.z * dot * (1 - c)\n            };\n        },\n        /**\n         * Interpolate tool axis between two orientations\n         * Uses spherical linear interpolation (SLERP)\n         */\n        slerp: function(axis1, axis2, t) {\n            // Normalize inputs\n            const a1 = PRISM_MULTIAXIS_TOOLPATH_ENGINE._normalize(axis1);\n            const a2 = PRISM_MULTIAXIS_TOOLPATH_ENGINE._normalize(axis2);\n\n            // Calculate angle between axes\n            let dot = a1.x * a2.x + a1.y * a2.y + a1.z * a2.z;\n\n            // Handle parallel/anti-parallel cases\n            if (Math.abs(dot) > 0.9999) {\n                // Linear interpolation for near-parallel\n                return PRISM_MULTIAXIS_TOOLPATH_ENGINE._normalize({\n                    x: a1.x + t * (a2.x - a1.x),\n                    y: a1.y + t * (a2.y - a1.y),\n                    z: a1.z + t * (a2.z - a1.z)\n                });\n            }\n            // Ensure shortest path\n            if (dot < 0) {\n                dot = -dot;\n                a2.x = -a2.x;\n                a2.y = -a2.y;\n                a2.z = -a2.z;\n            }\n            const theta = Math.acos(Math.min(1, Math.max(-1, dot)));\n            const sinTheta = Math.sin(theta);\n\n            if (sinTheta < PRISM_CONSTANTS.TOLERANCE.ZERO) {\n                return a1;\n            }\n            const s1 = Math.sin((1 - t) * theta) / sinTheta;\n            const s2 = Math.sin(t * theta) / sinTheta;\n\n            return PRISM_MULTIAXIS_TOOLPATH_ENGINE._normalize({\n                x: a1.x * s1 + a2.x * s2,\n                y: a1.y * s1 + a2.y * s2,\n                z: a1.z * s1 + a2.z * s2\n            });\n        },\n        /**\n         * Smooth tool axis along toolpath to avoid sudden changes\n         * Uses moving average with Gaussian weights\n         */\n        smoothToolAxis: function(toolpath, windowSize = 5) {\n            if (!toolpath || toolpath.length < 3) return toolpath;\n\n            const smoothed = [];\n            const halfWindow = Math.floor(windowSize / 2);\n\n            // Generate Gaussian weights\n            const sigma = windowSize / 4;\n            const weights = [];\n            let weightSum = 0;\n\n            for (let i = -halfWindow; i <= halfWindow; i++) {\n                const w = Math.exp(-(i * i) / (2 * sigma * sigma));\n                weights.push(w);\n                weightSum += w;\n            }\n            // Normalize weights\n            for (let i = 0; i < weights.length; i++) {\n                weights[i] /= weightSum;\n            }\n            // Apply smoothing\n            for (let i = 0; i < toolpath.length; i++) {\n                const point = { ...toolpath[i] };\n\n                if (point.axis) {\n                    let avgAxis = { x: 0, y: 0, z: 0 };\n                    let totalWeight = 0;\n\n                    for (let j = -halfWindow; j <= halfWindow; j++) {\n                        const idx = Math.max(0, Math.min(toolpath.length - 1, i + j));\n                        const neighborAxis = toolpath[idx].axis;\n\n                        if (neighborAxis) {\n                            const w = weights[j + halfWindow];\n                            avgAxis.x += neighborAxis.i * w;\n                            avgAxis.y += neighborAxis.j * w;\n                            avgAxis.z += neighborAxis.k * w;\n                            totalWeight += w;\n                        }\n                    }\n                    if (totalWeight > 0) {\n                        avgAxis = PRISM_MULTIAXIS_TOOLPATH_ENGINE._normalize({\n                            x: avgAxis.x / totalWeight,\n                            y: avgAxis.y / totalWeight,\n                            z: avgAxis.z / totalWeight\n                        });\n\n                        point.axis = { i: avgAxis.x, j: avgAxis.y, k: avgAxis.z };\n                    }\n                }\n                smoothed.push(point);\n            }\n            return smoothed;\n        }\n    },\n    // 1.2 5-Axis Simultaneous Strategies\n\n    strategies: {\n        /**\n         * Generate swarf (flank) milling toolpath for ruled surfaces\n         * Tool side cuts along ruling lines\n         */\n        swarf: function(surface, params) {\n            const {\n                toolDiameter,\n                toolLength,\n                stepover,\n                tolerance = 0.01,\n                climbMilling = true\n            } = params;\n\n            const toolRadius = toolDiameter / 2;\n            const passes = [];\n\n            // Extract ruling lines from surface\n            const rulings = PRISM_MULTIAXIS_TOOLPATH_ENGINE._extractRulings(surface, stepover);\n\n            for (let i = 0; i < rulings.length; i++) {\n                const ruling = rulings[i];\n                const pass = [];\n\n                // Calculate tool position along each ruling\n                for (const point of ruling.points) {\n                    // Tool axis aligned with ruling direction\n                    const rulingDir = PRISM_MULTIAXIS_TOOLPATH_ENGINE._normalize({\n                        x: ruling.end.x - ruling.start.x,\n                        y: ruling.end.y - ruling.start.y,\n                        z: ruling.end.z - ruling.start.z\n                    });\n\n                    // Offset tool center from surface by tool radius\n                    const normal = point.normal || { x: 0, y: 0, z: 1 };\n                    const sideDir = PRISM_MULTIAXIS_TOOLPATH_ENGINE._cross(rulingDir, normal);\n                    const sideNorm = PRISM_MULTIAXIS_TOOLPATH_ENGINE._normalize(sideDir);\n\n                    const offset = climbMilling ? toolRadius : -toolRadius;\n\n                    pass.push({\n                        x: point.x + sideNorm.x * offset,\n                        y: point.y + sideNorm.y * offset,\n                        z: point.z + sideNorm.z * offset,\n                        axis: { i: rulingDir.x, j: rulingDir.y, k: rulingDir.z },\n                        type: 'swarf',\n                        engagement: Math.min(point.rulingLength || toolLength, toolLength)\n                    });\n                }\n                passes.push({\n                    type: 'swarf_pass',\n                    index: i,\n                    points: pass\n                });\n            }\n            return {\n                type: 'swarf',\n                strategy: '5axis_swarf',\n                passes,\n                params: { toolDiameter, toolLength, stepover, tolerance }\n            };\n        },\n        /**\n         * Generate 5-axis contour with tool axis following surface normal\n         */\n        surfaceNormalContour: function(surface, params) {\n            const {\n                toolDiameter,\n                stepover,\n                leadAngle = 0,\n                tiltAngle = 0,\n                tolerance = 0.01\n            } = params;\n\n            const toolRadius = toolDiameter / 2;\n            const passes = [];\n\n            // Get surface bounds\n            const bounds = PRISM_MULTIAXIS_TOOLPATH_ENGINE._getSurfaceBounds(surface);\n            const numPasses = Math.ceil((bounds.vMax - bounds.vMin) / stepover);\n\n            for (let p = 0; p <= numPasses; p++) {\n                const v = bounds.vMin + (p / numPasses) * (bounds.vMax - bounds.vMin);\n                const pass = [];\n\n                // Sample along u direction\n                const numSamples = Math.ceil((bounds.uMax - bounds.uMin) * 100);\n\n                for (let s = 0; s <= numSamples; s++) {\n                    const u = bounds.uMin + (s / numSamples) * (bounds.uMax - bounds.uMin);\n\n                    // Evaluate surface\n                    const point = PRISM_MULTIAXIS_TOOLPATH_ENGINE._evaluateSurface(surface, u, v);\n                    const normal = PRISM_MULTIAXIS_TOOLPATH_ENGINE._surfaceNormal(surface, u, v);\n\n                    // Calculate feed direction (tangent along u)\n                    const feedDir = PRISM_MULTIAXIS_TOOLPATH_ENGINE._surfaceTangentU(surface, u, v);\n\n                    // Calculate tool axis with lead/tilt\n                    const axis = PRISM_MULTIAXIS_TOOLPATH_ENGINE.toolAxisControl.fromNormalWithAngles(\n                        normal, feedDir, { leadAngle, tiltAngle }\n                    );\n\n                    // Offset tool center\n                    pass.push({\n                        x: point.x + normal.x * toolRadius,\n                        y: point.y + normal.y * toolRadius,\n                        z: point.z + normal.z * toolRadius,\n                        axis: { i: axis.x, j: axis.y, k: axis.z },\n                        u, v,\n                        type: '5axis_contour'\n                    });\n                }\n                passes.push({\n                    type: '5axis_contour_pass',\n                    v,\n                    points: pass\n                });\n            }\n            return {\n                type: '5axis_surface_normal',\n                strategy: '5axis_contour',\n                passes,\n                params\n            };\n        },\n        /**\n         * Generate 5-axis flowline machining\n         * Tool follows surface flowlines (principal curvature directions)\n         */\n        flowline: function(surface, params) {\n            const {\n                toolDiameter,\n                stepover,\n                direction = 'max_curvature', // 'max_curvature', 'min_curvature', 'iso_u', 'iso_v'\n                leadAngle = PRISM_CONSTANTS.PHYSICS.DEG_TO_RAD * 3\n            } = params;\n\n            const toolRadius = toolDiameter / 2;\n            const passes = [];\n\n            // Get surface bounds\n            const bounds = PRISM_MULTIAXIS_TOOLPATH_ENGINE._getSurfaceBounds(surface);\n\n            // Generate seed points\n            const numSeeds = Math.ceil((bounds.vMax - bounds.vMin) / stepover);\n\n            for (let s = 0; s <= numSeeds; s++) {\n                const seedV = bounds.vMin + (s / numSeeds) * (bounds.vMax - bounds.vMin);\n                const seedU = bounds.uMin;\n\n                // Trace flowline from seed\n                const flowline = PRISM_MULTIAXIS_TOOLPATH_ENGINE._traceFlowline(\n                    surface, seedU, seedV, direction, bounds\n                );\n\n                const pass = [];\n\n                for (const point of flowline) {\n                    const normal = PRISM_MULTIAXIS_TOOLPATH_ENGINE._surfaceNormal(surface, point.u, point.v);\n                    const feedDir = point.tangent || { x: 1, y: 0, z: 0 };\n\n                    const axis = PRISM_MULTIAXIS_TOOLPATH_ENGINE.toolAxisControl.fromNormalWithAngles(\n                        normal, feedDir, { leadAngle }\n                    );\n\n                    pass.push({\n                        x: point.x + normal.x * toolRadius,\n                        y: point.y + normal.y * toolRadius,\n                        z: point.z + normal.z * toolRadius,\n                        axis: { i: axis.x, j: axis.y, k: axis.z },\n                        type: 'flowline'\n                    });\n                }\n                if (pass.length > 2) {\n                    passes.push({\n                        type: 'flowline_pass',\n                        index: s,\n                        points: pass\n                    });\n                }\n            }\n            return {\n                type: '5axis_flowline',\n                strategy: 'flowline',\n                direction,\n                passes,\n                params\n            };\n        }\n    },\n    // 1.3 Gouge Detection and Avoidance\n\n    gougeAvoidance: {\n        /**\n         * Check for gouging at a single point\n         * @returns {Object} {gouges: boolean, depth: number, correctedAxis: Object}\n         */\n        checkPoint: function(position, axis, toolGeometry, surface, tolerance) {\n            const { toolDiameter, cornerRadius = 0, type = 'ball' } = toolGeometry;\n            const toolRadius = toolDiameter / 2;\n\n            // Sample points on tool surface\n            const checkPoints = this._getToolCheckPoints(position, axis, toolGeometry);\n            let maxGougeDepth = 0;\n            let gougeDetected = false;\n\n            for (const checkPoint of checkPoints) {\n                // Find closest point on surface\n                const surfacePoint = PRISM_MULTIAXIS_TOOLPATH_ENGINE._closestPointOnSurface(\n                    surface, checkPoint\n                );\n\n                if (surfacePoint) {\n                    // Calculate signed distance (negative = inside surface = gouge)\n                    const dist = PRISM_MULTIAXIS_TOOLPATH_ENGINE._signedDistance(\n                        checkPoint, surfacePoint, surface\n                    );\n\n                    if (dist < -tolerance) {\n                        gougeDetected = true;\n                        maxGougeDepth = Math.max(maxGougeDepth, Math.abs(dist));\n                    }\n                }\n            }\n            return {\n                gouges: gougeDetected,\n                depth: maxGougeDepth,\n                correctedAxis: gougeDetected ?\n                    this._correctAxis(position, axis, toolGeometry, surface, maxGougeDepth) :\n                    axis\n            };\n        },\n        /**\n         * Get check points on tool surface for gouge detection\n         */\n        _getToolCheckPoints: function(position, axis, toolGeometry) {\n            const { toolDiameter, type = 'ball' } = toolGeometry;\n            const toolRadius = toolDiameter / 2;\n            const points = [];\n\n            // Create local coordinate system\n            const axisNorm = PRISM_MULTIAXIS_TOOLPATH_ENGINE._normalize(axis);\n            const perpX = PRISM_MULTIAXIS_TOOLPATH_ENGINE._perpendicular(axisNorm);\n            const perpY = PRISM_MULTIAXIS_TOOLPATH_ENGINE._cross(axisNorm, perpX);\n\n            if (type === 'ball') {\n                // Sample hemisphere\n                const numRadial = 8;\n                const numAxial = 4;\n\n                for (let i = 0; i < numRadial; i++) {\n                    const angle = (i / numRadial) * Math.PI * 2;\n\n                    for (let j = 0; j <= numAxial; j++) {\n                        const phi = (j / numAxial) * Math.PI / 2;\n                        const r = toolRadius * Math.sin(phi);\n                        const z = toolRadius * (1 - Math.cos(phi));\n\n                        points.push({\n                            x: position.x + perpX.x * r * Math.cos(angle) + perpY.x * r * Math.sin(angle) - axisNorm.x * z,\n                            y: position.y + perpX.y * r * Math.cos(angle) + perpY.y * r * Math.sin(angle) - axisNorm.y * z,\n                            z: position.z + perpX.z * r * Math.cos(angle) + perpY.z * r * Math.sin(angle) - axisNorm.z * z\n                        });\n                    }\n                }\n            } else {\n                // Flat end mill - check edge points\n                const numPoints = 16;\n                for (let i = 0; i < numPoints; i++) {\n                    const angle = (i / numPoints) * Math.PI * 2;\n                    points.push({\n                        x: position.x + perpX.x * toolRadius * Math.cos(angle) + perpY.x * toolRadius * Math.sin(angle),\n                        y: position.y + perpX.y * toolRadius * Math.cos(angle) + perpY.y * toolRadius * Math.sin(angle),\n                        z: position.z + perpX.z * toolRadius * Math.cos(angle) + perpY.z * toolRadius * Math.sin(angle)\n                    });\n                }\n            }\n            return points;\n        },\n        /**\n         * Correct tool axis to avoid gouging\n         */\n        _correctAxis: function(position, axis, toolGeometry, surface, gougeDepth) {\n            // Simple correction: tilt tool away from gouge\n            // More sophisticated methods could use optimization\n\n            const normal = PRISM_MULTIAXIS_TOOLPATH_ENGINE._surfaceNormalAtPoint(surface, position);\n            const tiltAngle = Math.asin(Math.min(1, gougeDepth / (toolGeometry.toolDiameter / 2)));\n\n            return PRISM_MULTIAXIS_TOOLPATH_ENGINE.toolAxisControl._rotateAroundAxis(\n                PRISM_MULTIAXIS_TOOLPATH_ENGINE._normalize(axis),\n                PRISM_MULTIAXIS_TOOLPATH_ENGINE._perpendicular(normal),\n                tiltAngle\n            );\n        },\n        /**\n         * Check entire toolpath for gouging\n         */\n        checkToolpath: function(toolpath, toolGeometry, surface, tolerance = 0.01) {\n            const issues = [];\n            const corrected = [];\n\n            for (let i = 0; i < toolpath.length; i++) {\n                const point = toolpath[i];\n                const axis = point.axis || { i: 0, j: 0, k: 1 };\n\n                const check = this.checkPoint(\n                    { x: point.x, y: point.y, z: point.z },\n                    { x: axis.i, y: axis.j, z: axis.k },\n                    toolGeometry,\n                    surface,\n                    tolerance\n                );\n\n                if (check.gouges) {\n                    issues.push({\n                        index: i,\n                        position: { x: point.x, y: point.y, z: point.z },\n                        gougeDepth: check.depth\n                    });\n\n                    corrected.push({\n                        ...point,\n                        axis: { i: check.correctedAxis.x, j: check.correctedAxis.y, k: check.correctedAxis.z },\n                        gougeCorrected: true\n                    });\n                } else {\n                    corrected.push(point);\n                }\n            }\n            return {\n                valid: issues.length === 0,\n                issues,\n                correctedToolpath: corrected\n            };\n        }\n    },\n    // 1.4 Utility Functions\n\n    _normalize: function(v) {\n        const len = Math.sqrt(v.x * v.x + v.y * v.y + v.z * v.z);\n        if (len < PRISM_CONSTANTS.TOLERANCE.ZERO) return { x: 0, y: 0, z: 1 };\n        return { x: v.x / len, y: v.y / len, z: v.z / len };\n    },\n    _cross: function(a, b) {\n        return {\n            x: a.y * b.z - a.z * b.y,\n            y: a.z * b.x - a.x * b.z,\n            z: a.x * b.y - a.y * b.x\n        };\n    },\n    _perpendicular: function(v) {\n        // Find a vector perpendicular to v\n        if (Math.abs(v.x) < 0.9) {\n            return this._normalize(this._cross(v, { x: 1, y: 0, z: 0 }));\n        }\n        return this._normalize(this._cross(v, { x: 0, y: 1, z: 0 }));\n    },\n    _extractRulings: function(surface, stepover) {\n        // Extract ruling lines from ruled surface\n        const rulings = [];\n        const numRulings = Math.ceil(1 / stepover * 10);\n\n        for (let i = 0; i <= numRulings; i++) {\n            const v = i / numRulings;\n            const start = this._evaluateSurface(surface, 0, v);\n            const end = this._evaluateSurface(surface, 1, v);\n\n            const points = [];\n            const numPoints = 20;\n\n            for (let j = 0; j <= numPoints; j++) {\n                const u = j / numPoints;\n                const point = this._evaluateSurface(surface, u, v);\n                point.normal = this._surfaceNormal(surface, u, v);\n                point.rulingLength = Math.sqrt(\n                    (end.x - start.x) ** 2 + (end.y - start.y) ** 2 + (end.z - start.z) ** 2\n                );\n                points.push(point);\n            }\n            rulings.push({ start, end, points, v });\n        }\n        return rulings;\n    },\n    _getSurfaceBounds: function(surface) {\n        return surface.bounds || { uMin: 0, uMax: 1, vMin: 0, vMax: 1 };\n    },\n    _evaluateSurface: function(surface, u, v) {\n        // Use gateway if available, otherwise basic evaluation\n        if (typeof PRISM_GATEWAY !== 'undefined' && PRISM_GATEWAY.hasCapability('geometry.nurbs.evaluate')) {\n            return PRISM_GATEWAY.call('geometry.nurbs.evaluate', surface, u, v);\n        }\n        // Basic plane/bilinear evaluation\n        if (surface.type === 'plane') {\n            return {\n                x: surface.origin.x + u * (surface.uDir?.x || 100) + v * (surface.vDir?.x || 0),\n                y: surface.origin.y + u * (surface.uDir?.y || 0) + v * (surface.vDir?.y || 100),\n                z: surface.origin.z + u * (surface.uDir?.z || 0) + v * (surface.vDir?.z || 0)\n            };\n        }\n        return { x: u * 100, y: v * 100, z: 0 };\n    },\n    _surfaceNormal: function(surface, u, v) {\n        if (surface.type === 'plane') {\n            return surface.normal || { x: 0, y: 0, z: 1 };\n        }\n        // Numerical normal\n        const eps = 0.001;\n        const p = this._evaluateSurface(surface, u, v);\n        const pu = this._evaluateSurface(surface, Math.min(u + eps, 1), v);\n        const pv = this._evaluateSurface(surface, u, Math.min(v + eps, 1));\n\n        const du = { x: pu.x - p.x, y: pu.y - p.y, z: pu.z - p.z };\n        const dv = { x: pv.x - p.x, y: pv.y - p.y, z: pv.z - p.z };\n\n        return this._normalize(this._cross(du, dv));\n    },\n    _surfaceTangentU: function(surface, u, v) {\n        const eps = 0.001;\n        const p1 = this._evaluateSurface(surface, u, v);\n        const p2 = this._evaluateSurface(surface, Math.min(u + eps, 1), v);\n\n        return this._normalize({\n            x: p2.x - p1.x,\n            y: p2.y - p1.y,\n            z: p2.z - p1.z\n        });\n    },\n    _traceFlowline: function(surface, startU, startV, direction, bounds) {\n        const flowline = [];\n        let u = startU, v = startV;\n        const stepSize = 0.01;\n        const maxSteps = 1000;\n\n        for (let i = 0; i < maxSteps; i++) {\n            const point = this._evaluateSurface(surface, u, v);\n            point.u = u;\n            point.v = v;\n\n            // Get direction based on curvature or iso-parameter\n            let dir;\n            if (direction === 'iso_u') {\n                dir = this._surfaceTangentU(surface, u, v);\n            } else {\n                dir = this._surfaceTangentU(surface, u, v); // Simplified\n            }\n            point.tangent = dir;\n            flowline.push(point);\n\n            // Step along direction\n            u += stepSize;\n\n            // Check bounds\n            if (u > bounds.uMax || u < bounds.uMin) break;\n        }\n        return flowline;\n    },\n    _closestPointOnSurface: function(surface, point) {\n        // Simple grid search (could be improved with Newton iteration)\n        let closest = null;\n        let minDist = Infinity;\n\n        const samples = 10;\n        for (let i = 0; i <= samples; i++) {\n            for (let j = 0; j <= samples; j++) {\n                const u = i / samples;\n                const v = j / samples;\n                const sp = this._evaluateSurface(surface, u, v);\n\n                const dist = Math.sqrt(\n                    (sp.x - point.x) ** 2 + (sp.y - point.y) ** 2 + (sp.z - point.z) ** 2\n                );\n\n                if (dist < minDist) {\n                    minDist = dist;\n                    closest = { ...sp, u, v };\n                }\n            }\n        }\n        return closest;\n    },\n    _signedDistance: function(point, surfacePoint, surface) {\n        const normal = this._surfaceNormal(surface, surfacePoint.u, surfacePoint.v);\n        const vec = {\n            x: point.x - surfacePoint.x,\n            y: point.y - surfacePoint.y,\n            z: point.z - surfacePoint.z\n        };\n        return vec.x * normal.x + vec.y * normal.y + vec.z * normal.z;\n    },\n    _surfaceNormalAtPoint: function(surface, position) {\n        const closest = this._closestPointOnSurface(surface, position);\n        return closest ? this._surfaceNormal(surface, closest.u, closest.v) : { x: 0, y: 0, z: 1 };\n    }\n}",
      "methods": [],
      "lines": 660
    },
    {
      "name": "PRISM_ADVANCED_UNCONSTRAINED_OPTIMIZER",
      "category": "engines/optimization",
      "refs": 21,
      "status": "FOUND",
      "code": "const PRISM_ADVANCED_UNCONSTRAINED_OPTIMIZER = {\n    name: 'PRISM_ADVANCED_UNCONSTRAINED_OPTIMIZER',\n    version: '1.0.0',\n    description: 'Advanced unconstrained optimization: L-BFGS, Trust Region, Steepest Descent variants',\n    source: 'MIT 15.084j, Nocedal & Wright',\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Linear Algebra Utilities\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    _dot: function(a, b) {\n        return a.reduce((sum, ai, i) => sum + ai * b[i], 0);\n    },\n    \n    _norm: function(v) {\n        return Math.sqrt(v.reduce((sum, vi) => sum + vi * vi, 0));\n    },\n    \n    _scale: function(v, s) {\n        return v.map(vi => vi * s);\n    },\n    \n    _add: function(a, b) {\n        return a.map((ai, i) => ai + b[i]);\n    },\n    \n    _sub: function(a, b) {\n        return a.map((ai, i) => ai - b[i]);\n    },\n    \n    _clone: function(v) {\n        return [...v];\n    },\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // L-BFGS (Limited-Memory BFGS)\n    // Efficient for large-scale optimization\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    lbfgs: function(config) {\n        const {\n            f,\n            gradient,\n            x0,\n            m = 10,           // Memory size (number of corrections stored)\n            maxIter = 1000,\n            tol = 1e-8,\n            lineSearchMaxIter = 20,\n            c1 = 1e-4,        // Armijo condition\n            c2 = 0.9          // Curvature condition\n        } = config;\n        \n        const n = x0.length;\n        let x = this._clone(x0);\n        let g = gradient(x);\n        \n        // Storage for s and y vectors\n        const sHistory = [];  // s_k = x_{k+1} - x_k\n        const yHistory = [];  // y_k = g_{k+1} - g_k\n        const rhoHistory = []; // rho_k = 1 / (y_k^T s_k)\n        \n        const history = [{ x: this._clone(x), f: f(x), gradNorm: this._norm(g) }];\n        \n        for (let iter = 0; iter < maxIter; iter++) {\n            const gradNorm = this._norm(g);\n            \n            if (gradNorm < tol) {\n                return {\n                    x,\n                    f: f(x),\n                    converged: true,\n                    iterations: iter,\n                    history,\n                    method: 'L-BFGS'\n                };\n            }\n            \n            // Compute search direction using two-loop recursion\n            const d = this._lbfgsTwoLoop(g, sHistory, yHistory, rhoHistory);\n            \n            // Line search (Strong Wolfe conditions)\n            const { alpha, fNew, gNew } = this._wolfeLineSearch(f, gradient, x, d, g, c1, c2, lineSearchMaxIter);\n            \n            if (alpha === 0) {\n                return {\n                    x,\n                    f: f(x),\n                    converged: false,\n                    iterations: iter,\n                    reason: 'Line search failed',\n                    history\n                };\n            }\n            \n            // Compute s and y\n            const s = this._scale(d, alpha);\n            const xNew = this._add(x, s);\n            const y = this._sub(gNew, g);\n            \n            // Update history\n            const sTy = this._dot(s, y);\n            if (sTy > 1e-10) { // Curvature condition\n                if (sHistory.length >= m) {\n                    sHistory.shift();\n                    yHistory.shift();\n                    rhoHistory.shift();\n                }\n                sHistory.push(s);\n                yHistory.push(y);\n                rhoHistory.push(1 / sTy);\n            }\n            \n            x = xNew;\n            g = gNew;\n            \n            history.push({\n                x: this._clone(x),\n                f: fNew,\n                gradNorm: this._norm(g),\n                alpha\n            });\n        }\n        \n        return {\n            x,\n            f: f(x),\n            converged: false,\n            iterations: maxIter,\n            history,\n            method: 'L-BFGS'\n        };\n    },\n    \n    _lbfgsTwoLoop: function(g, sHistory, yHistory, rhoHistory) {\n        const k = sHistory.length;\n        let q = this._clone(g);\n        const alpha = [];\n        \n        // First loop (backward)\n        for (let i = k - 1; i >= 0; i--) {\n            alpha[i] = rhoHistory[i] * this._dot(sHistory[i], q);\n            q = this._sub(q, this._scale(yHistory[i], alpha[i]));\n        }\n        \n        // Initial Hessian approximation (scaled identity)\n        let gamma = 1;\n        if (k > 0) {\n            gamma = this._dot(sHistory[k-1], yHistory[k-1]) / \n                    this._dot(yHistory[k-1], yHistory[k-1]);\n        }\n        let r = this._scale(q, gamma);\n        \n        // Second loop (forward)\n        for (let i = 0; i < k; i++) {\n            const beta = rhoHistory[i] * this._dot(yHistory[i], r);\n            r = this._add(r, this._scale(sHistory[i], alpha[i] - beta));\n        }\n        \n        // Negate for descent direction\n        return this._scale(r, -1);\n    },\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Steepest Descent with Adaptive Step Size\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    steepestDescentAdaptive: function(config) {\n        const {\n            f,\n            gradient,\n            x0,\n            maxIter = 10000,\n            tol = 1e-8,\n            initialStep = 1.0,\n            stepIncrease = 1.2,\n            stepDecrease = 0.5,\n            c = 0.0001\n        } = config;\n        \n        let x = this._clone(x0);\n        let step = initialStep;\n        const history = [];\n        \n        for (let iter = 0; iter < maxIter; iter++) {\n            const g = gradient(x);\n            const gradNorm = this._norm(g);\n            const fx = f(x);\n            \n            history.push({ x: this._clone(x), f: fx, gradNorm, step });\n            \n            if (gradNorm < tol) {\n                return {\n                    x,\n                    f: fx,\n                    converged: true,\n                    iterations: iter,\n                    history,\n                    method: 'Steepest Descent (Adaptive)'\n                };\n            }\n            \n            // Direction: negative gradient\n            const d = this._scale(g, -1);\n            \n            // Adaptive step size with Armijo condition\n            let alpha = step;\n            let accepted = false;\n            \n            for (let ls = 0; ls < 50; ls++) {\n                const xNew = this._add(x, this._scale(d, alpha));\n                const fNew = f(xNew);\n                \n                // Armijo condition\n                if (fNew <= fx + c * alpha * this._dot(g, d)) {\n                    x = xNew;\n                    accepted = true;\n                    \n                    // Increase step for next iteration\n                    step = Math.min(alpha * stepIncrease, 10);\n                    break;\n                }\n                \n                alpha *= stepDecrease;\n            }\n            \n            if (!accepted) {\n                return {\n                    x,\n                    f: fx,\n                    converged: false,\n                    iterations: iter,\n                    reason: 'Line search failed',\n                    history\n                };\n            }\n        }\n        \n        return {\n            x,\n            f: f(x),\n            converged: false,\n            iterations: maxIter,\n            history,\n            method: 'Steepest Descent (Adaptive)'\n        };\n    },\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Nonlinear Conjugate Gradient (Fletcher-Reeves & Polak-Ribi\u00e8re)\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    nonlinearCG: function(config) {\n        const {\n            f,\n            gradient,\n            x0,\n            method = 'PR',    // 'FR' (Fletcher-Reeves) or 'PR' (Polak-Ribi\u00e8re)\n            maxIter = 10000,\n            tol = 1e-8,\n            restartInterval = null\n        } = config;\n        \n        const n = x0.length;\n        let x = this._clone(x0);\n        let g = gradient(x);\n        let d = this._scale(g, -1);\n        const history = [];\n        \n        for (let iter = 0; iter < maxIter; iter++) {\n            const gradNorm = this._norm(g);\n            const fx = f(x);\n            \n            history.push({ x: this._clone(x), f: fx, gradNorm });\n            \n            if (gradNorm < tol) {\n                return {\n                    x,\n                    f: fx,\n                    converged: true,\n                    iterations: iter,\n                    history,\n                    method: `Nonlinear CG (${method})`\n                };\n            }\n            \n            // Line search\n            const alpha = this._backtrackingLineSearch(f, x, d, g);\n            x = this._add(x, this._scale(d, alpha));\n            \n            const gNew = gradient(x);\n            \n            // Compute beta\n            let beta;\n            if (method === 'FR') {\n                // Fletcher-Reeves\n                beta = this._dot(gNew, gNew) / this._dot(g, g);\n            } else {\n                // Polak-Ribi\u00e8re (with restart)\n                beta = Math.max(0, this._dot(gNew, this._sub(gNew, g)) / this._dot(g, g));\n            }\n            \n            // Restart check\n            if (restartInterval && (iter + 1) % restartInterval === 0) {\n                beta = 0;\n            }\n            \n            // Update direction\n            d = this._add(this._scale(gNew, -1), this._scale(d, beta));\n            g = gNew;\n        }\n        \n        return {\n            x,\n            f: f(x),\n            converged: false,\n            iterations: maxIter,\n            history,\n            method: `Nonlinear CG (${method})`\n        };\n    },\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // SR1 (Symmetric Rank-1) Quasi-Newton\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    sr1: function(config) {\n        const {\n            f,\n            gradient,\n            x0,\n            maxIter = 1000,\n            tol = 1e-8,\n            skipThreshold = 1e-8\n        } = config;\n        \n        const n = x0.length;\n        let x = this._clone(x0);\n        let g = gradient(x);\n        \n        // Initialize Hessian approximation as identity\n        let B = this._identity(n);\n        \n        const history = [{ x: this._clone(x), f: f(x), gradNorm: this._norm(g) }];\n        \n        for (let iter = 0; iter < maxIter; iter++) {\n            const gradNorm = this._norm(g);\n            \n            if (gradNorm < tol) {\n                return {\n                    x,\n                    f: f(x),\n                    converged: true,\n                    iterations: iter,\n                    history,\n                    method: 'SR1'\n                };\n            }\n            \n            // Solve B * d = -g for search direction\n            const d = this._solveLinear(B, this._scale(g, -1));\n            \n            // Line search\n            const alpha = this._backtrackingLineSearch(f, x, d, g);\n            \n            const s = this._scale(d, alpha);\n            const xNew = this._add(x, s);\n            const gNew = gradient(xNew);\n            const y = this._sub(gNew, g);\n            \n            // SR1 update\n            const Bs = this._matVec(B, s);\n            const r = this._sub(y, Bs);\n            const rTs = this._dot(r, s);\n            \n            // Skip update if denominator is too small\n            if (Math.abs(rTs) > skipThreshold * this._norm(r) * this._norm(s)) {\n                // B = B + (r * r') / (r' * s)\n                const rrT = this._outer(r, r);\n                B = this._matAdd(B, this._matScale(rrT, 1 / rTs));\n            }\n            \n            x = xNew;\n            g = gNew;\n            \n            history.push({\n                x: this._clone(x),\n                f: f(x),\n                gradNorm: this._norm(g),\n                alpha\n            });\n        }\n        \n        return {\n            x,\n            f: f(x),\n            converged: false,\n            iterations: maxIter,\n            history,\n            method: 'SR1'\n        };\n    },\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // DFP (Davidon-Fletcher-Powell) Quasi-Newton\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    dfp: function(config) {\n        const {\n            f,\n            gradient,\n            x0,\n            maxIter = 1000,\n            tol = 1e-8\n        } = config;\n        \n        const n = x0.length;\n        let x = this._clone(x0);\n        let g = gradient(x);\n        \n        // Initialize inverse Hessian approximation as identity\n        let H = this._identity(n);\n        \n        const history = [{ x: this._clone(x), f: f(x), gradNorm: this._norm(g) }];\n        \n        for (let iter = 0; iter < maxIter; iter++) {\n            const gradNorm = this._norm(g);\n            \n            if (gradNorm < tol) {\n                return {\n                    x,\n                    f: f(x),\n                    converged: true,\n                    iterations: iter,\n                    history,\n                    method: 'DFP'\n                };\n            }\n            \n            // Search direction: d = -H * g\n            const d = this._scale(this._matVec(H, g), -1);\n            \n            // Line search\n            const alpha = this._backtrackingLineSearch(f, x, d, g);\n            \n            const s = this._scale(d, alpha);\n            const xNew = this._add(x, s);\n            const gNew = gradient(xNew);\n            const y = this._sub(gNew, g);\n            \n            // DFP update\n            const sTy = this._dot(s, y);\n            if (sTy > 1e-10) {\n                const Hy = this._matVec(H, y);\n                const yTHy = this._dot(y, Hy);\n                \n                // H = H + (s * s') / (s' * y) - (Hy * Hy') / (y' * Hy)\n                const ssT = this._outer(s, s);\n                const HyyTH = this._outer(Hy, Hy);\n                \n                H = this._matAdd(H, this._matScale(ssT, 1 / sTy));\n                H = this._matSub(H, this._matScale(HyyTH, 1 / yTHy));\n            }\n            \n            x = xNew;\n            g = gNew;\n            \n            history.push({\n                x: this._clone(x),\n                f: f(x),\n                gradNorm: this._norm(g),\n                alpha\n            });\n        }\n        \n        return {\n            x,\n            f: f(x),\n            converged: false,\n            iterations: maxIter,\n            history,\n            method: 'DFP'\n        };\n    },\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Broyden's Method (for systems of equations)\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    broyden: function(config) {\n        const {\n            F,              // Vector function F(x) = 0\n            x0,\n            maxIter = 100,\n            tol = 1e-8\n        } = config;\n        \n        const n = x0.length;\n        let x = this._clone(x0);\n        let Fx = F(x);\n        \n        // Initialize Jacobian approximation as identity\n        let J = this._identity(n);\n        \n        const history = [{ x: this._clone(x), residual: this._norm(Fx) }];\n        \n        for (let iter = 0; iter < maxIter; iter++) {\n            const residual = this._norm(Fx);\n            \n            if (residual < tol) {\n                return {\n                    x,\n                    residual,\n                    converged: true,\n                    iterations: iter,\n                    history,\n                    method: 'Broyden'\n                };\n            }\n            \n            // Solve J * s = -F for Newton step\n            const s = this._solveLinear(J, this._scale(Fx, -1));\n            \n            const xNew = this._add(x, s);\n            const FxNew = F(xNew);\n            const y = this._sub(FxNew, Fx);\n            \n            // Broyden update: J = J + ((y - J*s) * s') / (s' * s)\n            const Js = this._matVec(J, s);\n            const diff = this._sub(y, Js);\n            const sTs = this._dot(s, s);\n            \n            if (sTs > 1e-12) {\n                const update = this._outer(diff, s);\n                J = this._matAdd(J, this._matScale(update, 1 / sTs));\n            }\n            \n            x = xNew;\n            Fx = FxNew;\n            \n            history.push({ x: this._clone(x), residual: this._norm(Fx) });\n        }\n        \n        return {\n            x,\n            residual: this._norm(Fx),\n            converged: false,\n            iterations: maxIter,\n            history,\n            method: 'Broyden'\n        };\n    },\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Line Search Methods\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    _wolfeLineSearch: function(f, gradient, x, d, g, c1, c2, maxIter) {\n        let alpha = 1;\n        let alphaLo = 0;\n        let alphaHi = Infinity;\n        \n        const fx = f(x);\n        const gTd = this._dot(g, d);\n        \n        for (let i = 0; i < maxIter; i++) {\n            const xNew = this._add(x, this._scale(d, alpha));\n            const fNew = f(xNew);\n            const gNew = gradient(xNew);\n            \n            // Armijo condition\n            if (fNew > fx + c1 * alpha * gTd) {\n                alphaHi = alpha;\n                alpha = (alphaLo + alphaHi) / 2;\n                continue;\n            }\n            \n            // Curvature condition\n            const gNewTd = this._dot(gNew, d);\n            if (gNewTd < c2 * gTd) {\n                alphaLo = alpha;\n                alpha = alphaHi === Infinity ? 2 * alpha : (alphaLo + alphaHi) / 2;\n                continue;\n            }\n            \n            // Both conditions satisfied\n            return { alpha, fNew, gNew };\n        }\n        \n        // Return best found\n        const xNew = this._add(x, this._scale(d, alpha));\n        return { alpha, fNew: f(xNew), gNew: gradient(xNew) };\n    },\n    \n    _backtrackingLineSearch: function(f, x, d, g, c = 0.0001, rho = 0.5) {\n        let alpha = 1;\n        const fx = f(x);\n        const gTd = this._dot(g, d);\n        \n        for (let i = 0; i < 50; i++) {\n            const xNew = this._add(x, this._scale(d, alpha));\n            if (f(xNew) <= fx + c * alpha * gTd) {\n                return alpha;\n            }\n            alpha *= rho;\n        }\n        \n        return alpha;\n    },\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Matrix Utilities\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    _identity: function(n) {\n        return Array(n).fill(null).map((_, i) => \n            Array(n).fill(0).map((_, j) => i === j ? 1 : 0)\n        );\n    },\n    \n    _outer: function(a, b) {\n        return a.map(ai => b.map(bj => ai * bj));\n    },\n    \n    _matVec: function(A, x) {\n        return A.map(row => this._dot(row, x));\n    },\n    \n    _matAdd: function(A, B) {\n        return A.map((row, i) => row.map((a, j) => a + B[i][j]));\n    },\n    \n    _matSub: function(A, B) {\n        return A.map((row, i) => row.map((a, j) => a - B[i][j]));\n    },\n    \n    _matScale: function(A, s) {\n        return A.map(row => row.map(a => a * s));\n    },\n    \n    _solveLinear: function(A, b) {\n        const n = b.length;\n        const aug = A.map((row, i) => [...row, b[i]]);\n        \n        // Forward elimination with pivoting\n        for (let i = 0; i < n; i++) {\n            let maxRow = i;\n            for (let k = i + 1; k < n; k++) {\n                if (Math.abs(aug[k][i]) > Math.abs(aug[maxRow][i])) maxRow = k;\n            }\n            [aug[i], aug[maxRow]] = [aug[maxRow], aug[i]];\n            \n            if (Math.abs(aug[i][i]) < 1e-12) continue;\n            \n            for (let k = i + 1; k < n; k++) {\n                const factor = aug[k][i] / aug[i][i];\n                for (let j = i; j <= n; j++) {\n                    aug[k][j] -= factor * aug[i][j];\n                }\n            }\n        }\n        \n        // Back substitution\n        const x = new Array(n).fill(0);\n        for (let i = n - 1; i >= 0; i--) {\n            x[i] = aug[i][n];\n            for (let j = i + 1; j < n; j++) {\n                x[i] -= aug[i][j] * x[j];\n            }\n            x[i] /= aug[i][i] || 1;\n        }\n        \n        return x;\n    },\n    \n    // Gateway registration\n    register: function() {\n        if (typeof PRISM_GATEWAY !== 'undefined') {\n            PRISM_GATEWAY.register('opt.lbfgs', 'PRISM_ADVANCED_UNCONSTRAINED_OPTIMIZER.lbfgs');\n            PRISM_GATEWAY.register('opt.steepestAdaptive', 'PRISM_ADVANCED_UNCONSTRAINED_OPTIMIZER.steepestDescentAdaptive');\n            PRISM_GATEWAY.register('opt.nlcg', 'PRISM_ADVANCED_UNCONSTRAINED_OPTIMIZER.nonlinearCG');\n            PRISM_GATEWAY.register('opt.sr1', 'PRISM_ADVANCED_UNCONSTRAINED_OPTIMIZER.sr1');\n            PRISM_GATEWAY.register('opt.dfp', 'PRISM_ADVANCED_UNCONSTRAINED_OPTIMIZER.dfp');\n            PRISM_GATEWAY.register('opt.broyden', 'PRISM_ADVANCED_UNCONSTRAINED_OPTIMIZER.broyden');\n        }\n    }\n};\n\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// MODULE 2: PRISM_TRUST_REGION_OPTIMIZER\n// Trust Region Methods for Robust Optimization\n// Source: MIT 15.084j, Conn-Gould-Toint\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nconst PRISM_TRUST_REGION_OPTIMIZER = {\n    name: 'PRISM_TRUST_REGION_OPTIMIZER',\n    version: '1.0.0',\n    description: 'Trust region methods: Cauchy Point, Dogleg, Steihaug-Toint CG',\n    source: 'MIT 15.084j, Conn-Gould-Toint',\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Cauchy Point Trust Region\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    trustRegionCauchy: function(config) {\n        const {\n            f,\n            gradient,\n            hessian,\n            x0,\n            maxIter = 1000,\n            tol = 1e-8,\n            initialRadius = 1.0,\n            maxRadius = 100.0,\n            eta = 0.15\n        } = config;\n        \n        let x = [...x0];\n        let delta = initialRadius;\n        const history = [];\n        \n        for (let iter = 0; iter < maxIter; iter++) {\n            const g = gradient(x);\n            const gradNorm = this._norm(g);\n            const fx = f(x);\n            \n            history.push({ x: [...x], f: fx, gradNorm, delta });\n            \n            if (gradNorm < tol) {\n                return {\n                    x,\n                    f: fx,\n                    converged: true,\n                    iterations: iter,\n                    history,\n                    method: 'Trust Region (Cauchy Point)'\n                };\n            }\n            \n            const H = hessian(x);\n            \n            // Compute Cauchy point\n            const gHg = this._quadForm(g, H, g);\n            let tau;\n            \n            if (gHg <= 0) {\n                tau = 1;\n            } else {\n                tau = Math.min(1, Math.pow(gradNorm, 3) / (delta * gHg));\n            }\n            \n            const pC = this._scale(g, -tau * delta / gradNorm);\n            \n            // Compute actual vs predicted reduction\n            const xNew = this._add(x, pC);\n            const fNew = f(xNew);\n            \n            const actualReduction = fx - fNew;\n            const predictedReduction = -this._dot(g, pC) - 0.5 * this._quadForm(pC, H, pC);\n            \n            const rho = predictedReduction !== 0 ? actualReduction / predictedReduction : 0;\n            \n            // Update trust region radius\n            if (rho < 0.25) {\n                delta *= 0.25;\n            } else if (rho > 0.75 && Math.abs(this._norm(pC) - delta) < 1e-8) {\n                delta = Math.min(2 * delta, maxRadius);\n            }\n            \n            // Accept or reject step\n            if (rho > eta) {\n                x = xNew;\n            }\n        }\n        \n        return {\n            x,\n            f: f(x),\n            converged: false,\n            iterations: maxIter,\n            history,\n            method: 'Trust Region (Cauchy Point)'\n        };\n    },\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Dogleg Trust Region\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    trustRegionDogleg: function(config) {\n        const {\n            f,\n            gradient,\n            hessian,\n            x0,\n            maxIter = 1000,\n            tol = 1e-8,\n            initialRadius = 1.0,\n            maxRadius = 100.0,\n            eta = 0.15\n        } = config;\n        \n        let x = [...x0];\n        let delta = initialRadius;\n        const history = [];\n        \n        for (let iter = 0; iter < maxIter; iter++) {\n            const g = gradient(x);\n            const gradNorm = this._norm(g);\n            const fx = f(x);\n            \n            history.push({ x: [...x], f: fx, gradNorm, delta });\n            \n            if (gradNorm < tol) {\n                return {\n                    x,\n                    f: fx,\n                    converged: true,\n                    iterations: iter,\n                    history,\n                    method: 'Trust Region (Dogleg)'\n                };\n            }\n            \n            const H = hessian(x);\n            \n            // Compute Newton step\n            const pB = this._solveLinear(H, this._scale(g, -1));\n            const pBNorm = this._norm(pB);\n            \n            // Compute Cauchy point\n            const gHg = this._quadForm(g, H, g);\n            const pU = this._scale(g, -gradNorm * gradNorm / gHg);\n            const pUNorm = this._norm(pU);\n            \n            // Compute dogleg path\n            let p;\n            if (pBNorm <= delta) {\n                // Newton step is inside trust region\n                p = pB;\n            } else if (pUNorm >= delta) {\n                // Cauchy point is outside trust region\n                p = this._scale(g, -delta / gradNorm);\n            } else {\n                // Interpolate between Cauchy and Newton\n                const diff = this._sub(pB, pU);\n                const a = this._dot(diff, diff);\n                const b = 2 * this._dot(pU, diff);\n                const c = this._dot(pU, pU) - delta * delta;\n                \n                const tau = (-b + Math.sqrt(b * b - 4 * a * c)) / (2 * a);\n                p = this._add(pU, this._scale(diff, tau));\n            }\n            \n            // Compute actual vs predicted reduction\n            const xNew = this._add(x, p);\n            const fNew = f(xNew);\n            \n            const actualReduction = fx - fNew;\n            const predictedReduction = -this._dot(g, p) - 0.5 * this._quadForm(p, H, p);\n            \n            const rho = predictedReduction !== 0 ? actualReduction / predictedReduction : 0;\n            \n            // Update trust region radius\n            if (rho < 0.25) {\n                delta *= 0.25;\n            } else if (rho > 0.75 && Math.abs(this._norm(p) - delta) < 1e-8) {\n                delta = Math.min(2 * delta, maxRadius);\n            }\n            \n            // Accept or reject step\n            if (rho > eta) {\n                x = xNew;\n            }\n        }\n        \n        return {\n            x,\n            f: f(x),\n            converged: false,\n            iterations: maxIter,\n            history,\n            method: 'Trust Region (Dogleg)'\n        };\n    },\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Steihaug-Toint CG Trust Region\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    trustRegionSteihaugCG: function(config) {\n        const {\n            f,\n            gradient,\n            hessian,\n            x0,\n            maxIter = 1000,\n            tol = 1e-8,\n            initialRadius = 1.0,\n            maxRadius = 100.0,\n            eta = 0.15,\n            cgMaxIter = 100\n        } = config;\n        \n        let x = [...x0];\n        let delta = initialRadius;\n        const history = [];\n        \n        for (let iter = 0; iter < maxIter; iter++) {\n            const g = gradient(x);\n            const gradNorm = this._norm(g);\n            const fx = f(x);\n            \n            history.push({ x: [...x], f: fx, gradNorm, delta });\n            \n            if (gradNorm < tol) {\n                return {\n                    x,\n                    f: fx,\n                    converged: true,\n                    iterations: iter,\n                    history,\n                    method: 'Trust Region (Steihaug-CG)'\n                };\n            }\n            \n            const H = hessian(x);\n            \n            // Solve trust region subproblem using CG\n            const p = this._steihaugCG(g, H, delta, gradNorm * 1e-3, cgMaxIter);\n            \n            // Compute actual vs predicted reduction\n            const xNew = this._add(x, p);\n            const fNew = f(xNew);\n            \n            const actualReduction = fx - fNew;\n            const predictedReduction = -this._dot(g, p) - 0.5 * this._quadForm(p, H, p);\n            \n            const rho = predictedReduction !== 0 ? actualReduction / predictedReduction : 0;\n            \n            // Update trust region radius\n            if (rho < 0.25) {\n                delta *= 0.25;\n            } else if (rho > 0.75 && Math.abs(this._norm(p) - delta) < 1e-8) {\n                delta = Math.min(2 * delta, maxRadius);\n            }\n            \n            // Accept or reject step\n            if (rho > eta) {\n                x = xNew;\n            }\n        }\n        \n        return {\n            x,\n            f: f(x),\n            converged: false,\n            iterations: maxIter,\n            history,\n            method: 'Trust Region (Steihaug-CG)'\n        };\n    },\n    \n    _steihaugCG: function(g, H, delta, tol, maxIter) {\n        const n = g.length;\n        let z = new Array(n).fill(0);\n        let r = [...g];\n        let d = this._scale(g, -1);\n        \n        if (this._norm(r) < tol) {\n            return z;\n        }\n        \n        for (let j = 0; j < maxIter; j++) {\n            const Hd = this._matVec(H, d);\n            const dHd = this._dot(d, Hd);\n            \n            // Check for negative curvature\n            if (dHd <= 0) {\n                // Find tau such that ||z + tau*d|| = delta\n                const tau = this._findBoundaryIntersection(z, d, delta);\n                return this._add(z, this._scale(d, tau));\n            }\n            \n            const alpha = this._dot(r, r) / dHd;\n            const zNew = this._add(z, this._scale(d, alpha));\n            \n            // Check if we hit the boundary\n            if (this._norm(zNew) >= delta) {\n                const tau = this._findBoundaryIntersection(z, d, delta);\n                return this._add(z, this._scale(d, tau));\n            }\n            \n            z = zNew;\n            const rNew = this._add(r, this._scale(Hd, alpha));\n            \n            if (this._norm(rNew) < tol) {\n                return z;\n            }\n            \n            const beta = this._dot(rNew, rNew) / this._dot(r, r);\n            d = this._add(this._scale(rNew, -1), this._scale(d, beta));\n            r = rNew;\n        }\n        \n        return z;\n    },\n    \n    _findBoundaryIntersection: function(z, d, delta) {\n        const a = this._dot(d, d);\n        const b = 2 * this._dot(z, d);\n        const c = this._dot(z, z) - delta * delta;\n        \n        const discriminant = b * b - 4 * a * c;\n        if (discriminant < 0) return 0;\n        \n        return (-b + Math.sqrt(discriminant)) / (2 * a);\n    },\n    \n    // Helper functions\n    _norm: function(v) {\n        return Math.sqrt(v.reduce((sum, vi) => sum + vi * vi, 0));\n    },\n    \n    _dot: function(a, b) {\n        return a.reduce((sum, ai, i) => sum + ai * b[i], 0);\n    },\n    \n    _scale: function(v, s) {\n        return v.map(vi => vi * s);\n    },\n    \n    _add: function(a, b) {\n        return a.map((ai, i) => ai + b[i]);\n    },\n    \n    _sub: function(a, b) {\n        return a.map((ai, i) => ai - b[i]);\n    },\n    \n    _matVec: function(A, x) {\n        return A.map(row => this._dot(row, x));\n    },\n    \n    _quadForm: function(x, A, y) {\n        return this._dot(x, this._matVec(A, y));\n    },\n    \n    _solveLinear: function(A, b) {\n        return PRISM_ADVANCED_UNCONSTRAINED_OPTIMIZER._solveLinear(A, b);\n    },\n    \n    // Gateway registration\n    register: function() {\n        if (typeof PRISM_GATEWAY !== 'undefined') {\n            PRISM_GATEWAY.register('opt.trustRegion.cauchy', 'PRISM_TRUST_REGION_OPTIMIZER.trustRegionCauchy');\n            PRISM_GATEWAY.register('opt.trustRegion.dogleg', 'PRISM_TRUST_REGION_OPTIMIZER.trustRegionDogleg');\n            PRISM_GATEWAY.register('opt.trustRegion.steihaugCG', 'PRISM_TRUST_REGION_OPTIMIZER.trustRegionSteihaugCG');\n        }\n    }\n};\n\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// REGISTER ALL PART 1 MODULES\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nfunction registerSession3Part1() {\n    PRISM_ADVANCED_UNCONSTRAINED_OPTIMIZER.register();\n    PRISM_TRUST_REGION_OPTIMIZER.register();\n    \n    console.log('[Session 3 Part 1] Registered 2 modules, 9 gateway routes');\n    console.log('  - PRISM_ADVANCED_UNCONSTRAINED_OPTIMIZER: L-BFGS, Steepest, NLCG, SR1, DFP, Broyden');\n    console.log('  - PRISM_TRUST_REGION_OPTIMIZER: Cauchy, Dogleg, Steihaug-CG');\n}\n\n// Auto-register\nif (typeof window !== 'undefined') {\n    window.PRISM_ADVANCED_UNCONSTRAINED_OPTIMIZER = PRISM_ADVANCED_UNCONSTRAINED_OPTIMIZER;\n    window.PRISM_TRUST_REGION_OPTIMIZER = PRISM_TRUST_REGION_OPTIMIZER;\n    registerSession3Part1();\n}\n\nconsole.log('[Session 3 Part 1] Advanced Unconstrained Optimization loaded - 2 modules');\n/**\n * \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n * \u2551 PRISM SESSION 3: ULTIMATE OPTIMIZATION ENHANCEMENT - PART 2                              \u2551\n * \u2551 Constrained Optimization: Barrier, Augmented Lagrangian, SQP, Interior Point             \u2551\n * \u2551 Source: MIT 15.084j, MIT 6.251J, Boyd & Vandenberghe                                     \u2551\n * \u2551 Target: +1,200 lines | 2 Modules | 15+ Gateway Routes                                    \u2551\n * \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n */\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// MODULE 3: PRISM_CONSTRAINED_OPTIMIZER\n// Penalty, Barrier, and Augmented Lagrangian Methods\n// Source: MIT 15.084j, Boyd & Vandenberghe\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nconst PRISM_CONSTRAINED_OPTIMIZER = {\n    name: 'PRISM_CONSTRAINED_OPTIMIZER',\n    version: '1.0.0',\n    description: 'Constrained optimization: Penalty, Barrier, Augmented Lagrangian',\n    source: 'MIT 15.084j, Boyd & Vandenberghe',\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Linear Algebra Utilities\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    _dot: function(a, b) {\n        return a.reduce((sum, ai, i) => sum + ai * b[i], 0);\n    },\n    \n    _norm: function(v) {\n        return Math.sqrt(v.reduce((sum, vi) => sum + vi * vi, 0));\n    },\n    \n    _scale: function(v, s) {\n        return v.map(vi => vi * s);\n    },\n    \n    _add: function(a, b) {\n        return a.map((ai, i) => ai + b[i]);\n    },\n    \n    _sub: function(a, b) {\n        return a.map((ai, i) => ai - b[i]);\n    },\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Quadratic Penalty Method\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    quadraticPenalty: function(config) {\n        const {\n            f,                    // Objective function\n            gradient,             // Gradient of objective\n            equalityConstraints = [],   // Array of h_i(x) = 0 functions\n            inequalityConstraints = [], // Array of g_i(x) <= 0 functions\n            x0,\n            mu0 = 1,              // Initial penalty parameter\n            muGrowth = 10,        // Growth factor for mu\n            maxOuterIter = 50,\n            maxInnerIter = 1000,\n            outerTol = 1e-6,\n            innerTol = 1e-8\n        } = config;\n        \n        let x = [...x0];\n        let mu = mu0;\n        const history = [];\n        \n        for (let outer = 0; outer < maxOuterIter; outer++) {\n            // Penalized objective\n            const penalizedF = (x) => {\n                let val = f(x);\n                \n                // Equality constraints: sum of h_i(x)^2\n                for (const h of equalityConstraints) {\n                    val += mu * Math.pow(h(x), 2);\n                }\n                \n                // Inequality constraints: sum of max(0, g_i(x))^2\n                for (const g of inequalityConstraints) {\n                    val += mu * Math.pow(Math.max(0, g(x)), 2);\n                }\n                \n                return val;\n            };\n            \n            // Gradient of penalized objective (numerical)\n            const penalizedGradient = (x) => {\n                const eps = 1e-7;\n                return x.map((_, i) => {\n                    const xPlus = [...x];\n                    const xMinus = [...x];\n                    xPlus[i] += eps;\n                    xMinus[i] -= eps;\n                    return (penalizedF(xPlus) - penalizedF(xMinus)) / (2 * eps);\n                });\n            };\n            \n            // Solve unconstrained subproblem\n            const result = PRISM_ADVANCED_UNCONSTRAINED_OPTIMIZER.lbfgs({\n                f: penalizedF,\n                gradient: penalizedGradient,\n                x0: x,\n                maxIter: maxInnerIter,\n                tol: innerTol\n            });\n            \n            x = result.x;\n            \n            // Check constraint violation\n            let maxViolation = 0;\n            for (const h of equalityConstraints) {\n                maxViolation = Math.max(maxViolation, Math.abs(h(x)));\n            }\n            for (const g of inequalityConstraints) {\n                maxViolation = Math.max(maxViolation, Math.max(0, g(x)));\n            }\n            \n            history.push({\n                x: [...x],\n                f: f(x),\n                mu,\n                maxViolation,\n                innerIter: result.iterations\n            });\n            \n            // Check convergence\n            if (maxViolation < outerTol) {\n                return {\n                    x,\n                    f: f(x),\n                    converged: true,\n                    outerIterations: outer + 1,\n                    constraintViolation: maxViolation,\n                    history,\n                    method: 'Quadratic Penalty'\n                };\n            }\n            \n            // Increase penalty\n            mu *= muGrowth;\n        }\n        \n        return {\n            x,\n            f: f(x),\n            converged: false,\n            outerIterations: maxOuterIter,\n            history,\n            method: 'Quadratic Penalty'\n        };\n    },\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Log Barrier Method (Interior Point)\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    logBarrier: function(config) {\n        const {\n            f,                    // Objective function\n            gradient,             // Gradient of objective\n            inequalityConstraints = [], // Array of g_i(x) <= 0 functions\n            x0,\n            t0 = 1,               // Initial barrier parameter\n            tGrowth = 10,         // Growth factor for t\n            maxOuterIter = 50,\n            maxInnerIter = 100,\n            outerTol = 1e-6,\n            innerTol = 1e-8\n        } = config;\n        \n        const m = inequalityConstraints.length;\n        let x = [...x0];\n        let t = t0;\n        const history = [];\n        \n        // Verify initial point is strictly feasible\n        for (let i = 0; i < m; i++) {\n            if (inequalityConstraints[i](x) >= 0) {\n                console.warn(`Initial point violates constraint ${i}`);\n            }\n        }\n        \n        for (let outer = 0; outer < maxOuterIter; outer++) {\n            // Barrier function: f(x) - (1/t) * sum(log(-g_i(x)))\n            const barrierF = (x) => {\n                let val = t * f(x);\n                \n                for (const g of inequalityConstraints) {\n                    const gi = g(x);\n                    if (gi >= 0) return Infinity; // Infeasible\n                    val -= Math.log(-gi);\n                }\n                \n                return val;\n            };\n            \n            // Gradient of barrier function (numerical)\n            const barrierGradient = (x) => {\n                const eps = 1e-7;\n                return x.map((_, i) => {\n                    const xPlus = [...x];\n                    const xMinus = [...x];\n                    xPlus[i] += eps;\n                    xMinus[i] -= eps;\n                    const fPlus = barrierF(xPlus);\n                    const fMinus = barrierF(xMinus);\n                    if (!isFinite(fPlus) || !isFinite(fMinus)) {\n                        // One-sided difference\n                        return (barrierF(xPlus) - barrierF(x)) / eps;\n                    }\n                    return (fPlus - fMinus) / (2 * eps);\n                });\n            };\n            \n            // Solve barrier subproblem\n            const result = PRISM_ADVANCED_UNCONSTRAINED_OPTIMIZER.lbfgs({\n                f: barrierF,\n                gradient: barrierGradient,\n                x0: x,\n                maxIter: maxInnerIter,\n                tol: innerTol\n            });\n            \n            x = result.x;\n            \n            // Duality gap\n            const dualityGap = m / t;\n            \n            history.push({\n                x: [...x],\n                f: f(x),\n                t,\n                dualityGap,\n                innerIter: result.iterations\n            });\n            \n            // Check convergence\n            if (dualityGap < outerTol) {\n                return {\n                    x,\n                    f: f(x),\n                    converged: true,\n                    outerIterations: outer + 1,\n                    dualityGap,\n                    history,\n                    method: 'Log Barrier'\n                };\n            }\n            \n            // Increase t\n            t *= tGrowth;\n        }\n        \n        return {\n            x,\n            f: f(x),\n            converged: false,\n            outerIterations: maxOuterIter,\n            history,\n            method: 'Log Barrier'\n        };\n    },\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Augmented Lagrangian Method (Method of Multipliers)\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    augmentedLagrangian: function(config) {\n        const {\n            f,                    // Objective function\n            gradient,             // Gradient of objective\n            equalityConstraints = [],   // Array of h_i(x) = 0 functions\n            inequalityConstraints = [], // Array of g_i(x) <= 0 functions\n            x0,\n            lambda0 = null,       // Initial Lagrange multipliers for equality\n            mu0 = null,           // Initial Lagrange multipliers for inequality\n            rho0 = 1,             // Initial penalty parameter\n            rhoGrowth = 2,        // Growth factor for rho\n            maxOuterIter = 50,\n            maxInnerIter = 1000,\n            outerTol = 1e-6,\n            innerTol = 1e-8\n        } = config;\n        \n        const nEq = equalityConstraints.length;\n        const nIneq = inequalityConstraints.length;\n        \n        let x = [...x0];\n        let lambda = lambda0 || new Array(nEq).fill(0);\n        let mu = mu0 || new Array(nIneq).fill(0);\n        let rho = rho0;\n        \n        const history = [];\n        \n        for (let outer = 0; outer < maxOuterIter; outer++) {\n            // Augmented Lagrangian function\n            const augLag = (x) => {\n                let val = f(x);\n                \n                // Equality constraints\n                for (let i = 0; i < nEq; i++) {\n                    const hi = equalityConstraints[i](x);\n                    val += lambda[i] * hi + (rho / 2) * hi * hi;\n                }\n                \n                // Inequality constraints (using slack formulation)\n                for (let i = 0; i < nIneq; i++) {\n                    const gi = inequalityConstraints[i](x);\n                    const term = Math.max(0, mu[i] + rho * gi);\n                    val += (1 / (2 * rho)) * (term * term - mu[i] * mu[i]);\n                }\n                \n                return val;\n            };\n            \n            // Gradient of augmented Lagrangian (numerical)\n            const augLagGradient = (x) => {\n                const eps = 1e-7;\n                return x.map((_, i) => {\n                    const xPlus = [...x];\n                    const xMinus = [...x];\n                    xPlus[i] += eps;\n                    xMinus[i] -= eps;\n                    return (augLag(xPlus) - augLag(xMinus)) / (2 * eps);\n                });\n            };\n            \n            // Solve augmented Lagrangian subproblem\n            const result = PRISM_ADVANCED_UNCONSTRAINED_OPTIMIZER.lbfgs({\n                f: augLag,\n                gradient: augLagGradient,\n                x0: x,\n                maxIter: maxInnerIter,\n                tol: innerTol\n            });\n            \n            x = result.x;\n            \n            // Update multipliers\n            for (let i = 0; i < nEq; i++) {\n                lambda[i] += rho * equalityConstraints[i](x);\n            }\n            \n            for (let i = 0; i < nIneq; i++) {\n                mu[i] = Math.max(0, mu[i] + rho * inequalityConstraints[i](x));\n            }\n            \n            // Check constraint violation\n            let maxViolation = 0;\n            for (let i = 0; i < nEq; i++) {\n                maxViolation = Math.max(maxViolation, Math.abs(equalityConstraints[i](x)));\n            }\n            for (let i = 0; i < nIneq; i++) {\n                maxViolation = Math.max(maxViolation, Math.max(0, inequalityConstraints[i](x)));\n            }\n            \n            history.push({\n                x: [...x],\n                f: f(x),\n                rho,\n                maxViolation,\n                lambda: [...lambda],\n                mu: [...mu],\n                innerIter: result.iterations\n            });\n            \n            // Check convergence\n            if (maxViolation < outerTol) {\n                return {\n                    x,\n                    f: f(x),\n                    converged: true,\n                    outerIterations: outer + 1,\n                    constraintViolation: maxViolation,\n                    lambda,\n                    mu,\n                    history,\n                    method: 'Augmented Lagrangian'\n                };\n            }\n            \n            // Increase penalty\n            rho *= rhoGrowth;\n        }\n        \n        return {\n            x,\n            f: f(x),\n            converged: false,\n            outerIterations: maxOuterIter,\n            lambda,\n            mu,\n            history,\n            method: 'Augmented Lagrangian'\n        };\n    },\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Projected Gradient Method (for box constraints)\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    projectedGradient: function(config) {\n        const {\n            f,\n            gradient,\n            x0,\n            lowerBounds,\n            upperBounds,\n            maxIter = 10000,\n            tol = 1e-8,\n            learningRate = 0.01,\n            lineSearch = true\n        } = config;\n        \n        const project = (x) => {\n            return x.map((xi, i) => {\n                let val = xi;\n                if (lowerBounds && lowerBounds[i] !== undefined) {\n                    val = Math.max(val, lowerBounds[i]);\n                }\n                if (upperBounds && upperBounds[i] !== undefined) {\n                    val = Math.min(val, upperBounds[i]);\n                }\n                return val;\n            });\n        };\n        \n        let x = project([...x0]);\n        const history = [];\n        \n        for (let iter = 0; iter < maxIter; iter++) {\n            const g = gradient(x);\n            const gradNorm = this._norm(g);\n            const fx = f(x);\n            \n            history.push({ x: [...x], f: fx, gradNorm });\n            \n            // Check convergence using projected gradient\n            const xTest = project(this._sub(x, this._scale(g, 1)));\n            const projGradNorm = this._norm(this._sub(x, xTest));\n            \n            if (projGradNorm < tol) {\n                return {\n                    x,\n                    f: fx,\n                    converged: true,\n                    iterations: iter,\n                    history,\n                    method: 'Projected Gradient'\n                };\n            }\n            \n            // Line search or fixed step\n            let alpha = learningRate;\n            \n            if (lineSearch) {\n                // Backtracking line search with projection\n                const c = 0.0001;\n                for (let ls = 0; ls < 30; ls++) {\n                    const xNew = project(this._sub(x, this._scale(g, alpha)));\n                    if (f(xNew) <= fx + c * this._dot(g, this._sub(xNew, x))) {\n                        x = xNew;\n                        break;\n                    }\n                    alpha *= 0.5;\n                }\n            } else {\n                x = project(this._sub(x, this._scale(g, alpha)));\n            }\n        }\n        \n        return {\n            x,\n            f: f(x),\n            converged: false,\n            iterations: maxIter,\n            history,\n            method: 'Projected Gradient'\n        };\n    },\n    \n    // Gateway registration\n    register: function() {\n        if (typeof PRISM_GATEWAY !== 'undefined') {\n            PRISM_GATEWAY.register('opt.penalty.quadratic', 'PRISM_CONSTRAINED_OPTIMIZER.quadraticPenalty');\n            PRISM_GATEWAY.register('opt.barrier.log', 'PRISM_CONSTRAINED_OPTIMIZER.logBarrier');\n            PRISM_GATEWAY.register('opt.augmentedLagrangian', 'PRISM_CONSTRAINED_OPTIMIZER.augmentedLagrangian');\n            PRISM_GATEWAY.register('opt.projectedGradient', 'PRISM_CONSTRAINED_OPTIMIZER.projectedGradient');\n        }\n    }\n};\n\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// MODULE 4: PRISM_SQP_INTERIOR_POINT_ENGINE\n// Sequential Quadratic Programming and Primal-Dual Interior Point\n// Source: MIT 6.251J, Wright (IPM book)\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nconst PRISM_SQP_INTERIOR_POINT_ENGINE = {\n    name: 'PRISM_SQP_INTERIOR_POINT_ENGINE',\n    version: '1.0.0',\n    description: 'SQP and Interior Point methods for constrained optimization',\n    source: 'MIT 6.251J, Wright',\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Sequential Quadratic Programming (SQP)\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    sqp: function(config) {\n        const {\n            f,\n            gradient,\n            hessianApprox = 'bfgs',\n            equalityConstraints = [],\n            inequalityConstraints = [],\n            x0,\n            maxIter = 100,\n            tol = 1e-6\n        } = config;\n        \n        const nEq = equalityConstraints.length;\n        const nIneq = inequalityConstraints.length;\n        const n = x0.length;\n        \n        let x = [...x0];\n        let lambda = new Array(nEq).fill(0);\n        let mu = new Array(nIneq).fill(1);\n        \n        // Initialize approximate Hessian\n        let B = this._identity(n);\n        \n        const history = [];\n        \n        for (let iter = 0; iter < maxIter; iter++) {\n            const g = gradient(x);\n            const fx = f(x);\n            \n            // Evaluate constraints\n            const h = equalityConstraints.map(c => c(x));\n            const gIneq = inequalityConstraints.map(c => c(x));\n            \n            // Check KKT conditions\n            const kktViolation = this._computeKKTViolation(g, h, gIneq, lambda, mu, equalityConstraints, inequalityConstraints, x);\n            \n            history.push({ x: [...x], f: fx, kktViolation });\n            \n            if (kktViolation < tol) {\n                return {\n                    x,\n                    f: fx,\n                    converged: true,\n                    iterations: iter,\n                    lambda,\n                    mu,\n                    history,\n                    method: 'SQP'\n                };\n            }\n            \n            // Solve QP subproblem\n            // min 0.5 * d' * B * d + g' * d\n            // s.t. Ae * d + h = 0 (equality)\n            //      Ai * d + gIneq <= 0 (inequality)\n            \n            // Compute constraint Jacobians (numerical)\n            const Ae = this._computeJacobian(equalityConstraints, x);\n            const Ai = this._computeJacobian(inequalityConstraints, x);\n            \n            // Simplified QP solve using active set method\n            const qpResult = this._solveQP(B, g, Ae, h, Ai, gIneq);\n            \n            if (!qpResult.success) {\n                console.warn('QP subproblem failed');\n                break;\n            }\n            \n            const d = qpResult.d;\n            const lambdaNew = qpResult.lambda;\n            const muNew = qpResult.mu;\n            \n            // Line search with merit function\n            const alpha = this._meritLineSearch(f, equalityConstraints, inequalityConstraints, x, d, g, rho);\n            \n            // BFGS update for B\n            const xNew = this._add(x, this._scale(d, alpha));\n            const gNew = gradient(xNew);\n            \n            const s = this._scale(d, alpha);\n            const y = this._sub(gNew, g);\n            \n            // Damped BFGS update\n            B = this._dampedBFGSUpdate(B, s, y);\n            \n            // Update\n            x = xNew;\n            lambda = lambdaNew;\n            mu = muNew.map(m => Math.max(0, m));\n        }\n        \n        return {\n            x,\n            f: f(x),\n            converged: false,\n            iterations: maxIter,\n            history,\n            method: 'SQP'\n        };\n    },\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Primal-Dual Interior Point Method\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    primalDualInteriorPoint: function(config) {\n        const {\n            c,                    // Linear objective coefficients\n            A,                    // Inequality constraint matrix (Ax <= b)\n            b,                    // Inequality constraint RHS\n            Aeq = null,           // Equality constraint matrix\n            beq = null,           // Equality RHS\n            x0 = null,\n            maxIter = 100,\n            tol = 1e-8\n        } = config;\n        \n        const m = A.length;      // Number of inequalities\n        const n = c.length;      // Number of variables\n        const mEq = Aeq ? Aeq.length : 0;\n        \n        // Initialize\n        let x = x0 || new Array(n).fill(1);\n        let s = new Array(m).fill(1);  // Slack variables\n        let lambda = new Array(m).fill(1); // Dual variables for inequality\n        let nu = mEq > 0 ? new Array(mEq).fill(0) : []; // Dual for equality\n        \n        const history = [];\n        \n        for (let iter = 0; iter < maxIter; iter++) {\n            // Residuals\n            const Ax = this._matVec(A, x);\n            const rp = Ax.map((ai, i) => ai + s[i] - b[i]); // Primal residual\n            const rd = this._add(c, this._matVec(this._transpose(A), lambda)); // Dual residual\n            if (Aeq) {\n                const rdEq = this._matVec(this._transpose(Aeq), nu);\n                for (let i = 0; i < n; i++) rd[i] += rdEq[i];\n            }\n            const rc = s.map((si, i) => si * lambda[i]); // Complementarity\n            \n            const rpNorm = this._norm(rp);\n            const rdNorm = this._norm(rd);\n            const mu = rc.reduce((a, b) => a + b, 0) / m; // Duality measure\n            \n            history.push({\n                x: [...x],\n                objective: this._dot(c, x),\n                rpNorm,\n                rdNorm,\n                mu\n            });\n            \n            // Check convergence\n            if (rpNorm < tol && rdNorm < tol && mu < tol) {\n                return {\n                    x,\n                    objective: this._dot(c, x),\n                    converged: true,\n                    iterations: iter,\n                    lambda,\n                    history,\n                    method: 'Primal-Dual Interior Point'\n                };\n            }\n            \n            // Centering parameter\n            const sigma = 0.1;\n            const muTarget = sigma * mu;\n            \n            // Solve Newton system\n            // [0  A'  Aeq'] [dx]    [-rd]\n            // [A  0   0   ] [ds]  = [-rp]\n            // [S  Lambda 0] [dlam]  [-rc + muTarget*e]\n            \n            // Simplified: solve using Schur complement\n            const { dx, ds, dlambda } = this._solveIPMSystem(\n                A, Aeq, s, lambda, rd, rp, rc, muTarget\n            );\n            \n            // Line search to maintain positivity\n            let alphaP = 1;\n            let alphaD = 1;\n            const tau = 0.995;\n            \n            for (let i = 0; i < m; i++) {\n                if (ds[i] < 0) {\n                    alphaP = Math.min(alphaP, -tau * s[i] / ds[i]);\n                }\n                if (dlambda[i] < 0) {\n                    alphaD = Math.min(alphaD, -tau * lambda[i] / dlambda[i]);\n                }\n            }\n            \n            // Update\n            x = this._add(x, this._scale(dx, alphaP));\n            s = this._add(s, this._scale(ds, alphaP));\n            lambda = this._add(lambda, this._scale(dlambda, alphaD));\n        }\n        \n        return {\n            x,\n            objective: this._dot(c, x),\n            converged: false,\n            iterations: maxIter,\n            history,\n            method: 'Primal-Dual Interior Point'\n        };\n    },\n    \n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Linear Programming (Simplex-like for small problems)\n    // \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    \n    linearProgramming: function(config) {\n        const {\n            c,        // Objective: min c'x\n            A,        // Inequality constraints: Ax <= b\n            b,\n            Aeq = null,\n            beq = null,\n            bounds = null, // [[lb, ub], ...]\n            method = 'interior_point'\n        }",
      "methods": [],
      "lines": 1817
    },
    {
      "name": "PRISM_UNCONSTRAINED_OPTIMIZATION",
      "category": "engines/optimization",
      "refs": 18,
      "status": "FOUND",
      "code": "const PRISM_UNCONSTRAINED_OPTIMIZATION = {\n    name: 'PRISM_UNCONSTRAINED_OPTIMIZATION',\n    version: '1.0.0',\n    source: 'MIT 6.251J - Mathematical Programming',\n    \n    // Linear Algebra Helpers\n    _dot: function(a, b) {\n        return a.reduce((sum, ai, i) => sum + ai * (b[i] || 0), 0);\n    },\n    \n    _norm: function(v) {\n        return Math.sqrt(v.reduce((sum, vi) => sum + vi * vi, 0));\n    },\n    \n    _scale: function(v, s) {\n        return v.map(vi => vi * s);\n    },\n    \n    _add: function(a, b) {\n        return a.map((ai, i) => ai + (b[i] || 0));\n    },\n    \n    _sub: function(a, b) {\n        return a.map((ai, i) => ai - (b[i] || 0));\n    },\n    \n    _outerProduct: function(a, b) {\n        return a.map(ai => b.map(bj => ai * bj));\n    },\n    \n    _matVec: function(A, x) {\n        return A.map(row => this._dot(row, x));\n    },\n    \n    /**\n     * L-BFGS (Limited-memory BFGS)\n     * Memory-efficient quasi-Newton for large-scale problems\n     * Source: MIT 6.251J - Optimization Methods\n     */\n    lbfgs: function(config) {\n        const {\n            f,              // Objective function\n            gradient,       // Gradient function\n            x0,             // Initial point\n            m = 10,         // Memory size (number of corrections to store)\n            maxIter = 1000,\n            tol = 1e-8,\n            c1 = 1e-4,      // Armijo condition parameter\n            c2 = 0.9        // Wolfe condition parameter\n        } = config;\n        \n        const n = x0.length;\n        let x = [...x0];\n        let g = gradient(x);\n        \n        // Storage for limited memory\n        const s_list = [];  // s_k = x_{k+1} - x_k\n        const y_list = [];  // y_k = g_{k+1} - g_k\n        const rho_list = []; // rho_k = 1 / (y_k' s_k)\n        \n        const history = [{ x: [...x], f: f(x), gradNorm: this._norm(g) }];\n        \n        for (let iter = 0; iter < maxIter; iter++) {\n            const gradNorm = this._norm(g);\n            \n            if (gradNorm < tol) {\n                return {\n                    x,\n                    f: f(x),\n                    converged: true,\n                    iterations: iter,\n                    history,\n                    method: 'L-BFGS'\n                };\n            }\n            \n            // Two-loop recursion to compute search direction\n            const d = this._lbfgsTwoLoop(g, s_list, y_list, rho_list);\n            \n            // Line search with Wolfe conditions\n            const { alpha, x_new, g_new } = this._wolfeLineSearch(f, gradient, x, d, g, c1, c2);\n            \n            if (alpha === 0) {\n                return { x, f: f(x), converged: false, iterations: iter, reason: 'Line search failed', history };\n            }\n            \n            // Update storage\n            const s = this._sub(x_new, x);\n            const y = this._sub(g_new, g);\n            const ys = this._dot(y, s);\n            \n            if (ys > 1e-10) {  // Curvature condition\n                if (s_list.length >= m) {\n                    s_list.shift();\n                    y_list.shift();\n                    rho_list.shift();\n                }\n                s_list.push(s);\n                y_list.push(y);\n                rho_list.push(1 / ys);\n            }\n            \n            x = x_new;\n            g = g_new;\n            history.push({ x: [...x], f: f(x), gradNorm: this._norm(g), alpha });\n        }\n        \n        return { x, f: f(x), converged: false, iterations: maxIter, history, method: 'L-BFGS' };\n    },\n    \n    _lbfgsTwoLoop: function(g, s_list, y_list, rho_list) {\n        const m = s_list.length;\n        let q = [...g];\n        const alpha = [];\n        \n        // First loop (backward)\n        for (let i = m - 1; i >= 0; i--) {\n            alpha[i] = rho_list[i] * this._dot(s_list[i], q);\n            q = this._sub(q, this._scale(y_list[i], alpha[i]));\n        }\n        \n        // Initial Hessian approximation (scaled identity)\n        let gamma = 1;\n        if (m > 0) {\n            gamma = this._dot(s_list[m-1], y_list[m-1]) / this._dot(y_list[m-1], y_list[m-1]);\n        }\n        let r = this._scale(q, gamma);\n        \n        // Second loop (forward)\n        for (let i = 0; i < m; i++) {\n            const beta = rho_list[i] * this._dot(y_list[i], r);\n            r = this._add(r, this._scale(s_list[i], alpha[i] - beta));\n        }\n        \n        // Negate for descent direction\n        return this._scale(r, -1);\n    },\n    \n    _wolfeLineSearch: function(f, gradient, x, d, g, c1, c2, maxIter = 20) {\n        let alpha = 1;\n        const fx = f(x);\n        const gd = this._dot(g, d);\n        \n        for (let i = 0; i < maxIter; i++) {\n            const x_new = this._add(x, this._scale(d, alpha));\n            const fx_new = f(x_new);\n            \n            // Armijo condition\n            if (fx_new > fx + c1 * alpha * gd) {\n                alpha *= 0.5;\n                continue;\n            }\n            \n            const g_new = gradient(x_new);\n            \n            // Curvature condition (weak Wolfe)\n            if (this._dot(g_new, d) < c2 * gd) {\n                alpha *= 2;\n                if (alpha > 100) break;\n                continue;\n            }\n            \n            return { alpha, x_new, g_new };\n        }\n        \n        // Return best found\n        const x_new = this._add(x, this._scale(d, alpha));\n        return { alpha, x_new, g_new: gradient(x_new) };\n    },\n    \n    /**\n     * Trust Region Method (Dogleg)\n     * Source: MIT 6.251J - Nonlinear Optimization\n     */\n    trustRegion: function(config) {\n        const {\n            f,              // Objective function\n            gradient,       // Gradient function\n            hessian,        // Hessian function\n            x0,\n            initialRadius = 1.0,\n            maxRadius = 10.0,\n            eta = 0.1,      // Acceptance threshold\n            maxIter = 100,\n            tol = 1e-8\n        } = config;\n        \n        let x = [...x0];\n        let radius = initialRadius;\n        const history = [{ x: [...x], f: f(x), radius }];\n        \n        for (let iter = 0; iter < maxIter; iter++) {\n            const g = gradient(x);\n            const gradNorm = this._norm(g);\n            \n            if (gradNorm < tol) {\n                return { x, f: f(x), converged: true, iterations: iter, history, method: 'Trust Region' };\n            }\n            \n            const H = hessian(x);\n            const fx = f(x);\n            \n            // Compute dogleg step\n            const p = this._doglegStep(g, H, radius);\n            const x_new = this._add(x, p);\n            const fx_new = f(x_new);\n            \n            // Compute actual vs predicted reduction\n            const actualReduction = fx - fx_new;\n            const predictedReduction = -(this._dot(g, p) + 0.5 * this._dot(p, this._matVec(H, p)));\n            const rho = predictedReduction > 0 ? actualReduction / predictedReduction : 0;\n            \n            // Update trust region radius\n            if (rho < 0.25) {\n                radius *= 0.25;\n            } else if (rho > 0.75 && Math.abs(this._norm(p) - radius) < 1e-10) {\n                radius = Math.min(2 * radius, maxRadius);\n            }\n            \n            // Accept or reject step\n            if (rho > eta) {\n                x = x_new;\n            }\n            \n            history.push({ x: [...x], f: f(x), radius, rho, stepNorm: this._norm(p) });\n        }\n        \n        return { x, f: f(x), converged: false, iterations: maxIter, history, method: 'Trust Region' };\n    },\n    \n    _doglegStep: function(g, H, radius) {\n        const n = g.length;\n        \n        // Compute Cauchy point (steepest descent direction)\n        const gHg = this._dot(g, this._matVec(H, g));\n        let tau_c = gHg > 0 ? this._norm(g) ** 2 / gHg : 1;\n        const p_c = this._scale(g, -tau_c);\n        \n        // If Cauchy point outside trust region, return scaled Cauchy\n        const p_c_norm = this._norm(p_c);\n        if (p_c_norm >= radius) {\n            return this._scale(g, -radius / this._norm(g));\n        }\n        \n        // Compute Newton point\n        const p_n = this._solveLinear(H, this._scale(g, -1));\n        const p_n_norm = this._norm(p_n);\n        \n        // If Newton point inside trust region, return Newton\n        if (p_n_norm <= radius) {\n            return p_n;\n        }\n        \n        // Dogleg: interpolate between Cauchy and Newton\n        const d = this._sub(p_n, p_c);\n        const a = this._dot(d, d);\n        const b = 2 * this._dot(p_c, d);\n        const c = this._dot(p_c, p_c) - radius * radius;\n        const discriminant = b * b - 4 * a * c;\n        const tau = (-b + Math.sqrt(Math.max(0, discriminant))) / (2 * a);\n        \n        return this._add(p_c, this._scale(d, Math.min(1, Math.max(0, tau))));\n    },\n    \n    _solveLinear: function(A, b) {\n        const n = b.length;\n        const aug = A.map((row, i) => [...row, b[i]]);\n        \n        // Gaussian elimination with partial pivoting\n        for (let i = 0; i < n; i++) {\n            let maxRow = i;\n            for (let k = i + 1; k < n; k++) {\n                if (Math.abs(aug[k][i]) > Math.abs(aug[maxRow][i])) maxRow = k;\n            }\n            [aug[i], aug[maxRow]] = [aug[maxRow], aug[i]];\n            \n            if (Math.abs(aug[i][i]) < 1e-12) continue;\n            \n            for (let k = i + 1; k < n; k++) {\n                const factor = aug[k][i] / aug[i][i];\n                for (let j = i; j <= n; j++) {\n                    aug[k][j] -= factor * aug[i][j];\n                }\n            }\n        }\n        \n        // Back substitution\n        const x = new Array(n).fill(0);\n        for (let i = n - 1; i >= 0; i--) {\n            x[i] = aug[i][n];\n            for (let j = i + 1; j < n; j++) {\n                x[i] -= aug[i][j] * x[j];\n            }\n            x[i] /= aug[i][i] || 1;\n        }\n        \n        return x;\n    },\n    \n    /**\n     * Conjugate Gradient (Polak-Ribi\u00e8re variant)\n     * Source: MIT 6.251J\n     */\n    conjugateGradient: function(config) {\n        const {\n            f,\n            gradient,\n            x0,\n            maxIter = 1000,\n            tol = 1e-8,\n            restartInterval = null  // Restart every n iterations (null = n)\n        } = config;\n        \n        const n = x0.length;\n        const restart = restartInterval || n;\n        \n        let x = [...x0];\n        let g = gradient(x);\n        let d = this._scale(g, -1);  // Initial direction = -gradient\n        \n        const history = [{ x: [...x], f: f(x), gradNorm: this._norm(g) }];\n        \n        for (let iter = 0; iter < maxIter; iter++) {\n            const gradNorm = this._norm(g);\n            \n            if (gradNorm < tol) {\n                return { x, f: f(x), converged: true, iterations: iter, history, method: 'Conjugate Gradient' };\n            }\n            \n            // Line search\n            const alpha = this._backtrackingLineSearch(f, gradient, x, d, g);\n            const x_new = this._add(x, this._scale(d, alpha));\n            const g_new = gradient(x_new);\n            \n            // Polak-Ribi\u00e8re beta\n            const g_diff = this._sub(g_new, g);\n            let beta = this._dot(g_new, g_diff) / this._dot(g, g);\n            beta = Math.max(0, beta);  // Reset to steepest descent if beta < 0\n            \n            // Restart periodically\n            if ((iter + 1) % restart === 0) {\n                beta = 0;\n            }\n            \n            // Update direction\n            d = this._add(this._scale(g_new, -1), this._scale(d, beta));\n            \n            x = x_new;\n            g = g_new;\n            history.push({ x: [...x], f: f(x), gradNorm: this._norm(g), alpha, beta });\n        }\n        \n        return { x, f: f(x), converged: false, iterations: maxIter, history, method: 'Conjugate Gradient' };\n    },\n    \n    _backtrackingLineSearch: function(f, gradient, x, d, g, c1 = 1e-4, rho = 0.5) {\n        let alpha = 1;\n        const fx = f(x);\n        const gd = this._dot(g, d);\n        \n        for (let i = 0; i < 50; i++) {\n            const x_new = this._add(x, this._scale(d, alpha));\n            if (f(x_new) <= fx + c1 * alpha * gd) {\n                return alpha;\n            }\n            alpha *= rho;\n        }\n        \n        return alpha;\n    }\n};\n\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n// SECTION 2: CONSTRAINED OPTIMIZATION\n// \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nconst PRISM_CONSTRAINED_OPTIMIZATION_ENHANCED = {\n    name: 'PRISM_CONSTRAINED_OPTIMIZATION_ENHANCED',\n    version: '1.0.0',\n    source: 'MIT 15.084j - Nonlinear Programming',\n    \n    /**\n     * Augmented Lagrangian Method\n     * Handles both equality and inequality constraints\n     * Source: MIT 15.084j Lecture 13\n     */\n    augmentedLagrangian: function(config) {\n        const {\n            f,                    // Objective function\n            gradient,             // Gradient of f\n            equalityConstraints = [],  // h_i(x) = 0\n            inequalityConstraints = [], // g_j(x) <= 0\n            x0,\n            rho0 = 1,             // Initial penalty parameter\n            rhoMax = 1e6,\n            rhoGrowth = 2,\n            maxOuterIter = 50,\n            maxInnerIter = 100,\n            tol = 1e-6\n        } = config;\n        \n        const nEq = equalityConstraints.length;\n        const nIneq = inequalityConstraints.length;\n        \n        let x = [...x0];\n        let lambda = new Array(nEq).fill(0);    // Equality multipliers\n        let mu = new Array(nIneq).fill(0);      // Inequality multipliers\n        let rho = rho0;\n        \n        const history = [];\n        \n        for (let outer = 0; outer < maxOuterIter; outer++) {\n            // Define augmented Lagrangian\n            const L_aug = (x) => {\n                let val = f(x);\n                \n                // Equality constraints: L += lambda'h + (rho/2)||h||^2\n                for (let i = 0; i < nEq; i++) {\n                    const h = equalityConstraints[i](x);\n                    val += lambda[i] * h + (rho / 2) * h * h;\n                }\n                \n                // Inequality constraints with slack\n                for (let j = 0; j < nIneq; j++) {\n                    const g = inequalityConstraints[j](x);\n                    const muRho = mu[j] + rho * g;\n                    if (muRho > 0) {\n                        val += muRho * muRho / (2 * rho) - mu[j] * mu[j] / (2 * rho);\n                    }\n                }\n                \n                return val;\n            };\n            \n            // Gradient of augmented Lagrangian\n            const gradL = (x) => {\n                const grad = gradient(x);\n                const eps = 1e-8;\n                \n                for (let i = 0; i < nEq; i++) {\n                    const h = equalityConstraints[i](x);\n                    // Numerical gradient of h\n                    for (let k = 0; k < x.length; k++) {\n                        const x_plus = [...x]; x_plus[k] += eps;\n                        const x_minus = [...x]; x_minus[k] -= eps;\n                        const dh = (equalityConstraints[i](x_plus) - equalityConstraints[i](x_minus)) / (2 * eps);\n                        grad[k] += (lambda[i] + rho * h) * dh;\n                    }\n                }\n                \n                for (let j = 0; j < nIneq; j++) {\n                    const g = inequalityConstraints[j](x);\n                    const muRho = mu[j] + rho * g;\n                    if (muRho > 0) {\n                        for (let k = 0; k < x.length; k++) {\n                            const x_plus = [...x]; x_plus[k] += eps;\n                            const x_minus = [...x]; x_minus[k] -= eps;\n                            const dg = (inequalityConstraints[j](x_plus) - inequalityConstraints[j](x_minus)) / (2 * eps);\n                            grad[k] += muRho * dg;\n                        }\n                    }\n                }\n                \n                return grad;\n            };\n            \n            // Minimize augmented Lagrangian using L-BFGS\n            const result = PRISM_UNCONSTRAINED_OPTIMIZATION.lbfgs({\n                f: L_aug,\n                gradient: gradL,\n                x0: x,\n                maxIter: maxInnerIter,\n                tol: tol / 10\n            });\n            \n            x = result.x;\n            \n            // Compute constraint violations\n            let maxViolation = 0;\n            const hVals = equalityConstraints.map(h => h(x));\n            const gVals = inequalityConstraints.map(g => g(x));\n            \n            for (const h of hVals) maxViolation = Math.max(maxViolation, Math.abs(h));\n            for (const g of gVals) maxViolation = Math.max(maxViolation, Math.max(0, g));\n            \n            history.push({\n                outer,\n                x: [...x],\n                f: f(x),\n                maxViolation,\n                rho,\n                lambda: [...lambda],\n                mu: [...mu]\n            });\n            \n            // Check convergence\n            if (maxViolation < tol) {\n                return {\n                    x,\n                    f: f(x),\n                    converged: true,\n                    outerIterations: outer + 1,\n                    lambda,\n                    mu,\n                    history,\n                    method: 'Augmented Lagrangian'\n                };\n            }\n            \n            // Update multipliers\n            for (let i = 0; i < nEq; i++) {\n                lambda[i] += rho * hVals[i];\n            }\n            for (let j = 0; j < nIneq; j++) {\n                mu[j] = Math.max(0, mu[j] + rho * gVals[j]);\n            }\n            \n            // Increase penalty\n            rho = Math.min(rhoMax, rho * rhoGrowth);\n        }",
      "methods": [],
      "lines": 520
    },
    {
      "name": "PRISM_UNIT_SYSTEM",
      "category": "units",
      "refs": 99,
      "status": "NOT_FOUND",
      "code": "",
      "methods": [],
      "lines": 0
    },
    {
      "name": "PRISM_PARAM_ENGINE",
      "category": "core",
      "refs": 45,
      "status": "NOT_FOUND",
      "code": "",
      "methods": [],
      "lines": 0
    },
    {
      "name": "PRISM_CAPABILITY_REGISTRY",
      "category": "core",
      "refs": 44,
      "status": "FOUND",
      "code": "const PRISM_CAPABILITY_REGISTRY = {\n    version: '1.0.0',\n\n    // Registry of all capabilities: { id: capability }\n    capabilities: {},\n\n    // Category and layer indices\n    byCategory: {},\n    byLayer: {},\n\n    /**\n     * Register a module capability\n     * @param {string} moduleId - Full module path (e.g., 'layer3.algorithms.voronoi')\n     * @param {object} capability - Capability definition\n     */\n    register(moduleId, capability) {\n        const entry = {\n            id: capability.id || moduleId,\n            module: moduleId,\n            name: capability.name,\n            description: capability.description || '',\n            category: capability.category || 'general',\n            layer: capability.layer || this._inferLayer(moduleId),\n\n            // Input/Output schema for auto-generating UI\n            inputs: capability.inputs || {},\n            outputs: capability.outputs || {},\n\n            // UI hints\n            ui: {\n                icon: capability.icon || '\u00e2\u0161\u2122\u00ef\u00b8\u008f',\n                preferredComponent: capability.preferredComponent || null,\n                menuPath: capability.menuPath || null,\n                shortcut: capability.shortcut || null\n            },\n            // Execution function\n            execute: capability.execute || null,\n\n            // Metadata\n            registered: Date.now(),\n            version: capability.version || '1.0.0',\n            source: capability.source || null\n        };\n        // Store in registry\n        this.capabilities[entry.id] = entry;\n\n        // Index by category\n        if (!this.byCategory[entry.category]) {\n            this.byCategory[entry.category] = [];\n        }\n        this.byCategory[entry.category].push(entry.id);\n\n        // Index by layer\n        if (!this.byLayer[entry.layer]) {\n            this.byLayer[entry.layer] = [];\n        }\n        this.byLayer[entry.layer].push(entry.id);\n\n        PRISM_EVENT_BUS.publish('capability:registered', entry, { source: 'CAPABILITY_REGISTRY' });\n        (typeof PRISM_CONSTANTS !== 'undefined' && PRISM_CONSTANTS.DEBUG) && console.log(`[PRISM] Registered capability: ${entry.name} (${entry.id})`);\n\n        return entry.id;\n    },\n    /**\n     * Get all capabilities\n     */\n    getAll() {\n        return Object.values(this.capabilities);\n    },\n    /**\n     * Get capabilities by category\n     */\n    getByCategory(category) {\n        const ids = this.byCategory[category] || [];\n        return ids.map(id => this.capabilities[id]);\n    },\n    /**\n     * Get capabilities by layer\n     */\n    getByLayer(layer) {\n        const ids = this.byLayer[layer] || [];\n        return ids.map(id => this.capabilities[id]);\n    },\n    /**\n     * Get a specific capability\n     */\n    get(id) {\n        return this.capabilities[id] || null;\n    },\n    /**\n     * Execute a capability\n     */\n    async execute(id, inputs) {\n        const capability = this.capabilities[id];\n        if (!capability) {\n            throw new Error(`Unknown capability: ${id}`);\n        }\n        if (!capability.execute) {\n            throw new Error(`Capability ${id} has no execute function`);\n        }\n        // Validate inputs\n        const errors = this._validateInputs(inputs, capability.inputs);\n        if (errors.length > 0) {\n            throw new Error(`Invalid inputs: ${errors.join(', ')}`);\n        }\n        PRISM_EVENT_BUS.publish('capability:executing', { id, inputs }, { source: 'CAPABILITY_REGISTRY' });\n\n        try {\n            const result = await capability.execute(inputs);\n            PRISM_EVENT_BUS.publish('capability:complete', { id, inputs, result }, { source: 'CAPABILITY_REGISTRY' });\n            return result;\n        } catch (error) {\n            PRISM_EVENT_BUS.publish('capability:error', { id, inputs, error }, { source: 'CAPABILITY_REGISTRY' });\n            throw error;\n        }\n    },\n    /**\n     * Generate UI schema for a capability (for auto-generating forms)\n     */\n    getUISchema(id) {\n        const capability = this.capabilities[id];\n        if (!capability) return null;\n\n        return {\n            title: capability.name,\n            description: capability.description,\n            fields: Object.entries(capability.inputs).map(([name, schema]) => ({\n                name,\n                label: schema.label || name,\n                type: schema.type || 'text',\n                required: schema.required || false,\n                defaultValue: schema.default,\n                options: schema.options,\n                min: schema.min,\n                max: schema.max\n            }))\n        };\n    },\n    /**\n     * Get menu structure for auto-generating menus\n     */\n    getMenuStructure() {\n        const menu = {};\n\n        for (const cap of Object.values(this.capabilities)) {\n            const path = cap.ui.menuPath || `${cap.category}/${cap.name}`;\n            const parts = path.split('/');\n\n            let current = menu;\n            for (let i = 0; i < parts.length - 1; i++) {\n                if (!current[parts[i]]) {\n                    current[parts[i]] = { _items: [], _submenu: {} };\n                }\n                current = current[parts[i]]._submenu;\n            }\n            if (!current._items) current._items = [];\n            current._items.push({\n                id: cap.id,\n                label: parts[parts.length - 1],\n                icon: cap.ui.icon,\n                shortcut: cap.ui.shortcut\n            });\n        }\n        return menu;\n    },\n    _inferLayer(moduleId) {\n        const match = moduleId.match(/layer(\\d+)/i);\n        return match ? parseInt(match[1]) : 0;\n    },\n    _validateInputs(inputs, schema) {\n        const errors = [];\n\n        for (const [name, config] of Object.entries(schema)) {\n            if (config.required && (inputs[name] === undefined || inputs[name] === null)) {\n                errors.push(`${name} is required`);\n            }\n            if (inputs[name] !== undefined && config.type) {\n                const actualType = typeof inputs[name];\n                if (config.type === 'number' && actualType !== 'number') {\n                    errors.push(`${name} must be a number`);\n                }\n            }\n        }\n        return errors;\n    }\n}",
      "methods": [],
      "lines": 186
    },
    {
      "name": "PRISM_MACHINE_3D_MODELS",
      "category": "machines",
      "refs": 44,
      "status": "FOUND",
      "code": "const PRISM_MACHINE_3D_MODELS = {\n  uploadedModels: {\n    // Hurco Batch 3 (Uploaded CAD - January 2026)\n    'hurco_vc600i': {\n      source: 'Hurco VC600i.step', manufacturer: 'Hurco', model: 'VC600i', type: '3axis',\n      geometry: { faces: 8067, points: 184564 }, priority: 'uploaded'\n    },\n    'hurco_vmx42i_uploaded': {\n      source: 'Hurco VMX42i.step', manufacturer: 'Hurco', model: 'VMX42i', type: '3axis',\n      geometry: { faces: 9005, points: 163119 }, priority: 'uploaded'\n    },\n    'hurco_vmx42swi': {\n      source: 'Hurco VMX 42 SWi.step', manufacturer: 'Hurco', model: 'VMX42 SWi', type: '5axis',\n      geometry: { faces: 9079, points: 166130 }, priority: 'uploaded'\n    },\n    'hurco_vmx42srti': {\n      source: 'Hurco VMX42SRTi.step', manufacturer: 'Hurco', model: 'VMX42SRTi', type: '5axis',\n      geometry: { faces: 9808, points: 171968 }, priority: 'uploaded'\n    },\n    'hurco_vmx64ti': {\n      source: 'Hurco VMX64Ti.step', manufacturer: 'Hurco', model: 'VMX64Ti', type: '5axis',\n      geometry: { faces: 8627, points: 183912 }, priority: 'uploaded'\n    },\n  },\n  version: '1.0.0',\n\n  // BUILT-IN MACHINE MODELS (metadata + simplified mesh data)\n  builtInModels: {\n    'okuma_genos_m460v-5ax': {\n      id: 'okuma_genos_m460v-5ax',\n      manufacturer: 'Okuma',\n      model: 'GENOS M460V-5AX',\n      type: '5-axis_vmc',\n      source: 'user_upload',\n      fileFormat: 'STEP',\n      fileSize: 4237205,\n\n      // Assembly structure (kinematic chain)\n      components: [\n        { id: 'static', name: 'Base/Frame', type: 'fixed', parent: null },\n        { id: 'x_axis_head', name: 'X-Axis Head', type: 'linear', parent: 'static', axis: 'X', travel: [-230, 230] },\n        { id: 'z_axis_head', name: 'Z-Axis/Spindle', type: 'linear', parent: 'x_axis_head', axis: 'Z', travel: [-200, 200] },\n        { id: 'y_axis_table', name: 'Y-Axis Table', type: 'linear', parent: 'static', axis: 'Y', travel: [-200, 200] },\n        { id: 'a_axis_table', name: 'A-Axis Trunnion', type: 'rotary', parent: 'y_axis_table', axis: 'A', range: [-30, 120] },\n        { id: 'c_axis_table', name: 'C-Axis Rotary', type: 'rotary', parent: 'a_axis_table', axis: 'C', range: [-360, 360] }\n      ],\n\n      // Machine specs\n      specs: {\n        travelX: 460,\n        travelY: 400,\n        travelZ: 400,\n        tableSize: 400,  // diameter\n        maxRPM: 15000,\n        spindleTaper: 'BBT40',\n        controller: 'OSP-P300A',\n        weight: 6500  // kg\n      },\n      // Bounding box (mm)\n      boundingBox: {\n        min: { x: -1200, y: -800, z: 0 },\n        max: { x: 1200, y: 800, z: 2800 }\n      },\n      // Color scheme\n      colors: {\n        frame: 0x2a4d3a,      // Okuma green\n        covers: 0x3d3d3d,     // Dark gray\n        table: 0x4a4a4a,      // Medium gray\n        spindle: 0x888888,    // Light gray\n        accent: 0xff6600      // Orange accents\n      },\n      // Flag indicating full STEP file available\n      hasFullModel: true,\n      stepFileKey: 'okuma_genos_m460v-5ax_step'  // localStorage key if uploaded\n    }\n  },\n  // USER-UPLOADED MODELS (stored in IndexedDB/localStorage)\n  userModels: {},\n\n  // DATABASE OPERATIONS\n\n  /**\n   * Initialize the 3D models database\n   */\n  init() {\n    console.log('[PRISM_MACHINE_3D_MODELS] Initializing...');\n\n    // Load user models from localStorage\n    this.loadUserModels();\n\n    // Register global functions\n    window.uploadMachineModel = this.uploadMachineModel.bind(this);\n    window.getMachineModel = this.getMachineModel.bind(this);\n    window.listMachineModels = this.listMachineModels.bind(this);\n    window.deleteMachineModel = this.deleteMachineModel.bind(this);\n\n    console.log('[PRISM_MACHINE_3D_MODELS] Loaded ' + Object.keys(this.builtInModels).length + ' built-in models');\n    console.log('[PRISM_MACHINE_3D_MODELS] Loaded ' + Object.keys(this.userModels).length + ' user models');\n\n    return this;\n  },\n  /**\n   * Load user models from localStorage/IndexedDB\n   */\n  loadUserModels() {\n    try {\n      const stored = localStorage.getItem('prism_user_machine_models');\n      if (stored) {\n        this.userModels = JSON.parse(stored);\n      }\n    } catch (e) {\n      console.warn('[PRISM_MACHINE_3D_MODELS] Error loading user models:', e);\n      this.userModels = {};\n    }\n  },\n  /**\n   * Save user models to localStorage\n   */\n  saveUserModels() {\n    try {\n      // Don't save the actual file data to localStorage (too large)\n      // Just save metadata - actual files go to IndexedDB\n      const metadata = {};\n      for (const [key, model] of Object.entries(this.userModels)) {\n        metadata[key] = {\n          ...model,\n          fileData: null,  // Don't store file data in localStorage\n          hasFileData: !!model.fileData\n        };\n      }\n      localStorage.setItem('prism_user_machine_models', JSON.stringify(metadata));\n    }",
      "methods": [],
      "lines": 132
    }
  ]
}